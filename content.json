{"meta":{"title":"GOYTH","subtitle":"记录学习的技能和遇到的问题","description":"I hear and I forget, I see and I remember, I do and I understand.","author":"Luke Hu","url":"http://www.goyth.com"},"pages":[{"title":"about","date":"2018-03-30T13:05:14.000Z","updated":"2018-03-30T13:05:14.807Z","comments":true,"path":"about/index.html","permalink":"http://www.goyth.com/about/index.html","excerpt":"","text":""},{"title":"All categories","date":"2018-03-30T12:55:05.000Z","updated":"2018-03-30T13:07:24.000Z","comments":true,"path":"categories/index.html","permalink":"http://www.goyth.com/categories/index.html","excerpt":"","text":""},{"title":"All tags","date":"2018-03-30T12:44:24.000Z","updated":"2018-03-30T14:13:13.000Z","comments":true,"path":"tags/index.html","permalink":"http://www.goyth.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"webpack 打包构建流程分析","slug":"webpackFlow","date":"2018-12-10T13:22:43.000Z","updated":"2018-12-10T15:31:51.567Z","comments":true,"path":"2018/12/10/webpackFlow/","link":"","permalink":"http://www.goyth.com/2018/12/10/webpackFlow/","excerpt":"如何调试 webpackrequire(加载) node_modules/webpack-cli/bin 目录下的cli.js，预先设置debugger（断点），然后开启调试模式。 debugger.js12var webpackPath=require('path').resolve(__dirname,'node_modules', 'webpack-cli', 'bin', 'cli.js');require(webpackPath); webpack.config.js123456789const path=require('path');module.exports=&#123; mode:\"development\", entry: './src/index.js', output: &#123; path: path.resolve(__dirname,'dist'), filename:'bundle.js' &#125;&#125; webpack 主要工作流程Webpack 的运行流程是一个串行的过程，从启动到结束会依次执行以下流程： 初始化参数：从配置文件和 Shell 语句中读取与合并参数，得出最终的参数； 开始编译：用上一步得到的参数初始化 Compiler 对象，加载所有配置的插件，执行对象的run方法开始执行编译； 确定入口：根据配置中的 entry 找出所有的入口文件 编译模块：从入口文件出发，调用所有配置的 Loader 对模块进行编译，再找出该模块依赖的模块，再递归本步骤直到所有入口依赖的文件都经过了本步骤的处理； 完成模块编译：在经过第4步使用 Loader 翻译完所有模块后，得到了每个模块被翻译后的最终内容以及它们之间的依赖关系； 输出资源：根据入口和模块之间的依赖关系，组装成一个个包含多个模块的 Chunk，再把每个 Chunk 转换成一个单独的文件加入到输出列表，这步是可以修改输出内容的最后机会； 输出完成：在确定好输出内容后，根据配置确定输出的路径和文件名，把文件内容写入到文件系统。 在以上过程中，Webpack 会在特定的时间点广播出特定的事件，插件在监听到感兴趣的事件后会执行特定的逻辑，并且插件可以调用 Webpack 提供的 API 改变 Webpack 的运行结果。","text":"如何调试 webpackrequire(加载) node_modules/webpack-cli/bin 目录下的cli.js，预先设置debugger（断点），然后开启调试模式。 debugger.js12var webpackPath=require('path').resolve(__dirname,'node_modules', 'webpack-cli', 'bin', 'cli.js');require(webpackPath); webpack.config.js123456789const path=require('path');module.exports=&#123; mode:\"development\", entry: './src/index.js', output: &#123; path: path.resolve(__dirname,'dist'), filename:'bundle.js' &#125;&#125; webpack 主要工作流程Webpack 的运行流程是一个串行的过程，从启动到结束会依次执行以下流程： 初始化参数：从配置文件和 Shell 语句中读取与合并参数，得出最终的参数； 开始编译：用上一步得到的参数初始化 Compiler 对象，加载所有配置的插件，执行对象的run方法开始执行编译； 确定入口：根据配置中的 entry 找出所有的入口文件 编译模块：从入口文件出发，调用所有配置的 Loader 对模块进行编译，再找出该模块依赖的模块，再递归本步骤直到所有入口依赖的文件都经过了本步骤的处理； 完成模块编译：在经过第4步使用 Loader 翻译完所有模块后，得到了每个模块被翻译后的最终内容以及它们之间的依赖关系； 输出资源：根据入口和模块之间的依赖关系，组装成一个个包含多个模块的 Chunk，再把每个 Chunk 转换成一个单独的文件加入到输出列表，这步是可以修改输出内容的最后机会； 输出完成：在确定好输出内容后，根据配置确定输出的路径和文件名，把文件内容写入到文件系统。 在以上过程中，Webpack 会在特定的时间点广播出特定的事件，插件在监听到感兴趣的事件后会执行特定的逻辑，并且插件可以调用 Webpack 提供的 API 改变 Webpack 的运行结果。 \bwebpack打包流程图 流程详解初始化阶段 事件名 解释 代码位置 读取命令行参数&ensp; 从命令行中读取用户输入的参数 require(“./convert-argv”)(argv) 实例化 Compiler 1.用上一步得到的参数初始Compiler 实例 2.Compiler 负责文件监听和启动编译 3.Compiler 实例中包含了完整的 Webpack 配置，全局只有一个 Compiler 实例。 compiler = webpack(options); 加载插件 1.依次调用插件的 apply 方法，让插件可以监听后续的所有事件节点。同时给插件传入 compiler 实例的引用，以方便插件通过 compiler 调用 Webpack 提供的 API。 plugin.apply(compiler) 处理入口 读取配置的 Entrys，为每个 Entry 实例化一个对应的 EntryPlugin，为后面该 Entry 的递归解析工作做准备 new EntryOptionPlugin().apply(compiler) new SingleEntryPlugin(context, item, name) compiler.hooks.make.tapAsync 编译阶段 事件名 解释 代码位置 run 启动一次新的编译 this.hooks.run.callAsync compile 该事件是为了告诉插件一次新的编译将要启动，同时会给插件传入compiler 对象。 compile(callback) compilation 当 Webpack 以开发模式运行时，每当检测到文件变化，一次新的 Compilation 将被创建。一个 Compilation 对象包含了当前的模块资源、编译生成资源、变化的文件等。Compilation 对象也提供了很多事件回调供插件做扩展。 newCompilation(params) make 一个新的 Compilation 创建完毕主开始编译 this.hooks.make.callAsync addEntry 即将从 Entry 开始读取文件 compilation.addEntry this._addModuleChain moduleFactory 创建模块工厂 const moduleFactory = this.dependencyFactories.get(Dep) create 创建模块 moduleFactory.create factory 开始创建模块 factory(result, (err, module) resolver(result) this.hooks.resolver.tap(“NormalModuleFactory”) resolveRequestArray 解析loader路径 resolveRequestArray resolve 解析资源文件路径 resolve userRequest 得到包括loader在内的资源文件的绝对路径用!拼起来的字符串 userRequest ruleSet.exec 它可以根据模块路径名，匹配出模块所需的loader this.ruleSet.exec _run 它可以根据模块路径名，匹配出模块所需的loader _run loaders 得到所有的loader数组 results[0].concat(loaders, results[1], results[2]) getParser 获取AST解析器 this.getParser(type, settings.parser) buildModule 开始编译模块 this.buildModule(module) buildModule(module, optional, origin,dependencies, thisCallback) build 开始真正编译入口模块 build(options) doBuild 开始真正编译入口模块 doBuild 执行loader 使用loader进行转换 runLoaders runLoaders iteratePitchingLoaders 开始递归执行pitch loader iteratePitchingLoaders loadLoader 加载loader loadLoader runSyncOrAsync 执行pitchLoader runSyncOrAsync processResource 开始处理资源 processResourceoptions.readResourceiterateNormalLoadersiterateNormalLoaders createSource 创建源代码对象 this.createSource parse 使用parser转换抽象语法树 this.parser.parse parse 解析抽象语法树 parse(source, initialState) acorn.parse 解析语法树 acorn.parse(code, parserOptions) ImportDependency 遍历并添加添加依赖 parser.state.module.addDependency(clearDep) succeedModule 生成语法树后就表示一个模块编译完成 this.hooks.succeedModule.call(module) processModuleDependencies 递归编译依赖的模块 this.processModuleDependencies(module)processModuleDependencies(module, callback)this.addModuleDependenciesbuildModule make后 结束make this.hooks.make.callAsync(compilation, err =&gt; {} finish 编译完成 compilation.finish(); 结束阶段 事件名 解释 代码 seal 封装 compilation.seal seal(callback) addChunk 生成资源 addChunk(name) createChunkAssets 创建资源 this.createChunkAssets() getRenderManifest 获得要渲染的描述文件 getRenderManifest(options) render 渲染源码 source = fileManifest.render(); afterCompile 编译结束 this.hooks.afterCompile shouldEmit 所有需要输出的文件已经生成好，询问插件哪些文件需要输出，哪些不需要。 this.hooks.shouldEmit emit 确定好要输出哪些文件后，执行文件输出，可以在这里获取和修改输出内容。 this.emitAssets(compilation) this.hooks.emit.callAsync const emitFiles = errthis.outputFileSystem.writeFile this.emitRecords 写入记录 this.emitRecords done 全部完成 this.hooks.done.callAsync","categories":[{"name":"webpack","slug":"webpack","permalink":"http://www.goyth.com/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://www.goyth.com/tags/webpack/"}]},{"title":"JavaScript垃圾回收机制与内存泄漏","slug":"V8GC","date":"2018-12-02T05:46:27.000Z","updated":"2018-12-02T09:11:02.431Z","comments":true,"path":"2018/12/02/V8GC/","link":"","permalink":"http://www.goyth.com/2018/12/02/V8GC/","excerpt":"JavaScript 垃圾收集 程序的运行需要分配内存，内存资源是有限的，当程序运行结束后，就应该回收其内存资源。JavaScript使用自动内存管理，也称为垃圾回收机制（garbage collector） 自动垃圾回收的优点是可以简化开发，不用时刻惦记着回收不再使用的变量，降低内存泄漏的可能性；缺点是无法完全的掌握内存的分配以及回收的具体过程。 V8引擎垃圾回收机制自动垃圾回收算法的演变过程中出现了很多算法，但是由于不同对象的生存周期不同，没有一种算法适用于所有的情况。所以V8采用了一种分代回收的策略，将内存分为两个生代：新生代和老生代。新生代的对象为存活时间较短的对象，老生代中的对象为存活时间较长或常驻内存的对象。分别对新生代和老生代使用不同的垃圾回收算法来提升垃圾回收的效率。对象起初都会被分配到新生代，当新生代中的对象满足某些条件（后面会有介绍）时，会被移动到老生代（晋升）","text":"JavaScript 垃圾收集 程序的运行需要分配内存，内存资源是有限的，当程序运行结束后，就应该回收其内存资源。JavaScript使用自动内存管理，也称为垃圾回收机制（garbage collector） 自动垃圾回收的优点是可以简化开发，不用时刻惦记着回收不再使用的变量，降低内存泄漏的可能性；缺点是无法完全的掌握内存的分配以及回收的具体过程。 V8引擎垃圾回收机制自动垃圾回收算法的演变过程中出现了很多算法，但是由于不同对象的生存周期不同，没有一种算法适用于所有的情况。所以V8采用了一种分代回收的策略，将内存分为两个生代：新生代和老生代。新生代的对象为存活时间较短的对象，老生代中的对象为存活时间较长或常驻内存的对象。分别对新生代和老生代使用不同的垃圾回收算法来提升垃圾回收的效率。对象起初都会被分配到新生代，当新生代中的对象满足某些条件（后面会有介绍）时，会被移动到老生代（晋升） V8的分代内存默认情况下，64位环境下的V8引擎的新生代内存大小32MB、老生代内存大小为1400MB，而32位则减半，分别为16MB和700MB。V8内存的最大保留空间分别为1464MB（64位）和732MB（32位）。具体的计算公式是4*reserved_semispace_space_ + max_old_generation_size_，新生代由两块reserved_semispace_space_组成，每块16MB（64位）或8MB（32位） 新生代大多数的对象被分配在这里，这个区域很小但是垃圾回特别频繁。在新生代分配内存非常容易，我们只需要保存一个指向内存区的指针，不断根据新对象的大小进行递增即可。当该指针到达了新生代内存区的末尾，就会有一次清理（仅仅是清理新生代） 新生代的垃圾回收算法新生代使用Scavenge算法进行回收。在Scavenge算法的实现中，主要采用了Cheney算法。 Cheney算法算法是一种采用复制的方式实现的垃圾回收算法。它将内存一分为二，每一部分空间称为semispace。在这两个semispace中，一个处于使用状态，另一个处于闲置状态。处于使用状态的semispace空间称为From空间，处于闲置状态的空间称为To空间，当我们分配对象时，先是在From空间中进行分配。当开始进行垃圾回收算法时，会检查From空间中的存活对象，这些存活对象将会被复制到To空间中（复制完成后会进行紧缩），而非活跃对象占用的空间将会被释放。完成复制后，From空间和To空间的角色发生对换。也就是说，在垃圾回收的过程中，就是通过将存活对象在两个semispace之间进行复制。可以很容易看出来，使用Cheney算法时，总有一半的内存是空的。但是由于新生代很小，所以浪费的内存空间并不大。而且由于新生代中的对象绝大部分都是非活跃对象，需要复制的活跃对象比例很小，所以其时间效率十分理想。复制的过程采用的是BFS（广度优先遍历）的思想，从根对象出发，广度优先遍历所有能到达的对象 具体的执行过程大致是这样： 首先将From空间中所有能从根对象到达的对象复制到To区，然后维护两个To区的指针scanPtr和allocationPtr，分别指向即将扫描的活跃对象和即将为新对象分配内存的地方，开始循环。循环的每一轮会查找当前scanPtr所指向的对象，确定对象内部的每个指针指向哪里。如果指向老生代我们就不必考虑它了。如果指向From区，我们就需要把这个所指向的对象从From区复制到To区，具体复制的位置就是allocationPtr所指向的位置。复制完成后将scanPtr所指对象内的指针修改为新复制对象存放的地址，并移动allocationPtr。如果一个对象内部的所有指针都被处理完，scanPtr就会向前移动，进入下一个循环。若scanPtr和allocationPtr相遇，则说明所有的对象都已被复制完，From区剩下的都可以被视为垃圾，可以进行清理了 举个栗子，如果有类似如下的引用情况：123456789 +----- A对象 |根对象----+----- B对象 ------ E对象 | +----- C对象 ----+---- F对象 | +---- G对象 ----- H对象 D对象 在执行Scavenge之前，From区长这幅模样1234+---+---+---+---+---+---+---+---+--------+| A | B | C | D | E | F | G | H | |+---+---+---+---+---+---+---+---+--------+ 那么首先将根对象能到达的ABC对象复制到To区，于是乎To区就变成了这个样子：12345678 allocationPtr ↓ +---+---+---+----------------------------+| A | B | C | |+---+---+---+----------------------------+ ↑scanPtr 接下来进入循环，扫描scanPtr所指的A对象，发现其没有指针，于是乎scanPtr移动，变成如下这样1234567 allocationPtr ↓ +---+---+---+----------------------------+| A | B | C | |+---+---+---+----------------------------+ ↑ scanPtr 接下来扫描B对象，发现其有指向E对象的指针，且E对象在From区，那么我们需要将E对象复制到allocationPtr所指的地方并移动allocationPtr指针：1234567 allocationPtr ↓ +---+---+---+---+------------------------+| A | B | C | E | |+---+---+---+---+------------------------+ ↑ scanPtr B对象里所有指针都已被复制完，所以移动scanPtr：1234567 allocationPtr ↓ +---+---+---+---+------------------------+| A | B | C | E | |+---+---+---+---+------------------------+ ↑ scanPtr 接下来扫描C对象，C对象中有两个指针，分别指向F对象和G对象，且都在From区，先复制F对象到To区：1234567 allocationPtr ↓ +---+---+---+---+---+--------------------+| A | B | C | E | F | |+---+---+---+---+---+--------------------+ ↑ scanPtr 然后复制G对象到To区1234567 allocationPtr ↓ +---+---+---+---+---+---+----------------+| A | B | C | E | F | G | |+---+---+---+---+---+---+----------------+ ↑ scanPtr 这样C对象内部的指针已经复制完成了，移动scanPtr：1234567 allocationPtr ↓ +---+---+---+---+---+---+----------------+| A | B | C | E | F | G | |+---+---+---+---+---+---+----------------+ ↑ scanPtr 逐个扫描E，F对象，发现其中都没有指针，移动scanPtr：1234567 allocationPtr ↓ +---+---+---+---+---+---+----------------+| A | B | C | E | F | G | |+---+---+---+---+---+---+----------------+ ↑ scanPtr 扫描G对象，发现其中有一个指向H对象的指针，且H对象在From区，复制H对象到To区，并移动allocationPtr：1234567 allocationPtr ↓+---+---+---+---+---+---+---+------------+| A | B | C | E | F | G | H | |+---+---+---+---+---+---+---+------------+ ↑ scanPtr 完成后由于G对象没有其他指针，且H对象没有指针移动scanPtr：1234567 allocationPtr ↓ +---+---+---+---+---+---+---+------------+| A | B | C | E | F | G | H | |+---+---+---+---+---+---+---+------------+ ↑ scanPtr 此时scanPtr和allocationPtr重合，说明复制结束 可以对比一下From区和To区在复制完成后的结果：12345678//From区+---+---+---+---+---+---+---+---+--------+| A | B | C | D | E | F | G | H | |+---+---+---+---+---+---+---+---+--------+//To区+---+---+---+---+---+---+---+------------+| A | B | C | E | F | G | H | |+---+---+---+---+---+---+---+------------+ D对象没有被复制，它将被作为垃圾进行回收 写屏障如果新生代中的一个对象只有一个指向它的指针，而这个指针在老生代中，我们如何判断这个新生代的对象是否存活？为了解决这个问题，需要建立一个列表用来记录所有老生代对象指向新生代对象的情况。每当有老生代对象指向新生代对象的时候，我们就记录下来 对象的晋升当一个对象经过多次新生代的清理依旧幸存，这说明它的生存周期较长，也就会被移动到老生代，这称为对象的晋升。具体移动的标准有两种： 对象从From空间复制到To空间时，会检查它的内存地址来判断这个对象是否已经经历过一个新生代的清理，如果是，则复制到老生代中，否则复制到To空间中 对象从From空间复制到To空间时，如果To空间已经被使用了超过25%，那么这个对象直接被复制到老生代 老生代老生代的特点老生代所保存的对象大多数是生存周期很长的甚至是常驻内存的对象，而且老生代占用的内存较多 老生代的垃圾回收算法老生代占用内存较多（64位为1.4GB，32位为700MB），如果使用Scavenge算法，浪费一半空间不说，复制如此大块的内存消耗时间将会相当长。所以Scavenge算法显然不适合。V8在老生代中的垃圾回收策略采用Mark-Sweep和Mark-Compact相结合 Mark-Sweep（标记清除）标记清除分为标记和清除两个阶段。在标记阶段需要遍历堆中的所有对象，并标记那些活着的对象，然后进入清除阶段。在清除阶段总，只清除没有被标记的对象。由于标记清除只清除死亡对象，而死亡对象在老生代中占用的比例很小，所以效率较高 标记清除有一个问题就是进行一次标记清楚后，内存空间往往是不连续的，会出现很多的内存碎片。如果后续需要分配一个需要内存空间较多的对象时，如果所有的内存碎片都不够用，将会使得V8无法完成这次分配，提前触发垃圾回收。 Mark-Compact（标记整理）标记整理正是为了解决标记清除所带来的内存碎片的问题。标记整理在标记清除的基础进行修改，将其的清除阶段变为紧缩极端。在整理的过程中，将活着的对象向内存区的一段移动，移动完成后直接清理掉边界外的内存。紧缩过程涉及对象的移动，所以效率并不是太好，但是能保证不会生成内存碎片 算法思路标记清除和标记整理都分为两个阶段：标记阶段、清除或紧缩阶段 在标记阶段，所有堆上的活跃对象都会被标记。每个内存页有一个用来标记对象的位图，位图中的每一位对应内存页中的一个字。这个位图需要占据一定的空间（32位下为3.1%，64位为1.6%）。另外有两位用来标记对象的状态，这个状态一共有三种（所以要两位）——白，灰，黑： 如果一个对象为白对象，它还没未被垃圾回收器发现 如果一个对象为灰对象，它已经被垃圾回收器发现，但其邻接对象尚未全部处理 如果一个对象为黑对象，说明他步进被垃圾回收器发现，其邻接对象也全部被处理完毕了 如果将对中的对象看做由指针做边的有向图，标记算法的核心就是深度优先搜索。在初始时，位图为空，所有的对象也都是白对象。从根对象到达的对象会背染色为灰色，放入一个单独的双端队列中。标记阶段的每次循环，垃圾回收器都会从双端队列中取出一个对象并将其转变为黑对象，并将其邻接的对象转变为灰，然后把其邻接对象放入双端队列。如果双端队列为空或所有对象都变成黑对象，则结束。特别大的对象，可能会在处理时进行分片，防止双端队列溢出。如果双端队列溢出，则对象仍然会成为灰对象，但不会被放入队列中，这将导致其邻接对象无法被转变为灰对象。所以在双端队列为空时，需要扫描所有对象，如果仍有灰对象，将它们重新放入队列中进行处理。标记结束后，所有的对象都应该非黑即白，白对象将成为垃圾，等待释放 清除和紧缩阶段都是以内存页为单位回收内存 清除时垃圾回收器会扫描连续存放的死对象，将其变成空闲空间，并保存到一个空闲空间的链表中。这个链表常被scavenge算法用于分配被晋升对象的内存，但也被紧缩算法用于移动对象 紧缩算法会尝试将碎片页整合到一起来释放内存。由于页上的对象会被移动到新的页上，需要重新分配一些页。大致过程是，对目标碎片页中的每个活跃对象，在空闲内存链表中分配一块内存页，将该对象复制过去，并在碎片页中的该对象上写上新的内存地址。随后在迁出过程中，对象的旧地址将会被记录下来，在迁出结束后，V8会遍历所有它所记录的旧对象的地址，将其更新为新地址。由于标记过程中也记录了不同页之间的指针，这些指针在此时也会进行更新。如果一个页非常活跃，如其中有过多需要记录的指针，那么地址记录会跳过它，等到下一轮垃圾回收进行处理 结合使用标记清除和标记整理V8的老生代使用标记清除和标记整理结合的方式，主要采用标记清除算法，如果空间不足以分配从新生代晋升过来的对象时，才使用标记整理 V8的优化Incremental Marking（增量标记）由于全停顿会造成了浏览器一段时间无响应，所以V8使用了一种增量标记的方式，将完整的标记拆分成很多部分，每做完一部分就停下来，让JS的应用逻辑执行一会，这样垃圾回收与应用逻辑交替完成。经过增量标记的改进后，垃圾回收的最大停顿时间可以减少到原来的1/6左右 惰性清理由于标记完成后，所有的对象都已经被标记，不是死对象就是活对象，堆上多少空间格局已经确定。我们可以不必着急释放那些死对象所占用的空间，而延迟清理过程的执行。垃圾回收器可以根据需要逐一清理死对象所占用的内存页 其他V8后续还引入了增量式整理（incremental compaction），以及并行标记和并行清理，通过并行利用多核CPU来提升垃圾回收的性能 内\b存\b泄漏当应用程序不再需要占用内存的时候，由于某些原因，内存没有被操作系统或可用内存池回收时就会产生\b内存泄漏 四种类型的常见 JavaScript 内存泄漏1. 意外的全局变量JavaScript 处理未定义变量的方式比较宽松：未定义的变量会在全局对象创建一个新变量。在浏览器中，全局对象是 window 。123function foo(arg) &#123; bar = \"this is a hidden global variable\";&#125; 真相是：123function foo(arg) &#123; window.bar = \"this is an explicit global variable\";&#125; 函数 foo 内部忘记使用 var ，意外创建了一个全局变量。此例泄漏了一个简单的字符串，无伤大雅，但是有更糟的情况。 另一种意外的全局变量可能由 this 创建：123456function foo() &#123; this.variable = \"potential accidental global\";&#125;// Foo 调用自己，this 指向了全局对象（window）// 而不是 undefinedfoo(); 在 JavaScript 文件头部加上 &#39;use strict&#39;，可以避免此类错误发生。启用严格模式解析 JavaScript ，避免意外的全局变量。 全局变量注意事项 尽管我们讨论了一些意外的全局变量，但是仍有一些明确的全局变量产生的垃圾。它们被定义为不可回收（除非定义为空或重新分配）。尤其当全局变量用于临时存储和处理大量信息时，需要多加小心。如果必须使用全局变量存储大量数据时，确保用完以后把它设置为 null 或者重新定义。与全局变量相关的增加内存消耗的一个主因是缓存。缓存数据是为了重用，缓存必须有一个大小上限才有用。高内存消耗导致缓存突破上限，因为缓存内容无法被回收。 2. 被遗忘的计时器或回调函数在 JavaScript 中使用 setInterval 非常平常。一段常见的代码：12345678var someResource = getData();setInterval(function() &#123; var node = document.getElementById('Node'); if(node) &#123; // 处理 node 和 someResource node.innerHTML = JSON.stringify(someResource)); &#125;&#125;, 1000); 此例说明了什么：与节点或数据关联的计时器不再需要，node 对象可以删除，整个回调函数也不需要了。可是，计时器回调函数仍然没被回收（计时器停止才会被回收）。同时，someResource 如果存储了大量的数据，也是无法被回收的。 对于观察者的例子，一旦它们不再需要（或者关联的对象变成不可达），明确地移除它们非常重要。老的 IE 6 是无法处理循环引用的。如今，即使没有明确移除它们，一旦观察者对象变成不可达，大部分浏览器是可以回收观察者处理函数的。 观察者代码示例：123456var element = document.getElementById('button');function onClick(event) &#123; element.innerHTML = 'text';&#125;element.addEventListener('click', onClick); 对象观察者和循环引用注意事项 老版本的 IE 是无法检测 DOM 节点与 JavaScript 代码之间的循环引用，会导致内存泄漏。如今，现代的浏览器（包括 IE 和 Microsoft Edge）使用了更先进的垃圾回收算法，已经可以正确检测和处理循环引用了。换言之，回收节点内存时，不必非要调用 removeEventListener 了。 3. 脱离 DOM 的引用有时，保存 DOM 节点内部数据结构很有用。假如你想快速更新表格的几行内容，把每一行 DOM 存成字典（JSON 键值对）或者数组很有意义。此时，同样的 DOM 元素存在两个引用：一个在 DOM 树中，另一个在字典中。将来你决定删除这些行时，需要把两个引用都清除。1234567891011121314151617var elements = &#123; button: document.getElementById('button'), image: document.getElementById('image'), text: document.getElementById('text')&#125;;function doStuff() &#123; image.src = 'http://some.url/image'; button.click(); console.log(text.innerHTML); // 更多逻辑&#125;function removeButton() &#123; // 按钮是 body 的后代元素 document.body.removeChild(document.getElementById('button')); // 此时，仍旧存在一个全局的 #button 的引用 // elements 字典。button 元素仍旧在内存中，不能被 GC 回收。&#125; 此外还要考虑 DOM 树内部或子节点的引用问题。假如你的 JavaScript 代码中保存了表格某一个 &lt;td&gt; 的引用。将来决定删除整个表格的时候，直觉认为 GC 会回收除了已保存的&lt;td&gt;以外的其它节点。实际情况并非如此：此 &lt;td&gt;是表格的子节点，子元素与父元素是引用关系。由于代码保留了 &lt;td&gt; 的引用，导致整个表格仍待在内存中。保存 DOM 元素引用的时候，要小心谨慎。 4. 闭包闭包是 JavaScript 开发的一个关键方面：匿名函数可以访问父级作用域的变量。 代码示例：123456789101112131415var theThing = null;var replaceThing = function () &#123; var originalThing = theThing; var unused = function () &#123; if (originalThing) console.log(\"hi\"); &#125;; theThing = &#123; longStr: new Array(1000000).join('*'), someMethod: function () &#123; console.log(someMessage); &#125; &#125;;&#125;;setInterval(replaceThing, 1000); 代码片段做了一件事情：每次调用 replaceThing ，theThing 得到一个包含一个大数组和一个新闭包（someMethod）的新对象。同时，变量 unused 是一个引用 originalThing 的闭包（先前的 replaceThing 又调用了 theThing ）。思绪混乱了吗？最重要的事情是，闭包的作用域一旦创建，它们有同样的父级作用域，作用域是共享的。someMethod 可以通过 theThing 使用，someMethod 与 unused 分享闭包作用域，尽管 unused 从未使用，它引用的 originalThing 迫使它保留在内存中（防止被回收）。当这段代码反复运行，就会看到内存占用不断上升，垃圾回收器（GC）并无法降低内存占用。本质上，闭包的链表已经创建，每一个闭包作用域携带一个指向大数组的间接的引用，造成严重的内存泄漏。 参考链接：https://segmentfault.com/a/1190000000440270https://jinlong.github.io/2016/05/01/4-Types-of-Memory-Leaks-in-JavaScript-and-How-to-Get-Rid-Of-Them/","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"垃圾回收","slug":"垃圾回收","permalink":"http://www.goyth.com/tags/垃圾回收/"},{"name":"内存泄漏","slug":"内存泄漏","permalink":"http://www.goyth.com/tags/内存泄漏/"}]},{"title":"webpack 配置详解","slug":"webpackConfig","date":"2018-11-17T09:05:47.000Z","updated":"2018-11-17T15:23:47.350Z","comments":true,"path":"2018/11/17/webpackConfig/","link":"","permalink":"http://www.goyth.com/2018/11/17/webpackConfig/","excerpt":"什么是WebPackWebPack可以看做是模块打包机：它做的事情是，分析你的项目结构，找到JavaScript模块以及其它的一些浏览器不能直接运行的拓展语言（Scss，TypeScript等），并将其打包为合适的格式以供浏览器使用。","text":"什么是WebPackWebPack可以看做是模块打包机：它做的事情是，分析你的项目结构，找到JavaScript模块以及其它的一些浏览器不能直接运行的拓展语言（Scss，TypeScript等），并将其打包为合适的格式以供浏览器使用。 构建就是把源代码转换成发布到线上的可执行 JavaScrip、CSS、HTML 代码，包括如下内容。 代码转换：TypeScript 编译成 JavaScript、SCSS 编译成 CSS 等。 文件优化：压缩 JavaScript、CSS、HTML 代码，压缩合并图片等。 代码分割：提取多个页面的公共代码、提取首屏不需要执行部分的代码让其异步加载。 模块合并：在采用模块化的项目里会有很多个模块和文件，需要构建功能把模块分类合并成一个文件。 自动刷新：监听本地源代码的变化，自动重新构建、刷新浏览器。 代码校验：在代码被提交到仓库前需要校验代码是否符合规范，以及单元测试是否通过。 自动发布：更新完代码后，自动构建出线上发布代码并传输给发布系统。 构建其实是工程化、自动化思想在前端开发中的体现，把一系列流程用代码去实现，让代码自动化地执行这一系列复杂的流程。 构建给前端开发注入了更大的活力，解放了我们的生产力。 webpack核心概念 Entry：入口，Webpack 执行构建的第一步将从 Entry 开始，可抽象成输入。 Module：模块，在 Webpack 里一切皆模块，一个模块对应着一个文件。Webpack 会从配置的 Entry 开始递归找出所有依赖的模块。 Chunk：代码块，一个 Chunk 由多个模块组合而成，用于代码合并与分割。 Loader：模块转换器，用于把模块原内容按照需求转换成新内容。 Plugin：扩展插件，在 Webpack 构建流程中的特定时机注入扩展逻辑来改变构建结果或做你想要的事情。 Output：输出结果，在 Webpack 经过一系列处理并得出最终想要的代码后输出结果。 webpack基本配置安装webpack1npm install webpack webpack-cli -D 创建src目录1mkdir src 创建dist目录1mkdir dist 创建 webpack.config.js 配置文件1touch webpack.config.js webpack.config.js基本配置1234567891011const path=require('path');module.exports=&#123; entry: './src/index.js', output: &#123; path: path.resolve(__dirname,'dist'), filename:'bundle.js' &#125;, module: &#123;&#125;, plugins: [], devServer: &#123;&#125;&#125; entry：配置入口文件的地址 output：配置出口文件的地址 module：配置模块,主要用来配置不同文件的加载器 plugins：配置插件 devServer：配置开发服务器 创建index.html文件在dist目录下创建index.html文件12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div id=\"root\"&gt;&lt;/div&gt;&lt;script src=\"bundle.js\"&gt;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; webpack 详细配置配置开发服务器1npm i webpack-dev-server –D 12345678910devServer:&#123; contentBase:path.resolve(__dirname,'dist'), host:'localhost', compress:true, port:8080&#125; \"scripts\": &#123; \"build\": \"webpack --mode development\", \"dev\": \"webpack-dev-server --open --mode development \" &#125; contentBase 配置开发服务运行时的文件根目录 host：开发服务器监听的主机地址 compress 开发服务器是否启动gzip等压缩 port：开发服务器监听的端口 什么是Loader通过使用不同的Loader，Webpack可以要把不同的文件都转成JS文件,比如CSS、ES6/7、JSX等 test：匹配处理文件的扩展名的正则表达式 use：loader名称，就是你要使用模块的名称 include/exclude:手动指定必须处理的文件夹或屏蔽不需要处理的文件夹 query：为loaders提供额外的设置选项loader三种写法 支持加载css文件加载CSS文件，CSS文件有可能在node_modules里，比如bootstrap和antd1. loader12345678module: &#123; rules: [ &#123; test: /\\.css/, loader:['style-loader','css-loader'] &#125; ] &#125; 2. use 12345678module: &#123; rules: [ &#123; test: /\\.css/, use:['style-loader','css-loader'] &#125; ] &#125;, 3. use+loader 123456789101112131415module: &#123; rules: [ &#123; test: /\\.css/, include: path.resolve(__dirname,'src'), exclude: /node_modules/, use: [&#123; loader: 'style-loader', options: &#123; insertAt:'top' &#125; &#125;,'css-loader'] &#125; ]&#125; 插件在 webpack 的构建流程中，plugin 用于处理更多其他的一些构建任务模块代码转换的工作由 loader 来处理除此之外的其他任何工作都可以交由 plugin 来完成 自动产出html我们希望自动能产出HTML文件，并在里面引入产出后的资源 1npm i html-webpack-plugin -D 123456789plugins: [ new HtmlWebpackPlugin(&#123; minify: &#123; removeAttributeQuotes:true &#125;, hash: true, template: './src/index.html', filename:'index.html'&#125;)] minify 是对html文件进行压缩，removeAttrubuteQuotes是去掉属性的双引号 hash 引入产出资源的时候加上查询参数，值为哈希避免缓存 template 模版路径 支持图片手动添加图片1npm i file-loader url-loader -D file-loader 解决CSS等文件中的引入图片路径问题 url-loader 当图片小于limit的时候会把图片BASE64编码，大于limit参数的时候还是使用file-loader 进行拷贝JS中引入图片JS1234let logo=require('./images/logo.png');let img=new Image();img.src=logo;document.body.appendChild(img); webpack.config.js123456789&#123; test:/\\.(jpg|png|bmp|gif|svg|ttf|woff|woff2|eot)/, use:[ &#123; loader:'url-loader', options:&#123;limit:4096&#125; &#125; ]&#125; 在CSS中引入图片还可以在CSS文件中引入图片 CSS123456.logo&#123; width:355px; height:133px; background-image: url(./images/logo.png); background-size: cover;&#125; HTML1&lt;div class=\"logo\"&gt;&lt;/div&gt; 分离CSS因为CSS的下载和JS可以并行,当一个HTML文件很大的时候，我们可以把CSS单独提取出来加载 mini-css-extract-plugin filename 打包入口文件 chunkFilename 用来打包import(‘module’)方法中引入的模块 安装依赖模块 1npm install --save-dev mini-css-extract-plugin 配置webpack.config.js123456789101112131415161718plugins: [ //参数类似于webpackOptions.output new MiniCssExtractPlugin(&#123; filename: '[name].css', chunkFilename:'[id].css' &#125;)]module: &#123; rules: [ &#123; test: /\\.css/, include: path.resolve(__dirname,'src'), exclude: /node_modules/, use: [&#123; loader: MiniCssExtractPlugin.loader &#125;,'css-loader'] &#125; ]&#125; 压缩JS和CSS1npm i uglifyjs-webpack-plugin optimize-css-assets-webpack-plugin -D 12345678910111213141516const UglifyJsPlugin = require(\"uglifyjs-webpack-plugin\");const OptimizeCSSAssetsPlugin = require(\"optimize-css-assets-webpack-plugin\");module.exports = &#123; mode: 'development', optimization: &#123; minimizer: [ new UglifyJsPlugin(&#123; cache: true,//启动缓存 parallel: true,//启动并行压缩 //如果为true的话，可以获得sourcemap sourceMap: true // set to true if you want JS source maps &#125;), //压缩css资源的 new OptimizeCSSAssetsPlugin(&#123;&#125;) ] &#125; css和image存放单独目录 outputPath 输出路径 publicPath指定的是构建后在html里的路径 123456789101112131415161718192021222324252627output: &#123; path: path.resolve(__dirname,'dist'), filename: 'bundle.js', publicPath:'/' &#125;,module: &#123; rules: [ &#123; test:/\\.(jpg|jpeg|png|bmp|gif|svg|ttf|woff|woff2|eot)/, use:[ &#123; loader:'url-loader', options:&#123; limit: 4096, outputPath: 'images', publicPath:'/images' &#125; &#125; ] &#125; ]&#125;,plugins: [ new MiniCssExtractPlugin(&#123; filename: 'css/[name].css', chunkFilename:'css/[id].css' &#125;)] 在HTML中使用图片1npm i html-withimg-loader -D index.html1&lt;img src=\"./images/logo.png\"/&gt; webpack.config.js1234&#123; test: /\\.(html|htm)$/, use: 'html-withimg-loader'&#125; 编译less 和 sass安装less12npm i less less-loader -Dnpm i node-sass sass-loader -D 编写样式less1234@color:orange;.less-container&#123; color:@color;&#125; sass1234$color:green;.sass-container&#123; color:green;&#125; webpack.config.js12345678910111213141516&#123; test: /\\.less/, include: path.resolve(__dirname,'src'), exclude: /node_modules/, use: [&#123; loader: MiniCssExtractPlugin.loader, &#125;,'css-loader','less-loader']&#125;,&#123; test: /\\.scss/, include: path.resolve(__dirname,'src'), exclude: /node_modules/, use: [&#123; loader: MiniCssExtractPlugin.loader, &#125;,'css-loader','sass-loader']&#125; 处理CSS3属性前缀为了浏览器的兼容性，有时候我们必须加入-webkit,-ms,-o,-moz这些前缀 Trident内核：主要代表为IE浏览器, 前缀为-ms Gecko内核：主要代表为Firefox, 前缀为-moz Presto内核：主要代表为Opera, 前缀为-o Webkit内核：产要代表为Chrome和Safari, 前缀为 -webkit 1npm i postcss-loader autoprefixer -D index.css 123::placeholder &#123; color: red;&#125; postcss.config.js123module.exports=&#123; plugins:[require('autoprefixer')]&#125; webpack.config.js123456&#123; test:/\\.css$/, use:[MiniCssExtractPlugin.loader,'css-loader','postcss-loader'], include:path.join(__dirname,'./src'), exclude:/node_modules/&#125; 转义ES6/ES7/JSXBabel其实是一个编译JavaScript的平台,可以把ES6/ES7,React的JSX转义为ES5 babel-plugin-proposal-decorator安装依赖包12npm i babel-loader @babel/core @babel/preset-env @babel/preset-react -Dnpm i @babel/plugin-proposal-decorators @babel/plugin-proposal-class-properties -D decorator1234567891011//Option+Shift+Afunction readonly(target,key,discriptor) &#123; discriptor.writable=false;&#125;class Person&#123; @readonly PI=3.14;&#125;let p1=new Person();p1.PI=3.15;console.log(p1) jsconfig.json12345&#123; \"compilerOptions\": &#123; \"experimentalDecorators\": true &#125;&#125; webpack.config.js1234567891011121314&#123; test: /\\.jsx?$/, use: &#123; loader: 'babel-loader', options:&#123; \"plugins\": [ [\"@babel/plugin-proposal-decorators\", &#123; \"legacy\": true &#125;], [\"@babel/plugin-proposal-class-properties\", &#123; \"loose\" : true &#125;] ] &#125; &#125;, include: path.join(__dirname,'src'), exclude:/node_modules/&#125; babel runtimebabel 在每个文件都插入了辅助代码，使代码体积过大babel 对一些公共方法使用了非常小的辅助代码，比如 _extend默认情况下会被添加到每一个需要它的文件中。你可以引入 @babel/runtime 作为一个独立模块，来避免重复引入babel-plugin-transform-runtime12npm install --save-dev @babel/plugin-transform-runtimenpm install --save @babel/runtime .babelrc1234567891011121314&#123; \"presets\": [\"@babel/preset-env\"], \"plugins\": [ [ \"@babel/plugin-transform-runtime\", &#123; \"corejs\": false, \"helpers\": true, \"regenerator\": true, \"useESModules\": true &#125; ] ]&#125; webpack打包的时候，会自动优化重复引入公共方法的问题 ESLint校验代码格式规范1npm install eslint eslint-loader babel-eslint --D .eslintrc.js12345678910111213141516171819module.exports = &#123; root: true, //指定解析器选项 parserOptions: &#123; sourceType: 'module' &#125;, //指定脚本的运行环境 env: &#123; browser: true, &#125;, // 启用的规则及其各自的错误级别 rules: &#123; \"indent\": [\"error\", 4],//缩进风格 \"quotes\": [\"error\", \"double\"],//引号类型 \"semi\": [\"error\", \"always\"],//关闭语句强制分号结尾 \"no-console\": \"error\",//禁止使用console \"arrow-parens\": 0 //箭头函数用小括号括起来 &#125;&#125; 12345678910module: &#123; //配置加载规则 rules: [ &#123; test: /\\.js$/, loader: 'eslint-loader', enforce: \"pre\", include: [path.resolve(__dirname, 'src')], // 指定检查的目录 options: &#123; fix: true &#125; // 这里的配置项参数将会被传递到 eslint 的 CLIEngine &#125;, 如何调试打包后的代码webpack通过配置可以自动给我们source maps文件，map文件是一种对应编译文件和源文件的方法 source-map把映射文件生成到单独的文件，最完整最慢 cheap-module-source-map 在一个单独的文件中产生一个不带列映射的Map eval-source-map 使用eval打包源文件模块,在同一个文件中生成完整sourcemap cheap-module-eval-source-map sourcemap和打包后的JS同行显示，没有映射列1devtool:'eval-source-map' 打包第三方类库直接引入12import _ from 'lodash';alert(_.join(['a','b','c'],'@')); 插件引入 _ 函数会自动添加到当前模块的上下文，无需显示声明123new webpack.ProvidePlugin(&#123; _:'lodash'&#125;) 没有全局的$函数，所以导入依赖全局变量的插件依旧会失败 expose-loader不需要任何其他的插件配合，只要将下面的代码添加到所有的loader之前123456require(\"expose-loader?libraryName!./file.js\");&#123; test: require.resolve(\"jquery\"), loader: \"expose-loader?jQuery\"&#125;require(\"expose-loader?$!jquery\"); externals如果我们想引用一个库，但是又不想让webpack打包，并且又不影响我们在程序中以CMD、AMD或者window/global全局等方式进行使用，那就可以通过配置externals123456const jQuery = require(\"jquery\");import jQuery from 'jquery';externals: &#123; jquery: 'jQuery'//如果要在浏览器中运行，那么不用添加什么前缀，默认设置就是global&#125;,module: &#123;&#125; watch当代码发生修改后可以自动重新编译123456watch: true,watchOptions: &#123; ignored: /node_modules/, //忽略不用监听变更的目录 poll:1000, //每秒询问的文件变更的次数 aggregateTimeout: 500, //防止重复保存频繁重新编译,500毫秒内重复保存不打包&#125; webpack定时获取文件的更新时间，并跟上次保存的时间进行比对，不一致就表示发生了变化,poll就用来配置每秒问多少次当检测文件不再发生变化，会先缓存起来，等待一段时间后之后再通知监听者，这个等待时间通过aggregateTimeout配置webpack只会监听entry依赖的文件我们需要尽可能减少需要监听的文件数量和检查频率，当然频率的降低会导致灵敏度下降 添加商标1new webpack.BannerPlugin('Garmin'), 拷贝静态文件有时项目中没有引用的文件也需要打包到目标目录12345npm i copy-webpack-plugin -Dnew CopyWebpackPlugin([&#123; from: path.resolve(__dirname,'src/assets'),//静态资源目录源地址 to:path.resolve(__dirname,'dist/assets') //目标地址，相对于output的path目录&#125;]) 打包前先清空输出目录1npm i clean-webpack-plugin -D 1new CleanWebpackPlugin([path.resolve(__dirname,'dist')]) 服务器代理如果你有单独的后端开发服务器 API，并且希望在同域名下发送 API 请求 ，那么代理某些 URL 会很有用。 不修改路径12345//请求到 /api/users 现在会被代理到请求 http://localhost:3000/api/users。proxy: &#123; \"/api\": 'http://localhost:3000'&#125; 修改路径123456proxy: &#123; \"/api\": &#123; target: 'http://localhost:3000', pathRewrite:&#123;\"^/api\":\"\"&#125; &#125; &#125; before afterbefore 在 webpack-dev-server 静态资源中间件处理之前，可以用于拦截部分请求返回特定内容，或者实现简单的数据 mock。12345before(app)&#123; app.get('/api/users', function(req, res) &#123; res.json([&#123;id:1,name:'zfpx1'&#125;]) &#125;)&#125; webpack-dev-middlewarewebpack-dev-middleware就是在 Express 中提供 webpack-dev-server 静态服务能力的一个中间件1npm install webpack-dev-middleware --save-dev 123456789const express = require('express');const app = express();const webpack = require('webpack');const webpackDevMiddleware = require('webpack-dev-middleware');const webpackOptions = require('./webpack.config');webpackOptions.mode = 'development';const compiler = webpack(webpackOptions);app.use(webpackDevMiddleware(compiler, &#123;&#125;));app.listen(3000); webpack-dev-server 的好处是相对简单，直接安装依赖后执行命令即可而使用webpack-dev-middleware的好处是可以在既有的 Express 代码基础上快速添加 webpack-dev-server 的功能，同时利用 Express 来根据需要添加更多的功能，如 mock 服务、代理 API 请求等 resolve解析extensions指定extension之后可以不用在require或是import的时候加文件扩展名,会依次尝试添加扩展名进行匹配123resolve: &#123; extensions: [\".js\",\".jsx\",\".json\",\".css\"]&#125;, alias配置别名可以加快webpack查找模块的速度 每当引入bootstrap模块的时候，它会直接引入bootstrap,而不需要从node_modules文件夹中按模块的查找规则查找123456const bootstrap = path.resolve(__dirname,'node_modules/_bootstrap@3.3.7@bootstrap/dist/css/bootstrap.css');resolve: &#123; alias:&#123; \"bootstrap\":bootstrap &#125;&#125;, modules对于直接声明依赖名的模块（如 react ），webpack 会类似 Node.js 一样进行路径搜索，搜索node_modules目录这个目录就是使用resolve.modules字段进行配置的 默认配置123resolve: &#123;modules: ['node_modules'],&#125; 如果可以确定项目内所有的第三方依赖模块都是在项目根目录下的 node_modules 中的话123resolve: &#123;modules: [path.resolve(__dirname, 'node_modules')],&#125; mainFields默认情况下package.json 文件则按照文件中 main 字段的文件名来查找文件123456resolve: &#123; // 配置 target === \"web\" 或者 target === \"webworker\" 时 mainFields 默认值是： mainFields: ['browser', 'module', 'main'], // target 的值为其他时，mainFields 默认值为： mainFields: [\"module\", \"main\"],&#125; mainFiles当目录下没有 package.json 文件时，我们说会默认使用目录下的 index.js 这个文件，其实这个也是可以配置的123resolve: &#123; mainFiles: ['index'], // 你可以添加其他默认使用的文件名&#125;, resolveLoaderresolve.resolveLoader用于配置解析 loader 时的 resolve 配置,默认的配置：1234567module.exports = &#123; resolveLoader: &#123; modules: [ 'node_modules' ], extensions: [ '.js', '.json' ], mainFields: [ 'loader', 'main' ] &#125;&#125;; noParsemodule.noParse 字段，可以用于配置哪些模块文件的内容不需要进行解析不需要解析依赖（即无依赖） 的第三方大型类库等，可以通过这个字段来配置，以提高整体的构建速度12345678910module.exports = &#123;// ... module: &#123; noParse: /jquery|lodash/, // 正则表达式 // 或者使用函数 noParse(content) &#123; return /jquery|lodash/.test(content) &#125;, &#125;&#125; 使用 noParse 进行忽略的模块文件中不能使用 import、require、define 等导入机制 DefinePluginDefinePlugin创建一些在编译时可以配置的全局常量123456789101112new webpack.DefinePlugin(&#123; PRODUCTION: JSON.stringify(true), VERSION: \"1\", EXPRESSION: \"1+2\", COPYRIGHT: &#123; AUTHOR: JSON.stringify(\"珠峰培训\") &#125;&#125;)console.log(PRODUCTION);console.log(VERSION);console.log(EXPRESSION);console.log(COPYRIGHT); 如果配置的值是字符串，那么整个字符串会被当成代码片段来执行，其结果作为最终变量的值如果配置的值不是字符串，也不是一个对象字面量，那么该值会被转为一个字符串，如 true，最后的结果是 ‘true’如果配置的是一个对象字面量，那么该对象的所有 key 会以同样的方式去定义的结果是 'true'123456### IgnorePluginIgnorePlugin用于忽略某些特定的模块，让 webpack 不把这些指定的模块打包进去```jsimport moment from &apos;moment&apos;;console.log(moment);new webpack.IgnorePlugin(/^\\.\\/locale/,/moment$/) 第一个是匹配引入模块路径的正则表达式 第二个是匹配模块的对应上下文，即所在目录名区分环境变量 日常的前端开发工作中，一般都会有两套构建环境 一套开发时使用，构建结果用于本地开发调试，不进行代码压缩，打印 debug 信息，包含 sourcemap 文件 一套构建后的结果是直接应用于线上的，即代码都是压缩后，运行时不打印 debug 信息，静态文件不包括 sourcemap webpack 4.x 版本引入了 mode 的概念当你指定使用 production mode 时，默认会启用各种性能优化的功能，包括构建结果优化以及 webpack 运行性能优化而如果是 development mode 的话，则会开启 debug 工具，运行时打印详细的错误信息，以及更加快速的增量编译构建环境差异 生产环境 可能需要分离 CSS 成单独的文件，以便多个页面共享同一个 CSS 文件 需要压缩 HTML/CSS/JS 代码 需要压缩图片 开发环境 需要生成 sourcemap 文件 需要打印 debug 信息 需要 live reload 或者 hot reload 的功能…获取mode参数1npm install --save-dev optimize-css-assets-webpack-plugin 1234567891011121314const UglifyJSPlugin = require('webpack/lib/optimize/UglifyJsPlugin');const OptimizeCssAssetsPlugin = require('optimize-css-assets-webpack-plugin');module.exports=(env,argv) =&gt; (&#123; optimization: &#123; minimizer: argv.mode == 'production'?[ new UglifyJSplugin(&#123; cache: true,//启用缓存 parallel: true,// 使用多进程运行改进编译速度 sourceMap:true//生成sourceMap映射文件 &#125;), new OptimizeCssAssetsWebpackPlugin(&#123;&#125;) ]:[] &#125;&#125;) 封装log方法webpack 时传递的 mode 参数，是可以在我们的应用代码运行时，通过 process.env.NODE_ENV 这个变量获取12345export default function log(...args) &#123; if (process.env.NODE_ENV == 'development') &#123; console.log.apply(console,args); &#125;&#125; 拆分配置可以把 webpack 的配置按照不同的环境拆分成多个文件，运行时直接根据环境变量加载对应的配置即可 webpack.base.js：基础部分，即多个文件中共享的配置 webpack.development.js：开发环境使用的配置 webpack.production.js：生产环境使用的配置 webpack.test.js：测试环境使用的配置… webpack-merge12345678const &#123; smart &#125; = require('webpack-merge')const webpack = require('webpack')const base = require('./webpack.base.js')module.exports = smart(base, &#123; module: &#123; rules: [], &#125;&#125;) 多入口有时候我们的页面可以不止一个HTML页面，会有多个页面，所以就需要多入口123456789101112131415161718192021222324252627282930313233const path=require('path');const HtmlWebpackPlugin=require('html-webpack-plugin');module.exports=&#123; entry: &#123; index: './src/index.js', login: './src/login.js' &#125;, output: &#123; path: path.resolve(__dirname, 'dist'), filename: '[name].[hash].js', publicPath: '/' &#125;, plugins: [ new HtmlWebpackPlugin(&#123; minify: &#123; removeAttributeQuotes: true &#125;, hash: true, template: './src/index.html', chunks: ['index'], filename: 'index.html' &#125;), new HtmlWebpackPlugin(&#123; minify: &#123; removeAttributeQuotes: true &#125;, hash: true, chunks: ['login'], template: './src/login.html', filename: 'login.html' &#125;) ],&#125;","categories":[{"name":"webpack","slug":"webpack","permalink":"http://www.goyth.com/categories/webpack/"}],"tags":[{"name":"webpack","slug":"webpack","permalink":"http://www.goyth.com/tags/webpack/"}]},{"title":"MongoDB 知识点梳理(二)","slug":"mongodb2","date":"2018-10-13T13:47:00.000Z","updated":"2018-10-14T04:45:10.128Z","comments":true,"path":"2018/10/13/mongodb2/","link":"","permalink":"http://www.goyth.com/2018/10/13/mongodb2/","excerpt":"MongoDB通过配置项启动数据库启动服务器1mongod --config mongo.conf 启动客户端1mongo --port 50000","text":"MongoDB通过配置项启动数据库启动服务器1mongod --config mongo.conf 启动客户端1mongo --port 50000 参数 含义 –dbpath 指定数据库文件的目录 –port 端口 默认是27017 28017 –fork 以后台守护的方式进行启动 –logpath 指定日志文件输出路径 –config 指定一个配置文件 –auth 以安全方式启动数据库，默认不验证 mongo.conf123dbpath=/Users/demon/coding/mongo/datalogpath=/Users/demon/coding/mongo/logport=50000 导入导出数据这命令是保存成了文件格式 mongoimport 导出数据 mongoexport 导入数据 参数 含义 -h [ –host ] 连接的数据库 –port 端口号 -u 用户名 -p 密码 -d 导出的数据库 -d 导出的数据库 -c 指定导出的集合 -o 导出的文件存储路径 -q 进行过滤 准备数据1234567use school;var students = [];for(var i=1;i&lt;=10;i++)&#123; students.push(&#123;name:'luke'+i,age:i&#125;);&#125;db.students.insert(students);db.students.find(); 备份记录1mongoexport -h 127.0.0.1 --port 50000 -d school -c students -o stu.json 删除记录12&gt; db.students.remove(&#123;&#125;);WriteResult(&#123; \"nRemoved\" : 10 &#125;) 导入记录12mongoimport --port 50000 --db school --collection students --filestu.json 备份与恢复mongodump在Mongodb中我们使用mongodump命令来备份MongoDB数据。该命令可以导出所有数据到指定目录中。1mongodump -h dbhost -d dbname -o dbdirectory -h MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d 需要备份的数据库实例，例如：test -o 备份的数据存放位置 1mongodump -h 127.0.0.1 --port 50000 -d school -o data.dmp mongorestoremongodb使用 mongorestore 命令来恢复备份的数据。 –host MongoDB所在服务器地址 –db -d 需要恢复的数据库实例 最后的一个参数，设置备份数据所在位置 12mongorestore -h 127.0.0.1 --port 50000 data.dmpmongorestore -h 127.0.0.1 --port 50000 -d school data.bmp/school Mongodump可以backup整个数据库，而mongoexport要对每个collection进行操作，最主要的区别也是选择的标准是mongoexport输出的JSON比Mongodump的BSON可读性更高，进而可以直接对JSON文件进行操作然后还原数据（BSON转换JSON存在潜在兼容问题）。 锁定和解锁数据库为了数据的完整性和一致性，导出前要先锁定写入，导出后再解锁。12345678910&gt; use admin;switched to db admin&gt; db.runCommand(&#123;fsync:1,lock:1&#125;);&#123; \"info\" : \"now locked against writes, use db.fsyncUnlock() to unlock\", \"seeAlso\" : \"http://dochub.mongodb.org/core/fsynccommand\", \"ok\" : 1&#125;&gt; db.fsyncUnlock();&#123; \"ok\" : 1, \"info\" : \"unlock completed\" &#125; 用户管理查看角色1show roles; 内置角色 数据库用户角色：read、readWrite； 数据库管理角色：dbAdmin、dbOwner、userAdmin; 集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManage； 备份恢复角色：backup、restore； 所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase 超级用户角色：root 内部角色：__system 创建用户的方法12345678910&gt; db.createUser(&#123;user:'luke2',pwd:'123456',roles:[&#123;role:'read',db:'school'&#125;]&#125;);Successfully added user: &#123; \"user\" : \"luke2\", \"roles\" : [ &#123; \"role\" : \"read\", \"db\" : \"school\" &#125; ]&#125; 查看用户的权限1234567891011121314&gt; db.runCommand(&#123;usersInfo:'luke2',showPrivileges:true&#125;);&#123; \"users\" : [ &#123; \"_id\" : \"admin.luke2\", \"user\" : \"luke2\", \"db\" : \"admin\", \"roles\" : [ &#123; \"role\" : \"read\", \"db\" : \"school\" &#125; ]&#125; 数据库高级命令准备数据123456789var students = [ &#123;name:'luke1',home:'北京',age:1&#125;, &#123;name:'luke2',home:'北京',age:2&#125;, &#123;name:'luke3',home:'北京',age:3&#125;, &#123;name:'luke4',home:'广东',age:1&#125;, &#123;name:'luke5',home:'广东',age:2&#125;, &#123;name:'luke6',home:'广东',age:3&#125;]db.students.insert(students); count查看记录数1db.students.find().count(); 查找不重复的值 distinct123db.runCommand(&#123;distinct:'students',key:'home'&#125;).values;//[ \"北京\", \"广东\" ] group 分组12345678910db.runCommand(&#123; group:&#123; ns:集合名称， key:分组的键, initial:初始值, $reduce:分解器 condition:条件, finalize:完成时的处理器 &#125;&#125;); 按城市分组，求每个城市里符合条件的人的年龄总和1234567891011121314db.runCommand(&#123; group:&#123; ns:'students', key:&#123;home:true&#125;, initial:&#123;total:0&#125;, $reduce:function(doc,result)&#123; result.total += doc.age; &#125;, condition:&#123;age:&#123;$gt:1&#125;&#125;, finalize:function(result)&#123; result.desc = '本城市的总年龄为'+result.total; &#125; &#125;&#125;); 删除集合1db.runCommand(&#123;drop:'students'&#125;); 固定集合MongoDB 固定集合（Capped Collections）是性能出色且有着固定大小的集合，对于大小固定，我们可以想象其就像一个环形队列，当集合空间用完后，再插入的元素就会覆盖最初始的头部的元素！ firstinfirstout 特性 没有索引 插入和查询速度速度非常快 不需要重新分配空间 特别适合存储日志创建固定集合 我们通过createCollection来创建一个固定集合，且capped选项设置为true： 还可以指定文档个数,加上max:1000属性： 判断集合是否为固定集合: db.logs.isCapped() size 是整个集合空间大小，单位为【KB】 max 是集合文档个数上线，单位是【个】 如果空间大小到达上限，则插入下一个文档时，会覆盖第一个文档；如果文档个数到达上限，同样插入下一个文档时，会覆盖第一个文档。两个参数上限判断取的是【与】的逻辑。 capped 封顶的1db.createCollection('logs',&#123;size:50,max:5,capped:true&#125;); 非固定集合转为固定集合1db.runCommand(&#123;convertToCapped:\"logs\",size:5&#125;); 索引 索引通常能够极大的提高查询的效率，如果没有索引，MongoDB在读取数据时必须扫描集合中的每个文件并选取那些符合查询条件的记录。 这种扫描全集合的查询效率是非常低的，特别在处理大量的数据时，查询可以要花费几十秒甚至几分钟，这对网站的性能是非常致命的。 索引是特殊的数据结构，索引存储在一个易于遍历读取的数据集合中，索引是对数据库表中一列或多列的值进行排序的一种结构 使用索引，方便范围查询和匹配查询。 createIndex() 方法MongoDB使用 createIndex() 方法来创建索引。 注意在 3.0.0 版本前创建索引方法为 db.collection.ensureIndex()，之后的版本使用了 db.collection.createIndex() 方法，ensureIndex() 还能用，但只是 createIndex() 的别名。 语法createIndex()方法基本语法格式如下所示：1db.collection.createIndex(keys, options) 语法中 Key 值为你要创建的索引字段，1 为指定按升序创建索引，如果你想按降序来创建索引指定为 -1 即可。 实例1db.col.createIndex(&#123;\"title\":1&#125;) createIndex() 方法中你也可以设置使用多个字段创建索引（关系型数据库中称作复合索引）。 1db.col.createIndex(&#123;\"title\":1,\"description\":-1&#125;) 指定使用的索引1db.students.find(&#123;name:'zfpx299999',age:299999&#125;).hint(&#123;name:1&#125;).explain(true); 创建唯一索引并删除重复记录1db.person.ensureIndex(&#123; \"name\" : -1 &#125;,&#123; \"name\" : \"indexname\", \"unique\" : true,dropDups:true &#125;) 删除索引123db.students.dropIndex('namedIndex');//删除指定的索引db.students.dropIndex('*');db.runCommand(&#123;dropIndexes:\"students\",index:\"namedIndex\"&#125;);//删除所有的索引 在后台创建索引1db.students.ensureIndex(&#123;name:1&#125;,&#123;name:'nameIndex',unique:true,background:true&#125;); 过期索引在一定的时间后会过期，过期后相应数据数据被删除,比如 session、日志、缓存和临时文件123db.stus.insert(&#123;time:new Date()&#125;);db.stus.ensureIndex(&#123;time:1&#125;,&#123;expireAfterSeconds:10&#125;);db.stus.find(); 索引字段的值必须Date对象，不能是其它类型比如时间戳 删除时间不精确，每60秒跑一次。删除也要时间，所以有误差。全文索引大篇幅的文章中搜索关键词,MongoDB为我们提供了全文索引12345678910db.article.insert(&#123;content:'I am a gir'&#125;);db.article.insert(&#123;content:'I am a boy'&#125;);$text:表示要在全文索引中查东西$search:后边跟查找的内容, 默认全部匹配db.article.find(&#123;$text:&#123;$search:'boy'&#125;&#125;);db.article.find(&#123;$text:&#123;$search:'girl'&#125;&#125;);db.article.find(&#123;$text:&#123;$search:'boy girl'&#125;&#125;);//多次查找，多个关键字为或的关系db.article.find(&#123;$text:&#123;$search:\"a b\"&#125;&#125;); db.article.find(&#123;$text:&#123;$search:\"boy -girl\"&#125;&#125;); // -表示取消db.article.find(&#123;$text:&#123;$search:\"a \\\"coco cola\\\" b \"&#125;&#125;); //支持转义符的,用\\斜杠来转义 索引使用的注意事项 1为正序 -1为倒序 索引虽然可以提升查询性能，但会降低插件性能，对于插入多查询少不要创索引 数据量不大时不需要使用索引。性能的提升并不明显，反而大大增加了内存和硬盘的消耗。 查询数据超过表数据量30%时，不要使用索引字段查询 排序工作的时候可以建立索引以提高排序速度 数字索引，要比字符串索引快的多 MongoDB 复制（副本集）MongoDB复制是将数据同步在多个服务器的过程。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。复制还允许您从硬件故障和服务中断中恢复数据。 MongoDB复制原理mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。mongodb各个节点常见的搭配方式为：一主一从、一主多从。主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。 流程 一台活跃服务器和二个备份服务器 当活跃服务器出现故障，这时集群根据权重算法推选出出活跃服务器 当原来的主服务器恢复后又会变成从服务器 配置副本集A服务器123dbpath=E:\\repl\\repl1port=2001replSet=group B服务器123dbpath=E:\\repl\\repl2port=2002replSet=group C服务器123dbpath=E:\\repl\\repl3port=2003replSet=group 初始化副本集rs.initiate() 启动一个新的副本集rs.conf() 查看副本集的配置rs.status() 命令123456789101112use admin;var conf=&#123; \"_id\" : \"group\", \"members\" : [ &#123; \"_id\" : 0, \"host\" : \"127.0.0.1:2001\" &#125;, &#123; \"_id\" : 1, \"host\" : \"127.0.0.1:2002\" &#125;, &#123; \"_id\" : 2, \"host\" : \"127.0.0.1:2003\" &#125; ]&#125;rs.initiate(conf);rs.status(); 高级参数 standard 常规节点 参与投票有可能成为活跃节点 passive 副本节点 参与投票，但不能成为活跃节点 arbiter 仲裁节点 只参与投票，不复制节点，也不能成为活跃节点 priority 0到1000之间，0代表是副本节点，1到1000是常规节点 arbiterOnly:true 仲裁节点读写分离操作一般情况下作为副本节点是不能进行数据库操作的，但是在读取密集的系统中读写分离是必要的1rs.slaveOk(); Oplog它被存储在本地数据库local中，会记录每一个操作。 如果希望在故障恢复的时候尽可能更多，可以把这个size设置的大一点123--oplogSize 1024use local; db.oplog.rs.find().limit(2); MongoDB的副本集与我们常见的主从有所不同，主从在主机宕机后所有服务将停止，而副本集在主机宕机后，副本会接管主节点成为主节点，不会出现宕机的情况。 MongoDB 分片分片在Mongodb里面存在另一种集群，就是分片技术,可以满足MongoDB数据量大量增长的需求。 当MongoDB存储海量的数据时，一台机器可能不足以存储数据，也可能不足以提供可接受的读写吞吐量。这时，我们就可以通过在多台机器上分割数据，使得数据库系统能存储和处理更多的数据。 为什么使用分片 复制所有的写入操作到主节点 延迟的敏感数据会在主节点查询 单个副本集限制在12个节点 当请求量巨大时会出现内存不足。 本地磁盘不足 垂直扩展价格昂贵 MongoDB分片下图展示了在MongoDB中使用分片集群结构分布： 上图中主要有如下所述三个主要组件： Shard:用于存储实际的数据块，实际生产环境中一个shard server角色可由几台机器组个一个replica set承担，防止主机单点故障 Config Server:mongod实例，存储了整个 ClusterMetadata，其中包括 chunk信息。 Query Routers:前端路由，客户端由此接入，且让整个集群看上去像单一数据库，前端应用可以透明使用。 分片实例分片结构端口分布如下：123456Shard Server 1：27020Shard Server 2：27021Shard Server 3：27022Shard Server 4：27023Config Server ：27100Route Process：40000 步骤一：启动Shard Server12345678[root@100 /]# mkdir -p /www/mongoDB/shard/s0[root@100 /]# mkdir -p /www/mongoDB/shard/s1[root@100 /]# mkdir -p /www/mongoDB/shard/s2[root@100 /]# mkdir -p /www/mongoDB/shard/s3[root@100 /]# mkdir -p /www/mongoDB/shard/log[root@100 /]# /usr/local/mongoDB/bin/mongod --port 27020 --dbpath=/www/mongoDB/shard/s0 --logpath=/www/mongoDB/shard/log/s0.log --logappend --fork....[root@100 /]# /usr/local/mongoDB/bin/mongod --port 27023 --dbpath=/www/mongoDB/shard/s3 --logpath=/www/mongoDB/shard/log/s3.log --logappend --fork 步骤二： 启动Config Server12[root@100 /]# mkdir -p /www/mongoDB/shard/config[root@100 /]# /usr/local/mongoDB/bin/mongod --port 27100 --dbpath=/www/mongoDB/shard/config --logpath=/www/mongoDB/shard/log/config.log --logappend --fork 注意：这里我们完全可以像启动普通mongodb服务一样启动，不需要添加—shardsvr和configsvr参数。因为这两个参数的作用就是改变启动端口的，所以我们自行指定了端口就可以。 步骤三： 启动Route Process1/usr/local/mongoDB/bin/mongos --port 40000 --configdb localhost:27100 --fork --logpath=/www/mongoDB/shard/log/route.log --chunkSize 500 mongos启动参数中，chunkSize这一项是用来指定chunk的大小的，单位是MB，默认大小为200MB. 步骤四： 配置Sharding 接下来，我们使用MongoDB Shell登录到mongos，添加Shard节点123456789101112[root@100 shard]# /usr/local/mongoDB/bin/mongo admin --port 40000MongoDB shell version: 2.0.7connecting to: 127.0.0.1:40000/adminmongos&gt; db.runCommand(&#123; addshard:\"localhost:27020\" &#125;)&#123; \"shardAdded\" : \"shard0000\", \"ok\" : 1 &#125;......mongos&gt; db.runCommand(&#123; addshard:\"localhost:27029\" &#125;)&#123; \"shardAdded\" : \"shard0009\", \"ok\" : 1 &#125;mongos&gt; db.runCommand(&#123; enablesharding:\"test\" &#125;) #设置分片存储的数据库&#123; \"ok\" : 1 &#125;mongos&gt; db.runCommand(&#123; shardcollection: \"test.log\", key: &#123; id:1,time:1&#125;&#125;)&#123; \"collectionsharded\" : \"test.log\", \"ok\" : 1 &#125; 步骤五： 程序代码内无需太大更改，直接按照连接普通的mongo数据库那样，将数据库连接接入接口40000","categories":[{"name":"Database","slug":"Database","permalink":"http://www.goyth.com/categories/Database/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://www.goyth.com/tags/MongoDB/"}]},{"title":"MongoDB 知识点梳理（一）","slug":"mongodb","date":"2018-10-12T13:12:45.000Z","updated":"2018-12-02T08:39:29.398Z","comments":true,"path":"2018/10/12/mongodb/","link":"","permalink":"http://www.goyth.com/2018/10/12/mongodb/","excerpt":"什么是MongoDBMongoDB是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。","text":"什么是MongoDBMongoDB是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB 基本概念数据库MongoDB的单个实例可以容纳多个独立的数据库，每一个都有自己的集合和权限，不同的数据库也放置在不同的文件中。 “show dbs” 命令可以显示所有数据的列表。 12345678$ ./mongoMongoDB shell version: 3.0.6connecting to: test&gt; show dbsadmin 0.000GBlocal 0.078GBtest 0.078GB&gt; 执行 “db” 命令可以显示当前数据库对象或集合。 123456$ ./mongoMongoDB shell version: 3.0.6connecting to: test&gt; dbtest&gt; 运行”use”命令，可以连接到一个指定的数据库。 12345&gt; use localswitched to db local&gt; dblocal&gt; 数据库名可以是满足以下条件的任意UTF-8字符串。 不能是空字符串（””)。 不得含有’ ‘（空格)、.、$、/、\\和\\0 (空字符)。 应全部小写。 最多64字节。 有一些数据库名是保留的，可以直接访问这些有特殊作用的数据库。 admin： 从权限的角度来看，这是”root”数据库。要是将一个用户添加到这个数据库，这个用户自动继承所有数据库的权限。一些特定的服务器端命令也只能从这个数据库运行，比如列出所有的数据库或者关闭服务器。local: 这个数据永远不会被复制，可以用来存储限于本地单台服务器的任意集合config: 当Mongo用于分片设置时，config数据库在内部使用，用于保存分片的相关信息。 文档文档是一组键值(key-value)对(即BSON)。MongoDB 的文档不需要设置相同的字段，并且相同的字段不需要相同的数据类型，这与关系型数据库有很大的区别，也是 MongoDB 非常突出的特点。 RDBMS（关系型数据库）与MongoDB对应术语 RDBMS MongoDB 数据库 数据库 表格 集合 行 文档 列 字段 表联合 嵌入文档 主键 主键 (MongoDB 提供了 key 为 _id ) 需要注意的是： 文档中的键/值对是有序的。 文档中的值不仅可以是在双引号里面的字符串，还可以是其他几种数据类型（甚- 至可以是整个嵌入的文档)。 MongoDB区分类型和大小写。 MongoDB的文档不能有重复的键。 文档的键是字符串。除了少数例外情况，键可以使用任意UTF-8字符。 文档键命名规范： 键不能含有\\0 (空字符)。这个字符用来表示键的结尾。 .和$有特别的意义，只有在特定环境下才能使用。 以下划线”_”开头的键是保留的(不是严格要求的)。 集合集合就是 MongoDB 文档组，类似于 RDBMS （关系数据库管理系统：Relational Database Management System)中的表格。集合存在于数据库中，集合没有固定的结构，这意味着你在对集合可以插入不同格式和类型的数据，但通常情况下我们插入集合的数据都会有一定的关联性。 MongoDB 数据类型 数据类型 描述 String 字符串。存储数据常用的数据类型。在 MongoDB 中，UTF-8 编码的字符串才是合法的。 Integer 整型数值。用于存储数值。根据你所采用的服务器，可分为 32 位或 64 位。 Boolean 布尔值。用于存储布尔值（真/假）。 Double 双精度浮点值。用于存储浮点值。 Min/Max keys 将一个值与 BSON（二进制的 JSON）元素的最低值和最高值相对比。 Array 用于将数组或列表或多个值存储为一个键。 Timestamp 时间戳。记录文档修改或添加的具体时间。 Object 用于内嵌文档。 Null 用于创建空值。 Symbol 符号。该数据类型基本上等同于字符串类型，但不同的是，它一般用于采用特殊符号类型的语言。 Date 日期时间。用 UNIX 时间格式来存储当前日期或时间。你可以指定自己的日期时间：创建 Date 对象，传入年月日信息。 Object ID 对象 ID。用于创建文档的 ID。 Binary Data 二进制数据。用于存储二进制数据。 Code 代码类型。用于在文档中存储 JavaScript 代码。 Regular expression 正则表达式类型。用于存储正则表达式。 ObjectIdObjectId 类似唯一主键，可以很快的去生成和排序，包含 12 bytes，含义是： 前 4 个字节表示创建 unix 时间戳,格林尼治时间 UTC 时间，比北京时间晚了 8 个小时接下来的 3 个字节是机器标识码紧接的两个字节由进程 id 组成 PID最后三个字节是随机数 MongoDB 中存储的文档必须有一个 _id 键。这个键的值可以是任何类型的，默认是个 ObjectId 对象 由于 ObjectId 中保存了创建的时间戳，所以你不需要为你的文档保存时间戳字段，你可以通过 getTimestamp 函数来获取文档的创建时间: 123&gt; ObjectId().getTimestamp()ISODate(\"2018-10-12T14:07:33Z\")&gt; 数据库操作\b创建数据库1use database_name // database_name代表数据库的名字 如果数据库不存在，则创建数据库，否则切换到指定数据库。 \b查看\b数据库查看所有数据库1show dbs 查看当前数据库123db// 或者db.getName() 删除数据库1db.dropDatabase() 创建集合创建一个空集合12db.createCollection(collection_Name)//collection_Name集合的名称 创建集合并插入一个文档123//collection_Name集合的名称//document要插入的文档db.collection_Name.insert(document) 插入文档insert1db.collection_name.insert(document) 参数 collection_name 集合的名字 document 插入的文档 每当插入一条新文档的时候mongodb会自动为此文档生成一个_id属性,_id一定是唯一的，用来唯一标识一个文档 _id也可以直接指定，但如果数据库中此集合下已经有此_id的话插入会失败123&gt; db.students.insert(&#123;_id:1,name:'luke',age:1&#125;);WriteResult(&#123; \"nInserted\" : 1 &#125;)&gt; db.students.insert(&#123;_id:1,name:'luke',age:1&#125;); save1db.collection_name.save(document) 参数 collection_name 集合的名字 document 插入的文档 注：如果不指定 _id 字段 save() 方法类似于 insert() 方法。如果指定 _id 字段，则会更新该 _id 的数据。 实例1234&gt; db.students.save(&#123;_id:1,name:'luke',age:1&#125;);WriteResult(&#123; \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 0 &#125;)&gt; db.students.save(&#123;_id:1,name:'luke',age:100&#125;);WriteResult(&#123; \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 &#125;) 更新文档12345678db.collection.update( &lt;query&gt;, &lt;updateObj&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt; &#125;) 参数说明 query 查询条件,指定要更新符合哪些条件的文档 updateObj 更新后的对象或指定一些更新的操作符 $set 直接指定更新后的值 $inc 在原基础上累加 $unset 删除指定的键 $push 向数组中添加元素 upsert 可选，这个参数的意思是，如果不存在符合条件的记录时是否插入updateObj. 默认是false,不插入。 multi 可选，mongodb 默认只更新找到的第一条记录，如果这个参数为true,就更新所有符合条件的记录。实例 将students集合中数据中name是luke2的值修改为luke2212&gt; db.students.update(&#123;name:'luke2'&#125;,&#123;age:300&#125;);WriteResult(&#123; \"nMatched\" : 1, \"nUpserted\" : 0, \"nModified\" : 1 &#125;) 注：如果有多条name是luke2的数据只更新一条,如果想全部更新需要指定{multi:true}的参数12db.students.update(&#123;name:'luke2'&#125;,&#123;$set:&#123;age:300&#125;&#125;,&#123;multi:true&#125;);WriteResult(&#123; \"nMatched\" : 2, \"nUpserted\" : 0, \"nModified\" : 1 &#125;) runCommand1234567891011 var modify = &#123; findAndModify:'student', query:&#123;name:'张三'&#125;, update:&#123;$set:&#123;age:100&#125;&#125;, fields:&#123;name:'1'&#125;, sort:true, new:true //返回修改后的值&#125;var result = db.runCommand(modify);printjson(result); 文档的删除remove方法是用来移除集合中的数据123456db.collection.remove( &lt;query&gt;, &#123; justOne: &lt;boolean&gt; &#125;) 参数说明 query :（可选）删除的文档的条件。 justOne : （可选）如果设为 true 或 1，则只删除匹配到的多个文档中的第一个 实例 删除worker集合里name是luke2的所有文档数据12&gt; db.students.remove(&#123;name:'luke2'&#125;);WriteResult(&#123; \"nRemoved\" : 2 &#125;) 即使匹配多条也只删除一条12&gt; db.students.remove(&#123;name:\"luke2\"&#125;,&#123;justOne:true&#125;)WriteResult(&#123; \"nRemoved\" : 1 &#125;) 查询文档find1db.collection_name.find() 参数 collection_name 集合的名字 查询students下所有的文档1db.students.find() 查询指定列1db.collection_name.find(&#123;queryWhere&#125;,&#123;key:1,key:1&#125;) 参数 collection_name 集合的名字 queryWhere 参阅查询条件操作符 key 指定要返回的列 1 表示要显示 只返回显示age列1&gt; db.students.find(&#123;&#125;,&#123;age:1&#125;); findOne查询匹配结果的第一条数据 语法1db.collection_name.findOne() 实例1db.students.findOne() $in1db.student.find(&#123;age:&#123;$in:[30,100]&#125;&#125;,&#123;name:1,age:1&#125;); $nin1db.student.find(&#123;age:&#123;$nin:[30,100]&#125;&#125;,&#123;name:1,age:1&#125;); $nin1db.student.find(&#123;age:&#123;$in:[30,100]&#125;&#125;,&#123;name:1,age:1&#125;); $not1db.student.find(&#123;age:&#123;$not:&#123;$gte:20,$lte:30&#125;&#125;&#125;); array12345678910111213//按所有元素匹配let result = db.student.find(&#123;friends:[ \"Lufy\", \"Nami2\", \"Wusopu\", \"A\" ]&#125;);//匹配一条let result = db.student.find(&#123;friends:\"A\"&#125;);//$alllet result = db.student.find(&#123;friends:&#123;$all:['A',\"Lufy\"]&#125;&#125;);//$inlet result = db.student.find(&#123;friends:&#123;$in:['A',\"Lufy\"]&#125;&#125;);//$sizelet result = db.student.find(&#123;friends:&#123;$size:4&#125;&#125;);//$slicelet result = db.student.find(&#123;friends:&#123;$size:5&#125;&#125;,&#123;name:1,friends:&#123;$slice:1&#125;&#125;);let result = db.student.find(&#123;friends:&#123;$size:5&#125;&#125;,&#123;name:1,friends:&#123;$slice:-1&#125;&#125;); where1db.student.find(&#123;$where:\"this.age&gt;30\"&#125;,&#123;name:1,age:1&#125;); cursor1234567var result = db.student.find();//while(result.hasNext())&#123;// printjson(result.next());//&#125;result.forEach(element=&gt;printjson(element)); 条件操作符条件操作符用于比较两个表达式并从mongoDB集合中获取数据 大于操作符查询age 大于 30的数据1db.students.find(&#123;age:&#123;$gt:30&#125;&#125;) 大于等于操作符查询age 3大于等于30 的数据1db.students.find(&#123;age: &#123;$gte: 30&#125;&#125;) 小于操作符查询age 小于30的数据1db.students.find(&#123;age: &#123;$lt: 30&#125;&#125;) 小于等于操作符查询age 小于等于30的数据1db.students.find(&#123;age: &#123;$lte: 30&#125;&#125;) 同时使用 $gte和$lte实例 查询age 大于等于 30 并且 age 小于等于 50 的数据1db.students.find(&#123;age: &#123;$gte: 30, $lte: 50&#125;&#125;) 等于查询age = 30的数据1db.students.find(&#123;\"age\": 30&#125;) 使用 _id进行查询实例 查询_id是 562af23062d5a57609133974 数据12&gt; db.students.find(&#123;_id:ObjectId(\"5adb666ecd738e9771638985\")&#125;);&#123; \"_id\" : ObjectId(\"5adb666ecd738e9771638985\"), \"name\" : \"zzzz\" &#125; 查询结果集的条数1db.students.find().count() 正则匹配实例 查询name里包含luke的数据1db.students.find(&#123;name:/luke/&#125;) 查询某个字段的值当中是否以另一个值开头1db.students.find(&#123;name:/^luke/&#125;) ###与和或 andfind方法可以传入多个键(key)，每个键(key)以逗号隔开1db.collection_name.find(&#123;key1:value1, key2:value2&#125;) 实例 查询name是luke并且age是1的数据1db.students.find(&#123;name:'luke',age:1&#125;) or语法1234567db.collection_name.find( &#123; $or: [ &#123;key1: value1&#125;, &#123;key2:value2&#125; ] &#125;) 实例 查询age = 30 或者 age = 50 的数据1db.students.find(&#123;$or:[&#123;age:30&#125;,&#123;age:50&#125;]&#125;) and和or联用12345678910db.collection_name.find( &#123; key1:value1, key2:value2, $or: [ &#123;key1: value1&#125;, &#123;key2:value2&#125; ] &#125;) 实例 查询 name是luke 并且 age是30 或者 age是 50 的数据1db.students.find(&#123;name:'luke',$or:[&#123;age:30&#125;,&#123;age:50&#125;]&#125;) 分页查询limit读取指定数量的数据记录1db.collectoin_name.find().limit(number) 参数 collectoin_name集合number读取的条数实例 查询前3条数据1db.students.find().limit(3) skip跳过指定数量的数据，skip方法同样接受一个数字参数作为跳过的记录条数 语法1db.collectoin_name.find().skip(number) 参数 collectoin_name集合number跳过的条数实例 查询3条以后的数据1db.students.find().skip(3) skip+limit通常用这种方式来实现分页功能 语法1db.collectoin_name.find().skip(skipNum).limit(limitNum) 参数 collectoin_name 集合名称skipNum 跳过的条数limitNum 限制返回的条数实例 查询在4-6之间的数据1db.students.find().skip(3).limit(3); sort排序sort()方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而-1是用于降序排列。 语法12db.collectoin_name.find().sort(&#123;key:1&#125;)db.collectoin_name.find().sort(&#123;key:-1&#125;) 参数 collectoin_name集合key表示字段实例 查询出并升序排序 {age:1} age表示按那个字段排序 1表示升序1db.students.find().sort(&#123;age:1&#125;)","categories":[{"name":"Database","slug":"Database","permalink":"http://www.goyth.com/categories/Database/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://www.goyth.com/tags/MongoDB/"}]},{"title":"实现一个符合Promise A+规范的Promise","slug":"promise","date":"2018-08-03T03:43:09.000Z","updated":"2018-08-03T07:04:18.375Z","comments":true,"path":"2018/08/03/promise/","link":"","permalink":"http://www.goyth.com/2018/08/03/promise/","excerpt":"Promise模拟实现一个符合Promise A+规范的promise，仅供学习其实现原理 源码地址链接 我的博客 github博客主页 Promise的详细使用方法可参考阮一峰老师的文章","text":"Promise模拟实现一个符合Promise A+规范的promise，仅供学习其实现原理 源码地址链接 我的博客 github博客主页 Promise的详细使用方法可参考阮一峰老师的文章 Promise A+规范概述promise雏形简单点说 promise 函数的参数（executor）是一个函数，这个函数有两个参数resolve和reject，这两个参数也都是函数，分别在promise成功和失败时调用。 当构建一个promise实例时，会自动调用这个函数（executor） 每个promise对象都有一个onFulfilledCallback队列和一个onRejectedCallback队列，用来分别存储成功和失败时调用的回调函数 每个promise有三种状态pending 、fulfilled、rejected，同一时刻只能处于其中一种状态，并且只能从pending 、状态转化成fulfilled状态，或者rejected状态，一旦状态发生转化就不能再被改变。 当调用resolve(value)函数时，promise的状态会从pending转化成fulfilled，并且将resolve参数中的value值赋值给此promise的value变量，promise的value被赋值后，就不能再次改变了；此时还会去取出onFulfilledCallback队列中所有的回调函数，并将此promise的value作为回调函数的参数，依次执行 当调用rejected(reason)函数时，promise的状态会从pending转化成rejected，并且将rejected(reason)函数中的reason参数赋值给此promise的reason变量，这个reason被赋值后，也是不能再次改变了；此时还会去取出onRejectedCallback队列中所有的回调函数，并将此promise的reason作为回调函数的参数，依次执行 当executor执行抛异常时捕获这个异常，并将异常的原因作为reject函数的参数，执行reject函数 根据这些我们先写一个第一版的promise 1234567891011121314151617181920212223242526272829303132function Promise(executor) &#123; const self = this; self.state = 'pending'; self.value = null; self.reason = null; self.onFulfilledCallback = []; self.onRejectedCallback = []; function resolve(value) &#123; if(self.state === 'pending')&#123; self.state = 'fulfilled'; self.value = value; self.onFulfilledCallback.foreach(fn=&gt;fn(self.value)) &#125; &#125; function reject(reason) &#123; if(self.state === 'pending')&#123; self.state = 'rejected'; self.reason = reason; self.onRejectedCallback.foreach(fn=&gt;fn(self.reason)) &#125; &#125; try&#123; executor(resolve, reject) &#125;catch(e)&#123; reject(e) &#125; &#125; promise.then 每个promise必须提供一个then方法，并且then方法包含两个参数onFulfilled 和 onRejected 这两个参数如果不是函数的话就直接忽略，并且将成功或失败的值传递给下一个then注册的回调函数及下一个then的onFulfilled 和 onRejected 当执行then函数时，如果promise的状态是pending则将then中注册的成功和失败时对应的回调函数onFulfilled 和 onRejected分别放入onFulfilledCallback队列和一个onRejectedCallback队列中 如果promise的状态是fulfilled，就直接调用onFulfilled函数，并且将此promise的value作为onFulfilled函数的第一个参数执行 如果promise的状态为rejected，就直接调用onRejected函数，并且将此promise的reason作为onRejected函数的第一个参数执行 12345678910111213Promise.prototype.then = function (onFulfilled, onRejected) &#123; const self = this; onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : val =&gt; val; onRejected = typeof onRejected === 'function' ? onRejected : err =&gt; &#123; throw err &#125;; if(self.state === 'fulfilled')&#123; onFulfilled(self.value); &#125;else if(self.state === 'rejected')&#123; onRejected(self.reason); &#125;else if(self.state === 'pending')&#123; self.onFulfilledCallback.push(onFulfilled); self.onRejectedCallback.push(onRejected); &#125;&#125; promise 链式调用 此时的promise 是不支持链式调用的，所以我们应该在then中返回一个新的promise来支持链式调用为什么是新的promise，而不是直接返回this呢？因为promise的状态一旦发生转变，就不能再次改变了，而链式调用中的then返回的promise是可以选择resolve或者reject的，所以then必须返回一个新的promise 所有的then中注册的回调函数，都应该是异步执行，标准promise的then中注册的回调函数是属于微观任务，我们这里可以用setTimeout来模拟，但是要注意的是setTimeout属于宏观任务 所有的then中注册的异步回调函数都应该放在try{}catch中执行，当执行then 中的回调函数抛出异常时，应该捕获这个异常，并将异常对象传递给reject，并调用reject 12345678910111213141516171819202122232425262728293031323334353637383940414243Promise.prototype.then = function (onFulfilled, onRejected) &#123; const self = this; return new Promise((resolve, reject) =&gt; &#123; onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : val =&gt; val; onRejected = typeof onRejected === 'function' ? onRejected : err =&gt; &#123; throw err &#125;; if(self.state === 'fulfilled')&#123; setTimeout(()=&gt;&#123; try&#123; onFulfilled(self.value); &#125;catch(e)&#123; reject(e) &#125; &#125;, 0) &#125;else if(self.state === 'rejected')&#123; setTimeout(()=&gt;&#123; try&#123; onRejected(self.reason); &#125;catch(e)&#123; reject(e) &#125; &#125;, 0) &#125;else if(self.state === 'pending')&#123; self.onFulfilledCallback.push(()=&gt;&#123; setTimeout(()=&gt;&#123; try&#123; onFulfilled(self.value); &#125;catch(e)&#123; reject(e) &#125; &#125;, 0) &#125;)); self.onRejectedCallback.push(()=&gt;&#123; setTimeout(()=&gt;&#123; try&#123; onRejected(self.reason); &#125;catch(e)&#123; reject(e) &#125; &#125;, 0) &#125;)); &#125; &#125;)&#125; 嵌套promise问题1234567891011121314151617let promise1 = new Promise((resolve, reject)=&gt;&#123; setTimeout(()=&gt;&#123; resolve(new Promise((resolve, reject)=&gt;&#123; setTimeout(()=&gt;&#123; resolve(new Promise((resolve, reject)=&gt;&#123; setTimeout(()=&gt;&#123; resolve('666') &#125;, 0) &#125;)) &#125;, 0) &#125;)) &#125;, 0)&#125;)let promise2 = promise1.then((value)=&gt;&#123; console.log(value) //666&#125;) 我们知道当调用resolve(value)时，如果resolve中的参数value是一个普通值，则会将value传递给then中注册的成功时的回调函数，并调用此回调函数。但是如果value不是一个普通值，而是一个promise的话，则会执行这个promise，如果执行这个promise得到的结果仍然为一个promise，则继续递归执行，直到最终执行结果为一个普通值，并且将这个执行结果作为第一个promise的执行结果，Promise A+ 规范定义了这个解析流程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182function resolvePromise(promise2, x, resolve, reject) &#123; if(promise2 === x) &#123; //2.3.1 If promise and x refer to the same object, reject promise with a TypeError as the reason. return reject(new TypeError('circular reference')); &#125; let called = false; // 2.3.3.3.3 If both resolvePromise and rejectPromise are called, or multiple calls to the same argument are made, the first call takes precedence, and any further calls are ignored. if(x != null &amp;&amp; (typeof x === 'object' || typeof x === 'function'))&#123; // 2.3.3 if x is an object or function, try &#123; let then = x.then; // 2.3.3.1 Let then be x.then if(typeof then === 'function')&#123; // 2.3.3.3 If then is a function, call it with x as self, first argument resolvePromise, and second argument rejectPromise, where: then.call(x, y=&gt;&#123; if(called) return; // 2.3.3.3.4.1 If resolvePromise or rejectPromise have been called, ignore it. called = true; resolvePromise(promise2, y, resolve, reject) // 2.3.3.3.1 If/when resolvePromise is called with a value y, run [[Resolve]](promise, y) &#125;, reason=&gt;&#123; if(called) return; // 2.3.3.3.4.1 If resolvePromise or rejectPromise have been called, ignore it. called = true; reject(reason) // 2.3.3.3.2 If/when rejectPromise is called with a reason r, reject promise with r. &#125;) &#125;else&#123; // 2.3.3.4 If then is not a function, fulfill promise with x. resolve(x) &#125; &#125; catch (e) &#123; // 2.3.3.2 If retrieving the property x.then results in a thrown exception e, reject promise with e as the reason. if(called) return; // 2.3.3.3.4.1 If resolvePromise or rejectPromise have been called, ignore it. called = true; reject(e) // 2.3.3.3.4.2 Otherwise, reject promise with e as the reason &#125; &#125;else&#123; // 2.3.4 If x is not an object or function, fulfill promise with x. resolve(x) &#125;&#125;Promise.prototype.then = function(onFulfilled, onRejected)&#123; const self = this; // 2.2.1 Both onFulfilled and onRejected are optional arguments: onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : value =&gt; value onRejected = typeof onRejected === 'function' ? onRejected : reason =&gt; &#123; throw reason &#125; let promise2 = new Promise(function(resolve, reject)&#123; if(self.state === PENDING)&#123; self.resolveCallback.push(()=&gt;&#123; setTimeout(() =&gt; &#123; try &#123; let x = onFulfilled(self.value) resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0) &#125;); self.rejectCallback.push(()=&gt;&#123; setTimeout(() =&gt; &#123; try &#123; let x = onRejected(self.reason) resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0); &#125;); &#125;else if(self.state === FULFILLED)&#123; // 2.2.6.1 If/when promise is fulfilled, all respective onFulfilled callbacks must execute in the order of their originating calls to then. setTimeout(() =&gt; &#123; try &#123; let x = onFulfilled(self.value) // 2.2.2.1 it must be called after promise is fulfilled, with promise’s value as its first argument. resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0); &#125;else if(self.state === REJECTED)&#123; // 2.2.6.2 If/when promise is rejected, all respective onRejected callbacks must execute in the order of their originating calls to then. setTimeout(() =&gt; &#123; try &#123; let x = onRejected(self.reason) resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0); &#125; &#125;) return promise2; // 2.2.7 then must return a promise&#125; 整理一下，最终版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117function Promise(executor) &#123; const self = this; self.state = 'pending'; self.value = null; self.reason = null; self.onFulfilledCallback = []; self.onRejectedCallback = []; function resolve(value) &#123; if(self.state === 'pending')&#123; self.state = 'fulfilled'; self.value = value; self.onFulfilledCallback.forEach(fn=&gt;fn()) &#125; &#125; function reject(reason) &#123; if(self.state === 'pending')&#123; self.state = 'rejected'; self.reason = reason; self.onRejectedCallback.forEach(fn=&gt;fn()) &#125; &#125; try&#123; executor(resolve, reject) &#125;catch(e)&#123; reject(e) &#125;&#125;function resolvePromise(promise2, x, resolve, reject) &#123; if(promise2 === x) &#123; //2.3.1 If promise and x refer to the same object, reject promise with a TypeError as the reason. return reject(new TypeError('circular reference')); &#125; let called = false; // 2.3.3.3.3 If both resolvePromise and rejectPromise are called, or multiple calls to the same argument are made, the first call takes precedence, and any further calls are ignored. if(x != null &amp;&amp; (typeof x === 'object' || typeof x === 'function'))&#123; // 2.3.3 if x is an object or function, try &#123; let then = x.then; // 2.3.3.1 Let then be x.then if(typeof then === 'function')&#123; // 2.3.3.3 If then is a function, call it with x as self, first argument resolvePromise, and second argument rejectPromise, where: then.call(x, y=&gt;&#123; if(called) return; // 2.3.3.3.4.1 If resolvePromise or rejectPromise have been called, ignore it. called = true; resolvePromise(promise2, y, resolve, reject) // 2.3.3.3.1 If/when resolvePromise is called with a value y, run [[Resolve]](promise, y) &#125;, reason=&gt;&#123; if(called) return; // 2.3.3.3.4.1 If resolvePromise or rejectPromise have been called, ignore it. called = true; reject(reason) // 2.3.3.3.2 If/when rejectPromise is called with a reason r, reject promise with r. &#125;) &#125;else&#123; // 2.3.3.4 If then is not a function, fulfill promise with x. resolve(x) &#125; &#125; catch (e) &#123; // 2.3.3.2 If retrieving the property x.then results in a thrown exception e, reject promise with e as the reason. if(called) return; // 2.3.3.3.4.1 If resolvePromise or rejectPromise have been called, ignore it. called = true; reject(e) // 2.3.3.3.4.2 Otherwise, reject promise with e as the reason &#125; &#125;else&#123; // 2.3.4 If x is not an object or function, fulfill promise with x. resolve(x) &#125;&#125;Promise.prototype.then = function(onFulfilled, onRejected)&#123; const self = this; // 2.2.1 Both onFulfilled and onRejected are optional arguments: onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : value =&gt; value onRejected = typeof onRejected === 'function' ? onRejected : reason =&gt; &#123; throw reason &#125; let promise2 = new Promise(function(resolve, reject)&#123; if(self.state === PENDING)&#123; self.resolveCallback.push(()=&gt;&#123; setTimeout(() =&gt; &#123; try &#123; let x = onFulfilled(self.value) resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0) &#125;); self.rejectCallback.push(()=&gt;&#123; setTimeout(() =&gt; &#123; try &#123; let x = onRejected(self.reason) resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0); &#125;); &#125;else if(self.state === FULFILLED)&#123; // 2.2.6.1 If/when promise is fulfilled, all respective onFulfilled callbacks must execute in the order of their originating calls to then. setTimeout(() =&gt; &#123; try &#123; let x = onFulfilled(self.value) // 2.2.2.1 it must be called after promise is fulfilled, with promise’s value as its first argument. resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0); &#125;else if(self.state === REJECTED)&#123; // 2.2.6.2 If/when promise is rejected, all respective onRejected callbacks must execute in the order of their originating calls to then. setTimeout(() =&gt; &#123; try &#123; let x = onRejected(self.reason) resolvePromise(promise2, x, resolve, reject) // 2.2.7.1 If either onFulfilled or onRejected returns a value x, run the Promise Resolution Procedure [[Resolve]](promise2, x). &#125; catch (e) &#123; reject(e) // 2.2.7.2 If either onFulfilled or onRejected throws an exception e, promise2 must be rejected with e as the reason. &#125; &#125;, 0); &#125; &#125;) return promise2; // 2.2.7 then must return a promise&#125;module.exports = Promise; 测试安装promises-aplus-tests1npm i -g promises-aplus-tests 添加测试代码12345678Promise.deferred = Promise.defer = function()&#123; let defer = &#123;&#125;; defer.promise = new Promise((resolve, reject)=&gt;&#123; defer.resolve = resolve; defer.reject = reject; &#125;) return defer;&#125; 测试命令1promises-aplus-tests promise.js 测试结果(872 passing) Promise 其他常用方法实现Promise.resolve12345Promise.resolve = function(value)&#123; return new Promise((resolve, reject)=&gt;&#123; resolve(value) &#125;)&#125; Promise.reject12345Promise.reject = function(reason)&#123; return new Promise((resolve, reject)=&gt;&#123; reject(reason) &#125;)&#125; promise.catch123Promise.prototype.catch = function(onRejected)&#123; return this.then(null, onRejected)&#125; Promise.all1234567891011121314Promise.all = function(arr)&#123; let index = 0; let result = [] return new Promise((resolve, reject)=&gt;&#123; arr.forEach((promise, i)=&gt;&#123; promise.then(val=&gt;&#123; result[i] = val if(++index === arr.length) &#123; // 由于then注册的回调函数是异步执行的，无法确定回调函数什么时候执行完成，所以必须得把判断放到回调函数中，这样才能确保所有的异步任务执行完成后在调用resolve resolve(result) &#125; &#125;, reject); &#125;) &#125;)&#125; Promise.race1234567Promise.race = function(arr)&#123; return new Promise((resolve, reject)=&gt;&#123; arr.forEach((promise, i)=&gt;&#123; promise.then(resolve, reject); &#125;) &#125;)&#125;","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"Promise","slug":"Promise","permalink":"http://www.goyth.com/tags/Promise/"}]},{"title":"HTTP知识点整理","slug":"http2","date":"2018-07-11T12:25:51.000Z","updated":"2018-12-02T08:39:10.321Z","comments":true,"path":"2018/07/11/http2/","link":"","permalink":"http://www.goyth.com/2018/07/11/http2/","excerpt":"HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议。于2015年正式发布，HTTP/2解决了HTTP1.1线头阻塞、重复建立TCP连接等问题，充分利用TCP连接的高效传输，使得网络延迟大幅下降，网络传输速度大幅提升。","text":"HTTP/2是HTTP协议自1999年HTTP 1.1发布后的首个更新，主要基于SPDY协议。于2015年正式发布，HTTP/2解决了HTTP1.1线头阻塞、重复建立TCP连接等问题，充分利用TCP连接的高效传输，使得网络延迟大幅下降，网络传输速度大幅提升。 HTTP/0.9 - 1991第一版的HTTP文档是1991年提出来的 HTTP/0.9。这是有史以来最简单的协议；它仅有一个GET方法。如果客户端要访问服务器上的一些网页，它会作出如下的简单请求：1GET /index.html 并且来自服务器的响应内容如下：12(response body)(connection closed) 也就是说，服务器会得到这个请求，然后通过HTML格式回复响应内容，且一旦响应内容发送完毕，就会关闭这个连接。归纳一下： 没有header数据块 GET方法是唯一允许的方法 必须以HTML格式响应 HTTP/1.0 - 19961996年，HTTP/1.0 诞生了，它在原版本上做出了极大的改善。不像 HTTP/0.9 仅能以HTML格式响应，HTTP/1.1 现在可以处理其他的响应格式了，例如：图像，视频文件，纯文本或其他任何的内容类型。它增加了更多的方法（即 POST 和 HEAD），请求/响应的格式也发生了改变，请求和响应中均加入了HTTP头信息，响应数据还增加了状态码标识，还介绍了字符集的支持、多部分发送、权限、缓存、内容编码等很多内容。 如下所示，这是一个通过 HTTP/1.0 请求和响应的例子： 1234GET / HTTP/1.0Host: kamranahmed.infoUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5)Accept: */* 正如你所见，客户端除了发送请求以外，它还发送了它的个人信息，要求响应类型等。而在 HTTP/0.9 中因为没有头信息，客户端是不会发送这些信息的。 上面的例子对应的服务器响应结果如下： 123456789HTTP/1.0 200 OK Content-Type: text/plainContent-Length: 137582Expires: Thu, 05 Dec 1997 16:00:00 GMTLast-Modified: Wed, 5 August 1996 15:55:28 GMTServer: Apache 0.84(response body)(connection closed) 在这个新版本中，请求和响应的头信息仍然采用 ASCII 编码方式，但具体的响应内容可以是任何类型的，例如：图像、视频、HTML、纯文本或任何其他的内容类型。因此，现在的服务器端可以向客户端发送任何内容类型的数据； HTTP/1.0的主要缺点之一是，你不能在每个连接中发送多个请求。也就是说，每当客户端要向服务器端请求东西时，它都会打开一个新的TCP连接，并且在这个单独请求完成后，该连接就会被关闭。且对于下个需求时，它必须再创建一个新的连接。为什么会如此糟糕呢？好吧，来让我们做个假设，假设你需要访问一个包含10张图片、5个样式表和5个JS文件的网页，这是一个共20项内容要请求的网页。由于服务器会在每个请求完成后将连接关闭，所以，这将会有一系列的20个独立的连接，每个项目均有一个单独的连接。因为三次握手和其后的缓慢启动机制，若每次请求都创建一个新的TCP连接，这就会带来明显的性能损失，最终的结果就是，这些大量的连接会导致严重的性能下降。 HTTP/1.1 - 19991999年发布了HTTP/1.1，这是目前使用最广泛的一个版本，相对于HTTP/1.0，HTTP/1.1主要改进内容包含： 新增的HTTP方法PUT、PATCH、HEAD、OPTIONS、DELETE 主机名标识 在 HTTP/1.0 中，Host头信息不是必须项，但 HTTP/1.1 中要求必须要有Host头信息。 持久性连接 正如前面所说，在 HTTP/1.0 中每个连接只有一个请求 ，且在这个请求完成后该连接就会被关闭，从而会导致严重的性能下降及延迟问题。HTTP/1.1 引入了对持久性连接的支持，例如： 默认情况下连接不会被关闭，在多个连续的请求下它会保存连接的打开状态。想要关闭这些连接，需要将 Connection: close 加入到请求的头信息中。客户端通常会在最后一次请求中发送这个头信息用来安全的关闭连接。 管道机制 HTTP/1.1也引入了对管道机制的支持，客户端可以向服务器发送多个请求，而无需等待来自同一连接上的服务器响应，并且当收到请求时服务器必须以相同的顺序来响应。但你可能会问：客户端是怎么知道第一个响应下载完成和下一个响应内容开始的？要解决这个问题，必须要有Content-Length头信息，客户端可以用它来确定响应结束，然后开始等待下一个响应。 应该注意的是，为了从持久性连接或管道机制中获益，Content-Length头信息必须在可用的响应中，因为这会让客户端知道当传输完成后，它可以发送下一个请求（用正常顺序发送请求的方式）或者开始等待下一个响应（当启用了管道机制时）。 但这种方法仍然存在一个问题：如果数据是动态的，且服务器找不到之前的内容长度时怎么办？那么，在这种情况下，你就真的不能从持久性连接中收益了，不是吗？！为了解决这个问题，在 HTTP/1.1 中引入了分块编码的支持。在这种情况下，服务器可能会忽略 Content-Length 并支持分块编码。然而，如果他们没有可用的数据，那么连接必须在请求结束时关闭。 分块传输 在动态内容的情况下，当传输开始时服务器无法找到 Content-Length 头信息的话，它也可以开始以块的方式发送内容（一块一块的发），并且当每个小块发送后，它会给每个块添加一个 Content-Length 头信息。当所有的块发送完成后（即整个传输已经完成），它会发送一个空的块（即 Content-Length 为零的块）以确定客户端的传输已经完成。为了通知客户端采用分块传输的方式，服务器需要在头信息中包含Transfer-Encoding: chunked 不像HTTP/1.0 只有基本的身份验证，HTTP/1.1 还包含摘要和代理验证 高速缓存 字节范围 字符集 谈判语言 客户端cookie 加强对压缩的支持 新的状态代码 虽然HTTP/1.1对上一版协议进行了很多改进，但web世界每天都在改变，它开始显现出了它的不足。现在访问的网页与以前相比包含的资源更多。一个简单的网页都会至少打开30个连接。 我们知道 HTTP/1.1 是持久连接，那为什么还需要这么多连接？你会说这是由于HTTP/1.1在任何时刻都只有一个有效连接。 HTTP/1.1尝试通过pipeline来解决这个问题，但是它并没有完全的解决，因为在pipeline中虽然请求可以在应答回来之前一一发送，但是客户端还是必须得按照请求的顺序来接受应答。为了克服HTTP/1.1的这些缺点， 开发人员开始尝试一些解决方案，如：在CSS中使用雪碧图、图像编码 ，合并CSS或Javascript文件, 域名分片（将多个资源分别放入不同的子域名下）等等。 SPDY - 2009Google走在前面，它开始试验一种可替换的协议来减少网页的延迟，使得网页加载更快、提升web安全性 。 2009年, 他们称这种协议为SPDY。 SPDY是谷歌的一个商标,不是一个缩写词。 它们意识到如果继续增加带宽来提升网络性能的过程中，必然在到达某一个点后不会再带来更多提升。在有延迟的情况下如果我们不断减少延迟，那么性能建会是一个常数。这是 SPDY性能提升背后的核心理概念，减少延迟来提升网络性能。 对于那些不知道这两个概念的人， 延迟即数据从源传输到目标的耗时(以毫秒为单位)，带宽就是每秒传输的数据量(比特/秒). SPDY的功能包含： 多路复用, 压缩, 优先级, 安全等。我不打算进入SPDY的细节，在进入下一节HTTP / 2后就会明白，HTTP / 2主要受SPDY的启发。 SPDY 没有真正试图替换HTTP，它任然是存在于应用层的基于HTTP的传输层，它在请求发送前进行一些修改。 它开始成为一个事实上的标准，大多数的浏览器开始实现它。 2015年,谷歌不想存在两个相互竞争的标准，因此他们决定把它合并到HTTP中成为HTTP/2，同时放弃SPDY。 HTTP/2 - 2015 HTTP/2 是专为低延迟传输的内容而设计。 关键特征或与 HTTP / 1.1 旧版本的差异，如下： 二进制，而不是文本 多路复用- 在单个连接中多个异步HTTP请求 使用HPACK头部压缩 数据流优先级 服务端推送 - 单请求多个响应 二进制协议二进制分帧层 这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。 这样一来，客户端和服务器为了相互理解，都必须使用新的二进制编码机制：HTTP/1.x 客户端无法理解只支持 HTTP/2 的服务器，反之亦然。不过不要紧，现有的应用不必担心这些变化，因为客户端和服务器会替我们完成必要的分帧工作。 数据流、消息和帧 新的二进制分帧机制改变了客户端与服务器之间交换数据的方式。 为了说明这个过程，我们需要了解 HTTP/2 的三个概念： 数据流(Stream)：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息(Message)：与逻辑请求或响应消息对应的完整的一系列帧。 帧(Frame)：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。 这些概念的关系总结如下： 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载，等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 说通俗点就是HTTP 消息是由一个或多个帧组成的。有一个叫做 HEADERS 的帧存放元数据，真正的数据是放在 DATA 帧中的，帧类型定义在the HTTP/2 specs(HTTP/2规范)，如(HEADERS, DATA, RST_STREAM, SETTINGS, PRIORITY 等)。 每个HTTP / 2请求和响应都被赋予一个唯一的流ID且放入了帧中。帧就是一块二进制数据。 一系列帧的集合就称为流。 每个帧都有一个流id，用于标识它属于哪一个流，每一个帧都有相同的头。同时，除了流标识是唯一的，值得一提的是，客户端发起的任何请求都使用奇数和服务器的响应是偶数的流id。 除了 HEADERS和 DATA， 另外一个值得说一说帧类型是RST_STREAM，它是一个特殊的帧类型用于中止流，如：客户端发送这儿帧来告诉服务器我不再需要这个流了。在 HTTP/1.1 中只有一种方式来实现服务器停止发送响应给客户端，那就是关闭连接引起延迟增加，因为后续的请求就需要打开一个新的连接。 在HTTP/2中，客户端可以使用RST_FRAME来停止接收指定的流而不关闭连接且还可以在此连接中接收其它流。 简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。这是 HTTP/2 协议所有其他功能和性能优化的基础。 多路复用 在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使用多个 TCP 连接（请参阅使用多个 TCP 连接）。这是 HTTP/1.x 交付模型的直接结果，该模型可以保证每个连接每次只交付一个响应（响应排队）。更糟糕的是，这种模型也会导致队首阻塞，从而造成底层 TCP 连接的效率低下。 HTTP/2 中新的二进制分帧层突破了这些限制，实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。 将 HTTP 消息分解为独立的帧，交错发送，然后在另一端重新组装是 HTTP 2 最重要的一项增强。事实上，这个机制会在整个网络技术栈中引发一系列连锁反应，从而带来巨大的性能提升，让我们可以： 并行交错地发送多个请求，请求之间互不影响。 并行交错地发送多个响应，响应之间互不干扰。 使用一个连接并行发送多个请求和响应。 不必再为绕过 HTTP/1.x 限制而做很多工作（请参阅针对 HTTP/1.x 进行优化，例如级联文件、image sprites 和域名分片。 消除不必要的延迟和提高现有网络容量的利用率，从而减少页面加载时间。 HTTP/2 中的新二进制分帧层解决了 HTTP/1.x 中存在的队首阻塞问题，也消除了并行处理和发送请求及响应时对多个连接的依赖。结果，应用速度更快、开发更简单、部署成本更低。 头部压缩（Hpack）每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。为了减少此开销和提升性能，HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术： 这种格式支持通过静态 Huffman 代码对传输的标头字段进行编码，从而减小了各个传输的大小。 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会用作参考，对之前传输的值进行有效编码。 利用 Huffman 编码，可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。 头部压缩的过程如下图所示： 连接会维持一个查找表，该查找表中给出了62个常用字段及其默认值（来自对多个常用网站中请求的统计）。 在第一次请求时，会首先查看查找表中对应字段的值是否为本次请求携带的值，如果不是则更改这个查找表，同时增加查找表中没有的字段。在查找表中将所有头部添加完成后才根据查找表对头部进行压缩并发送请求。 在接下来的每次请求中（当前连接），报文中的压缩数据仅包含查找表中被修改的字段。鉴于一个连接中很多请求中大部分头部字段携带的值都是不常变化的，此举可以大大降低头部传输 作为一种进一步优化方式，HPACK 压缩上下文包含一个静态表和一个动态表：静态表在规范中定义，并提供了一个包含所有连接都可能使用的常用 HTTP 标头字段（例如，有效标头名称）的列表；动态表最初为空，将根据在特定连接内交换的值进行更新。因此，为之前未见过的值采用静态 Huffman 编码，并替换每一侧静态表或动态表中已存在值的索引，可以减小每个请求的大小。 注：在 HTTP/2 中，请求和响应标头字段的定义保持不变，仅有一些微小的差异：所有标头字段名称均为小写，请求行现在拆分成各个 :method、:scheme、:authority 和 :path 伪标头字段。 数据流优先级在HTTP/2中，请求和响应是可以乱序传输的，因此我们需要一个机制可以确保哪些被其他响应数据所依赖的或者关键资源被优先传输，以使网页的呈现和使用具有最好的体验。HTTP/2中在流的层面，采用了“优先级树”的形式确保响应数据能够按照依赖关系和优先级顺序来传输。 “优先级树”可以表示成如上图所示的样子。其中子节点所表示的流响应依赖于父节点流，因此父节点流应该被优先传输。在兄弟节点中，被分配权重较大的点应该被分配更多的网络资源，被优先传输。 如下图中(3)所示的“优先级树”中，A,B依赖于C，C依赖于D，因此D应该被优先传输，D传输完后才应该传输C，同理C传输完成后才应该传输A,B，A,B的数据在传输过程中所占用的网络资源应遵循3:1的关系。 服务端推送 HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源，而无需客户端明确地请求。 为什么在浏览器中需要一种此类机制呢？一个典型的网络应用包含多种资源，客户端需要检查服务器提供的文档才能逐个找到它们。那为什么不让服务器提前推送这些资源，从而减少额外的延迟时间呢？服务器已经知道客户端下一步要请求什么资源，这时候服务器推送即可派上用场。 事实上，如果您在网页中内联过 CSS、JavaScript，或者通过数据 URI 内联过其他资产（请参阅资源内联），那么您就已经亲身体验过服务器推送了。对于将资源手动内联到文档中的过程，我们实际上是在将资源推送给客户端，而不是等待客户端请求。使用 HTTP/2，我们不仅可以实现相同结果，还会获得其他性能优势。 推送资源可以进行以下处理： 由客户端缓存 在不同页面之间重用 与其他资源一起复用 由服务器设定优先级 被客户端拒绝 PUSH_PROMISE 101所有服务器推送数据流都由 PUSH_PROMISE 帧发起，表明了服务器向客户端推送所述资源的意图，并且需要先于请求推送资源的响应数据传输。这种传输顺序非常重要：客户端需要了解服务器打算推送哪些资源，以免为这些资源创建重复请求。满足此要求的最简单策略是先于父响应（即，DATA 帧）发送所有 PUSH_PROMISE 帧，其中包含所承诺资源的 HTTP 标头。 在客户端接收到 PUSH_PROMISE 帧后，它可以根据自身情况选择拒绝数据流（通过 RST_STREAM 帧）。 （如果资源已经位于缓存中，可能会发生这种情况。） 这是一个相对于 HTTP/1.x 的重要提升。 相比之下，使用资源内联（一种受欢迎的 HTTP/1.x“优化”）等同于“强制推送”：客户端无法选择拒绝、取消或单独处理内联的资源。 使用 HTTP/2，客户端仍然完全掌控服务器推送的使用方式。客户端可以限制并行推送的数据流数量；调整初始的流控制窗口以控制在数据流首次打开时推送的数据量；或完全停用服务器推送。这些优先级在 HTTP/2 连接开始时通过 SETTINGS 帧传输，可能随时更新。 推送的每个资源都是一个数据流，与内嵌资源不同，客户端可以对推送的资源逐一复用、设定优先级和处理。 浏览器强制执行的唯一安全限制是，推送的资源必须符合原点相同这一政策：服务器对所提供内容必须具有权威性。 去除某些针对HTTP/1.x的优化在HTTP/1.x中存在一些用于Web性能提升的“奇技淫巧”，但这些技术可能在HTTP/2中起到相反的作用，因此我们第一步就是先去除这些可能会妨碍性能的优化。 ###域名分片（domain sharding）HTTP/1.x中，通信两端最多只有六个连接，且是通过区分不同域名来维持管理的。为了突破这个限制，通常会把请求资源至于不同的域名下（如 shard1.example.org, shard2.example.org）。而在HTTP/2中，因为不需要新开连接来解决头阻塞问题，所以不需要通过这种方式来增加通信的连接数。相反的在HTTP/2中采用域名分片会造成以下两个问题： 增加DNS域名解析时间 增加传输中压缩头部的大小。前文已经提到，头部压缩中的数据复用是在一个连接上维持的，域名分片后新开的连接无法复用之前已经发送过的头部数据，造成一些不必要地数据在网络上的传输。 雪碧图HTTP/1.x中，为了减少请求多个图片带来的头阻塞问题，通常采用把多个图片拼接成一个大图，然后一个请求将所有图片加载在浏览器中，然后使用CSS技术将所需要的部分按需展示出来。显然的，雪碧图会带来如下问题： 增加代码量，需要写一些本不必要地CSS代码 在浏览器渲染过程中，内存中需要加载更多的图片内容 ###拼接JavaScript CSS同雪碧图的原理一样，拼接JavaScript、CSS的做法同样是为了减少请求数，以避免潜在的头阻塞问题。在HTTP/2中，因为不存在头阻塞问题，因此应该避免这种优化方式带来的一些不必要地资源的加载。 参考链接：https://developers.google.com/web/fundamentals/performance/http2/?hl=zh-cnhttps://zh.wikipedia.org/wiki/HTTP/2https://juejin.im/post/59e46b2651882578b8185a05","categories":[{"name":"Network Protocol","slug":"Network-Protocol","permalink":"http://www.goyth.com/categories/Network-Protocol/"}],"tags":[{"name":"HTTP/2","slug":"HTTP-2","permalink":"http://www.goyth.com/tags/HTTP-2/"}]},{"title":"WebSocket知识点梳理","slug":"webSocket","date":"2018-07-09T11:53:01.000Z","updated":"2018-12-02T08:40:27.445Z","comments":true,"path":"2018/07/09/webSocket/","link":"","permalink":"http://www.goyth.com/2018/07/09/webSocket/","excerpt":"什么是WebSocketWebSocket是一种在单个TCP连接上进行全双工通讯的协议。它与HTTP协一样，同属于应用层协议。 WebSocket解决了什么问题WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。简单说就是解决了浏览器和服务器之间双向数据传输的问题。","text":"什么是WebSocketWebSocket是一种在单个TCP连接上进行全双工通讯的协议。它与HTTP协一样，同属于应用层协议。 WebSocket解决了什么问题WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。简单说就是解决了浏览器和服务器之间双向数据传输的问题。 HTTP协议可以实现双向数据传输吗答案肯定是可以的，在HTTP协议中我们通常使用\b轮询\b来实现双向通信。轮询是通过在特定的的时间间隔（如每1秒），由浏览器对服务器发出HTTP请求，然后由服务器返回最新的数据给客户端的浏览器。这种传统的模式带来很明显的缺点，即浏览器需要不断的向服务器发出请求，然而HTTP请求可能包含较长的头部，其中真正有效的数据可能只是很小的一部分，显然这样会浪费很多的带宽等资源。 HTTP1.1长连接与WebSocket长连接有什么区别HTTP1.1默认启用”Connection: Keep-Alive”，使得在发送完http请求和应答后，\b不会立刻将连接关闭，在后续的http请求和应答可以继续\b使用这个连接，避免创建\b新的TCP连接时\b三次握手及断开连接时四次挥手的额外\b消耗。这个keep-alive一般会有固定的时间限制。如Apache是5s，而nginx默认是75s，超过这个时间服务器就会主动把TCP连接关闭了，因为不关闭的话会有大量的TCP连接占用系统资源。所以这个keep-alive并不是为了长连接设计的，只是为了提高http请求的效率。而WebSocket长连接的关闭可以由通过调用相应的API，主动控制。HTTP1.1长连接是无状态的，每一个\b请求对应一个应答，并且每个请求和应答里面都包含了完整的头部信息；而WebSocket长连接是有状态的，在建立连接后，WebSocket只用携带少量头部字段信息（\b如数据包长度、掩码），不用携带状态信息。 WebSocket的优点 较少的控制开销。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。 更强的实时性。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；即使是和Comet等类似的长轮询比较，其也能在短时间内更多次地传递数据。 保持连接状态。与HTTP不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。 更好的二进制支持。Websocket定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。 可以支持扩展。Websocket定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。 更好的压缩效果。相对于HTTP压缩，Websocket在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率。 WebSocket兼容性情况 WebSocket握手协议WebSocket 是独立的、创建在 TCP 上的协议。 Websocket 通过 HTTP/1.1 协议的101状态码进行握手。 为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为“握手”（handshaking）。 例子一个典型的Websocket握手请求如下： 客户端请求 1234567GET / HTTP/1.1Upgrade: websocketConnection: UpgradeHost: example.comOrigin: http://example.comSec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ==Sec-WebSocket-Version: 13 服务器回应 12345HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s=Sec-WebSocket-Location: ws://example.com/ 字段说明 Connection必须设置Upgrade，表示客户端希望连接升级。 Upgrade字段必须设置Websocket，表示希望升级到Websocket协议。 Sec-WebSocket-Key是随机的字符串，服务器端会用这些数据来构造出一个SHA-1的信息摘要。把“Sec-WebSocket-Key”加上一个特殊字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，然后计算SHA-1摘要，之后进行BASE-64编码，将结果做为“Sec-WebSocket-Accept”头的值，返回给客户端。如此操作，可以尽量避免普通HTTP请求被误认为Websocket协议。 Sec-WebSocket-Version 表示支持的Websocket版本。RFC6455要求使用的版本是13，之前草案的版本均应当弃用。 Origin字段是可选的，通常用来表示在浏览器中发起此Websocket连接所在的页面，类似于Referer。但是，与Referer不同的是，Origin只包含了协议和主机名称。 其他一些定义在HTTP协议中的字段，如Cookie等，也可以在Websocket中使用。 帧协议客户端、服务端数据的交换，离不开数据帧格式的定义。因此，在实际讲解数据交换之前，我们先来看下WebSocket的数据帧格式。 WebSocket客户端、服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。 发送端：将消息切割成多个帧，并发送给服务端；接收端：接收消息帧，并将关联的帧重新组装成完整的消息；本节的重点，就是讲解数据帧的格式。详细定义可参考 RFC6455 5.2节 。 FIN：1个比特。 如果是1，表示这是消息（message）的最后一个分片（fragment），如果是0，表示不是是消息（message）的最后一个分片（fragment）。 RSV1, RSV2, RSV3：各占1个比特。 一般情况下全为0。当客户端、服务端协商采用WebSocket扩展时，这三个标志位可以非0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用WebSocket扩展，连接出错。 Opcode: 4个比特。 操作代码，Opcode的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下： %x0：表示一个延续帧。当Opcode为0时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。 %x1：表示这是一个文本帧（frame） %x2：表示这是一个二进制帧（frame） %x3-7：保留的操作代码，用于后续定义的非控制帧。 %x8：表示连接断开。 %x9：表示这是一个ping操作。 %xA：表示这是一个pong操作。 %xB-F：保留的操作代码，用于后续定义的控制帧。 Mask: 1个比特。 表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。 如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。 如果Mask是1，那么在Masking-key中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask都是1。 掩码的算法、用途在下一小节讲解。 Payload length：数据载荷的长度，单位是字节。为7位，或7+16位，或1+64位。 假设数Payload length === x，如果 x为0~126：数据的长度为x字节。 x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。 x为127：后续8个字节代表一个64位的无符号整数（最高位为0），该无符号整数的值为数据的长度。 此外，如果payload length占用了多个字节的话，payload length的二进制表达采用网络序（big endian，重要的位在前）。 Masking-key：0或4字节（32位） 所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask为1，且携带了4字节的Masking-key。如果Mask为0，则没有Masking-key。 备注：载荷数据的长度，不包括mask key的长度。 Payload data：(x+y) 字节 载荷数据：包括了扩展数据、应用数据。其中，扩展数据x字节，应用数据y字节。 扩展数据：如果没有协商使用扩展的话，扩展数据数据为0字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。 应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。 掩码算法掩码键（Masking-key）是由客户端挑选出来的32位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法： 首先，假设： original-octet-i：为原始数据的第i字节。 transformed-octet-i：为转换后的数据的第i字节。 j：为i mod 4的结果。 masking-key-octet-j：为mask key第j字节。 算法描述为： original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。 12j = i MOD 4transformed-octet-i = original-octet-i XOR masking-key-octet-j 数据掩码的作用WebSocket协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。 那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。 答案还是两个字：安全。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。 跳动检测在握手之后的任何时候，客户端或者服务器都可以选择向对方发送 ping 帧。 当收到一个 ping 帧，收件人必须尽快发回一个 pong 帧。 这是一次跳动。 你可以使用它来确保客户端保持着连接。 ping 帧或 pong 帧只是一个常规的帧，但它是一个控制帧。 ping 帧具有 0x9 的操作码，并且 pong 帧具有 0xA 的操作码。 当你得到一个 ping 帧，发回一个 pong 帧与 ping 帧完全相同的有效载荷数据（对于 pings 和 pongs ，最大有效载荷长度是 125 ）。 你也可能会得到一个 pong 帧返回，而无需再发送一个 ping 帧。如果它发生就忽略它。 跳动检测可能是非常有用的。 有些服务（如负载均衡器）会终止空闲连接。 另外，接收方无法查看远端是否已经终止。 只有在下一个发送时你会意识到出了问题。 Sec-WebSocket-Key/Accept的作用前面提到了，Sec-WebSocket-Key/Sec-WebSocket-Accept在主要作用在于提供基础的防护，减少恶意连接、意外连接。 作用大致归纳如下： 避免服务端收到非法的websocket连接（比如http客户端不小心请求连接websocket服务，此时服务端可以直接拒绝连接） 确保服务端理解websocket连接。因为ws握手阶段采用的是http协议，因此可能ws连接是被一个http服务器处理并返回的，此时客户端可以通过Sec-WebSocket-Key来确保服务端认识ws协议。（并非百分百保险，比如总是存在那么些无聊的http服务器，光处理Sec-WebSocket-Key，但并没有实现ws协议。。。） 用浏览器里发起ajax请求，设置header时，Sec-WebSocket-Key以及其他相关的header是被禁止的。这样可以避免客户端发送ajax请求时，意外请求协议升级（websocket upgrade） 可以防止反向代理（不理解ws协议）返回错误的数据。比如反向代理前后收到两次ws连接的升级请求，反向代理把第一次请求的返回给cache住，然后第二次请求到来时直接把cache住的请求给返回（无意义的返回）。 Sec-WebSocket-Key主要目的并不是确保数据的安全性，因为Sec-WebSocket-Key、Sec-WebSocket-Accept的转换计算公式是公开的，而且非常简单，最主要的作用是预防一些常见的意外情况（非故意的）。 强调：Sec-WebSocket-Key/Sec-WebSocket-Accept 的换算，只能带来基本的保障，但连接是否安全、数据是否安全、客户端/服务端是否合法的 ws客户端、ws服务端，其实并没有实际性的保证。 数据传递一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。 WebSocket根据opcode来区分操作的类型。比如0x8表示断开连接，0x0-0x2表示数据交互。 1、数据分片WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据FIN的值来判断，是否已经收到消息的最后一个数据帧。 FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。 此外，opcode在数据交换的场景下，表示的是数据的类型。0x01表示文本，0x02表示二进制。而0x00比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。 2、数据分片例子直接看例子更形象些。下面例子来自MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。 第一条消息 FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。 第二条消息 FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。 FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。 FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。 12345678Client: FIN=1, opcode=0x1, msg=\"hello\"Server: (process complete message immediately) Hi.Client: FIN=0, opcode=0x1, msg=\"and a\"Server: (listening, new message containing text started)Client: FIN=0, opcode=0x0, msg=\"happy new\"Server: (listening, payload concatenated to previous message)Client: FIN=1, opcode=0x0, msg=\"year!\"Server: (process complete message) Happy new year to you too! Websocket APIWebSocket 的用法示例123456789101112131415var ws = new WebSocket(\"wss://echo.websocket.org\");ws.onopen = function(evt) &#123; console.log(\"Connection open ...\"); ws.send(\"Hello WebSockets!\");&#125;;ws.onmessage = function(evt) &#123; console.log( \"Received Message: \" + evt.data); ws.close();&#125;;ws.onclose = function(evt) &#123; console.log(\"Connection closed.\");&#125;; WebSocket 构造函数WebSocket 对象作为一个构造函数，用于新建 WebSocket 实例。 1var ws = new WebSocket('ws://localhost:8080'); 执行上面语句之后，客户端就会与服务器进行连接。 实例对象的所有属性和方法清单，参见这里。 webSocket.readyStatereadyState属性返回实例对象的当前状态，共有四种。 CONNECTING：值为0，表示正在连接。 OPEN：值为1，表示连接成功，可以通信了。 CLOSING：值为2，表示连接正在关闭。 CLOSED：值为3，表示连接已经关闭，或者打开连接失败。 下面是一个示例。 1234567891011121314151617switch (ws.readyState) &#123; case WebSocket.CONNECTING: // do something break; case WebSocket.OPEN: // do something break; case WebSocket.CLOSING: // do something break; case WebSocket.CLOSED: // do something break; default: // this never happens break;&#125; webSocket.onopen实例对象的onopen属性，用于指定连接成功后的回调函数。 123ws.onopen = function () &#123; ws.send('Hello Server!');&#125; 如果要指定多个回调函数，可以使用addEventListener方法。 123ws.addEventListener('open', function (event) &#123; ws.send('Hello Server!');&#125;); webSocket.onclose实例对象的onclose属性，用于指定连接关闭后的回调函数。 12345678910111213ws.onclose = function(event) &#123; var code = event.code; var reason = event.reason; var wasClean = event.wasClean; // handle close event&#125;;ws.addEventListener(\"close\", function(event) &#123; var code = event.code; var reason = event.reason; var wasClean = event.wasClean; // handle close event&#125;); webSocket.onmessage实例对象的onmessage属性，用于指定收到服务器数据后的回调函数。 123456789ws.onmessage = function(event) &#123; var data = event.data; // 处理数据&#125;;ws.addEventListener(\"message\", function(event) &#123; var data = event.data; // 处理数据&#125;); 注意，服务器数据可能是文本，也可能是二进制数据（blob对象或Arraybuffer对象）。 12345678910ws.onmessage = function(event)&#123; if(typeof event.data === String) &#123; console.log(\"Received data string\"); &#125; if(event.data instanceof ArrayBuffer)&#123; var buffer = event.data; console.log(\"Received arraybuffer\"); &#125;&#125; 除了动态判断收到的数据类型，也可以使用binaryType属性，显式指定收到的二进制数据类型。 1234567891011// 收到的是 blob 数据ws.binaryType = \"blob\";ws.onmessage = function(e) &#123; console.log(e.data.size);&#125;;// 收到的是 ArrayBuffer 数据ws.binaryType = \"arraybuffer\";ws.onmessage = function(e) &#123; console.log(e.data.byteLength);&#125;; webSocket.send()实例对象的send()方法用于向服务器发送数据。 发送文本的例子。 1ws.send('your message'); 发送 Blob 对象的例子。 1234var file = document .querySelector('input[type=\"file\"]') .files[0];ws.send(file); 发送 ArrayBuffer 对象的例子。 1234567// Sending canvas ImageData as ArrayBuffervar img = canvas_context.getImageData(0, 0, 400, 320);var binary = new Uint8Array(img.data.length);for (var i = 0; i &lt; img.data.length; i++) &#123; binary[i] = img.data[i];&#125;ws.send(binary.buffer); webSocket.bufferedAmount实例对象的bufferedAmount属性，表示还有多少字节的二进制数据没有发送出去。它可以用来判断发送是否结束。 12345678var data = new ArrayBuffer(10000000);socket.send(data);if (socket.bufferedAmount === 0) &#123; // 发送完毕&#125; else &#123; // 发送还没结束&#125; webSocket.onerror实例对象的onerror属性，用于指定报错时的回调函数。 1234567socket.onerror = function(event) &#123; // handle error event&#125;;socket.addEventListener(\"error\", function(event) &#123; // handle error event&#125;); 参考链接：https://zh.wikipedia.org/zh-cn/WebSockethttps://juejin.im/post/5b0a31f851882538bb0cfae2https://cloud.tencent.com/document/product/214/4150?fromSource=gwzcw.93403.93403.93403https://www.cnblogs.com/chyingp/p/websocket-deep-in.htmlhttps://www.zhihu.com/question/20215561https://mp.weixin.qq.com/s/7aXMdnajINt0C5dcJy2USghttps://www.oschina.net/translate/how-does-javascript-actually-work-part-5http://www.ruanyifeng.com/blog/2017/05/websocket.html","categories":[{"name":"Network Protocol","slug":"Network-Protocol","permalink":"http://www.goyth.com/categories/Network-Protocol/"}],"tags":[{"name":"webSocket","slug":"webSocket","permalink":"http://www.goyth.com/tags/webSocket/"}]},{"title":"DNS知识点梳理","slug":"DNS","date":"2018-07-07T10:29:09.000Z","updated":"2018-12-02T08:38:53.220Z","comments":true,"path":"2018/07/07/DNS/","link":"","permalink":"http://www.goyth.com/2018/07/07/DNS/","excerpt":"DNS 服务器DNS( Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作。DNS就是这样的一位“翻译官”，它的基本工作原理可用下图来表示。","text":"DNS 服务器DNS( Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作。DNS就是这样的一位“翻译官”，它的基本工作原理可用下图来表示。 全世界所有的人每天上网都会使用DNS服务器，如果大家都去同一个地方访问某一台服务器，时延将会非常大，所以DNS服务器的架构必须是分布式、高并发、高可用，如下图： 根 DNS 服务器 ：返回顶级域 DNS 服务器的 IP 地址 顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址 权威 DNS 服务器 ：返回相应主机的 IP 地址 DNS域名解析过程当用户在浏览器中输入www.abc.com并按下回车键后： 第一步查找本地DNS缓存本地DNS缓存有浏览器DNS缓存，操作系统（OS）DNS缓存，路由器DNS缓存，按照浏览器、操作系统、路由器的顺序依次查找www.abc.com对应的DNS缓存，如果缓存命中则停止。 1、浏览器DNS缓存浏览器在获取网站域名的实际IP地址后会对其IP进行缓存，减少网络请求的损耗。当浏览器收到一个DNS解析请求后，首先会检查缓存中有没有这个域名对应的解析过的IP地址，如果缓存中有，这个解析过程就将结束。浏览器缓存域名也是有限制的，不仅浏览器缓存大小有限制，而且缓存的时间也有限制，通常情况下为几分钟到几小时不等。这个缓存时间太长和太短都不好，如果缓存时间太长，一旦域名被解析到的IP有变化，会导致被客户端缓存的域名无法解析到变化后的IP地址，以致该域名不能正常解析，这段时间内有可能会有一部分用户无法访问网站。如果时间设置太短，会导致用户每次访问网站都要重新解析一次域名。浏览器DNS缓存的时间跟DNS服务器返回的TTL值无关。通常每种浏览器都有一个固定的DNS缓存时间，其中Chrome的过期时间是1分钟，在这个期限内不会重新请求DNS。Chrome浏览器看本身的DNS缓存时间比较方便，在地址栏输入1chrome://net-internals/#dns 2、系统（OS）DNS缓存如果用户浏览器缓存中没有数据，浏览器会查找操作系统缓存中是否有这个域名对应的DNS解析结果。其实操作系统也有一个域名解析的过程，在Windows中可以通过C:\\Windows\\System32\\drivers\\etc\\hosts文件来设置，在Linux中可以通过/etc/hosts文件来设置，用户可以将任何域名解析到任何能够访问的IP地址。例如，我们在测试时可以将一个域名解析到一台测试服务器上，这样不用修改任何代码就能测试到单独服务器上的代码的业务逻辑是否正确。正是因为有这种本地DNS解析的规程，所以有黑客就可能通过修改用户的域名来把特定的域名解析到他指定的IP地址上，导致这些域名被劫持。 第二步查找ISP DNS缓存如果本地DNS缓存没有对应的记录，就要用到我们网络配置中的”DNS服务器地址”了。操作系统会把这个域名发送给这个ISP，也就是本地区的域名服务器。这个DNS通常都提供给用户本地互联网接入的一个DNS解析服务，例如用户是在学校接入互联网，那么用户的DNS服务器肯定在学校；如果用户是在小区接入互联网，那么用户的DNS就是再提供接入互联网的应用提供商，即电信或联通，也就是通常说的SPA，那么这个DNS通常也会在用户所在城市的某个角落，不会很远。Windows环境下通过命令行输入ipconfig，Linux环境下通过cat /etc/resolv.conf就可以查询配置的DNS服务器了。这个专门的域名解析服务器性能都会很好，它们一般都会缓存域名解析结果，当然缓存时间是受到域名的失效时间控制的。大约80%的域名解析到这里就结束了，所以ISP主要承担了域名的解析工作。 递归搜索在前面都没有办法命中的DNS缓存的情况下,(1)本地 DNS服务器即将该请求转发到互联网上的根DNS（即一个完整域名最后面的那个点，通常省略不写）。(2)根DNS将所要查询域名中的顶级域（假设要查询www.abc.com，该域名的顶级域就是.com）的服务器IP地址返回到本地DNS。(3) 本地DNS根据返回的IP地址，再向顶级域（就是.com域）发送请求。(4) .com域服务器再将域名中的权威域名服务器（abc.com）的IP地址返回给本地DNS。(5) 本地DNS再向权威域名服务器（abc.com）发送请求进行查询。(6) 权威DNS查询到对应的IP后，就将IP返回给本地DNS服务器，本地 DNS 再将 IP 地址返回客户端。 DNS有关的网络性能优化1、减少DNS查找，避免重定向，浏览器DNS缓存 、计算机DNS缓存、 服务器DNS缓存、使用Keep-Alive特性 来减少DNS查找。考虑影响DNS缓存的因素： 服务器可以设置TTL值表示DNS记录的存活时间。本机DNS缓存将根据这个TTL值判断DNS记录什么时候被抛弃，这个TTL值一般都不会设置很大，主要是考虑到快速故障转移的问题。 浏览器DNS缓存也有自己的过期时间，这个时间是独立于本机DNS缓存的，相对也比较短，例如chrome只有1分钟左右。 浏览器DNS记录的数量也有限制，如果短时间内访问了大量不同域名的网站，则较早的DNS记录将被抛弃，必须重新查找。不过即使浏览器丢弃了DNS记录，操作系统的DNS缓存也有很大机率保留着该记录，这样可以避免通过网络查询而带来的延迟。 2、DNS的预解析DNS 请求需要的带宽非常小，但是延迟却有点高，这点在手机网络上特别明显。预读取 DNS 能让延迟明显减少一些，例如用户点击链接时。在某些情况下，延迟能减少一秒钟。 在某些浏览器中这个预读取的行为将会与页面实际内容并行发生（而不是串行）。正因如此，某些高延迟的域名的解析过程才不会卡住资源的加载。 这样可以极大的加速（尤其是移动网络环境下）页面的加载。在某些图片较多的页面中，在发起图片加载请求之前预先把域名解析好将会有至少 5% 的图片加载速度提升。 打开和关闭 DNS 预读取你可以通过在服务器端发送 X-DNS-Prefetch-Control 报头，或是在文档中使用值为 http-equiv 的 &lt;meta&gt; 标签：1&lt;meta http-equiv=\"x-dns-prefetch-control\" content=\"off\"&gt; 您可以通过将 content 的参数设置为on来改变设置。 强制查询特定主机名你可以通过使用 rel 属性值为 link type 中的 dns-prefetch 的&lt;link&gt; 标签来对特定域名进行预读取：1&lt;link rel=\"dns-prefetch\" href=\"http://www.spreadfirefox.com/\"&gt; 在这个例子中，Firefox将预解析域名”www.spreadfirefox.com&quot;。 而且，&lt;link&gt; 元素也可以使用不完整的 URL 的主机名来标记预解析，但这些主机名前必需要有双斜线：1&lt;link rel=\"dns-prefetch\" href=\"//www.spreadfirefox.com\"&gt; 强制对域名进行预读取在有的情况下很有用, 比如, 在网站的主页上，强制在整个网站上频繁引用的域名的预解析，即使它们不在主页本身上使用。即使主页的性能可能不受影响，这将提高整体站点性能。 当客户端的DNS缓存为空时，DNS查找的数量与Web页面中唯一主机名的数量相等。减少唯一主机名的数量就可以减少DNS查找的数量。较少的域名来减少DNS查找（2-4个主机） 几种域名解析方式域名解析记录主要分为A记录、MX记录、CNAME记录、NS记录和TXT记录： A记录A代表Address，用来指定域名对应的IP地址，如将item.taobao.com指定到115.238.23.xxx，将switch.taobao.com指定到121.14.24.xxx。A记录可以将多个域名解析到一个IP地址，但是不能将一个域名解析到多个IP地址 MX记录Mail Exchange，就是可以将某个域名下的邮件服务器指向自己的Mail Server，如taobao.com域名的A记录IP地址是115.238.25.xxx，如果将MX记录设置为115.238.25.xxx，即xxx@taobao.com的邮件路由，DNS会将邮件发送到115.238.25.xxx所在的服务器，而正常通过Web请求的话仍然解析到A记录的IP地址 CNAME记录Canonical Name，即别名解析。所谓别名解析就是可以为一个域名设置一个或者多个别名，如将aaa.com解析到bbb.net、将ccc.com也解析到bbb.net，其中bbb.net分别是aaa.com和ccc.com的别名 NS记录为某个域名指定DNS解析服务器，也就是这个域名由指定的IP地址的DNS服务器取解析 TXT记录为某个主机名或域名设置说明，如可以为ddd.net设置TXT记录为”这是XXX的博客”这样的说明 参考链接：https://www.cnblogs.com/xrq730/p/4931418.htmlhttp://imweb.https://blog.csdn.net/kkdelta/article/details/53404005io/topic/55e3ba46771670e207a16bc8shttps://time.geekbang.org/column/article/9895https://developer.mozilla.org/zh-CN/docs/Controlling_DNS_prefetching","categories":[{"name":"Network Protocol","slug":"Network-Protocol","permalink":"http://www.goyth.com/categories/Network-Protocol/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"http://www.goyth.com/tags/DNS/"}]},{"title":"TCP/IP 协议知识点梳理","slug":"TcpIp","date":"2018-07-04T06:09:31.000Z","updated":"2018-12-02T08:40:18.025Z","comments":true,"path":"2018/07/04/TcpIp/","link":"","permalink":"http://www.goyth.com/2018/07/04/TcpIp/","excerpt":"TCP/IP协议TCP/IP协议模型（Transmission Control Protocol/Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。 TCP/IP 协议分层模型基于TCP/IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP/IP模型与OSI模型各层的对照关系。","text":"TCP/IP协议TCP/IP协议模型（Transmission Control Protocol/Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。 TCP/IP 协议分层模型基于TCP/IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP/IP模型与OSI模型各层的对照关系。 物理层将二进制的0和1和电压高低，光的闪灭和电波的强弱信号进行转换 链路层代表驱动 网络层 使用 IP 协议，IP 协议基于 IP 转发分包数据 IP 协议是个不可靠协议，不会重发 IP 协议发送失败会使用ICMP 协议通知失败 ARP 解析 IP 中的 MAC 地址，MAC 地址由网卡出厂提供 IP 还隐含链路层的功能，不管双方底层的链路层是啥，都能通信 传输层 通用的 TCP 和 UDP 协议 TCP 协议面向有连接，能正确处理丢包，传输顺序错乱的问题，但是为了建立与断开连接，需要至少7次的发包收包，资源浪费 UDP 面向无连接，不管对方有没有收到，如果要得到通知，需要通过应用层 会话层以上分层 TCP/IP 分层中，会话层，表示层，应用层集中在一起 网络管理通过 SNMP 协议 TCP/IP 协议模型封包解包TCP/IP协议族按照层次由上到下，层层包装。最上面的是应用层，这里面有http，ftp,等等我们熟悉的协议。而第二层则是传输层，著名的TCP和UDP协议就在这个层次。第三层是网络层，IP协议就在这里，它负责对数据加上IP地址和其他的数据以确定传输的目标。第四层是数据链路层，这个层次为待传送的数据加入一个以太网协议头，并进行CRC编码，为最后的数据传输做准备。 上图清楚地表示了TCP/IP协议中每个层的作用，而TCP/IP协议通信的过程其实就对应着数据入栈与出栈的过程。入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。 TCP三次握手TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。 第一次握手： 建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；第二次握手： 服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；第三次握手： 客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 为什么要三次握手？TCP的三次握手最主要是防止已过期的连接再次传到被连接的主机。如果采用两次握手，那么若Client向Server发起的包A1如果在传输链路上遇到的故障，导致传输到Server的时间相当滞后，在这个时间段由于Client没有收到Server的对于包A1的确认，那么就会重传一个包A2，假设服务器正常收到了A2的包，然后返回确认B2包。由于没有第三次握手，这个时候Client和Server已经建立连接了。再假设A1包随后在链路中传到了Server，这个时候Server又会返回B1包确认，但是由于Client已经清除了A1包，所以Client会丢弃掉这个确认包，但是Server会保持这个相当于“僵尸”的连接，浪费资源。 四次挥手当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。 第一次分手： 主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了；第二次分手： 主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；第三次分手： 主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；第四次分手： 主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要四次分手？TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。 为什么要等待2MSL？MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。原因有二： 保证TCP协议的全双工连接能够可靠关闭 保证这次连接的重复数据段从网络中消失 第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 TCP/UDPTCP/UDP都是是传输层协议，但是两者具有不同的特性，同时也具有不同的应用场景，下面以图表的形式对比分析。 面向报文面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会使IP太小。 面向字节流面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。 TCP和UDP协议的一些应用 什么时候应该使用TCP？当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 什么时候应该使用UDP？当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 TCP超时重传 原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的ACK报文，那么就重新发送数据，直到发送成功为止。 影响超时重传机制协议效率的一个关键参数是重传超时时间（RTO，Retransmission TimeOut）。RTO的值被设置过大过小都会对协议造成不利影响。 （1）RTO设长了，重发就慢，没有效率，性能差。 （2）RTO设短了，重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。 连接往返时间（RTT，Round Trip Time），指发送端从发送TCP包开始到接收它的立即响应所消耗的时间。 TCP流量控制如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。 TCP滑动窗口作用：（1）提供TCP的可靠性；（2）提供TCP的流控特性 TCP的滑动窗口的可靠性也是建立在“确认重传”基础上的。发送窗口只有收到对端对于本段发送窗口内字节的ACK确认，才会移动发送窗口的左边界。接收端可以根据自己的状况通告窗口大小，从而控制发送端的接收，进行流量控制。 示例设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。 从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd = 300 ，第二次又减到了 rwnd = 100 ，最后减到 rwnd = 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK = 1 ，只有在ACK=1时确认号字段才有意义。 TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。 TCP拥塞控制拥塞控制是一个全局性的过程； 流量控制是点对点通信量的控制TCP拥塞控制4个核心算法：慢开始（slow start）、拥塞避免（Congestion Avoidance）、快速重传（fast retransmit）、快速回复（fast recovery）。 发送方维持一个 拥塞窗口 cwnd ( congestion window ) 的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。 通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。 为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下： 当cwnd &lt; ssthresh时，使用慢开始算法。 当cwnd &gt; ssthresh时，改用拥塞避免算法。 当cwnd = ssthresh时，慢开始与拥塞避免算法任意。 拥塞避免让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。 拥塞控制的具体过程如下：（1）TCP连接初始化，将拥塞窗口设置为1（2）执行慢开始算法，cwnd按指数规律增长，直到cwnd=ssthresh时，开始执行拥塞避免算法，cwnd按线性规律增长（3）当网络发生拥塞，把ssthresh值更新为拥塞前cwnd值的一半，cwnd重新设置为1，按照步骤（2）执行 快重传快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。 接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。 但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。 快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 快恢复与快重传配合使用的还有快恢复算法，其过程有以下两个要点： 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh设置为cwnd值的一半。 与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为ssthresh的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。 参考链接：https://blog.csdn.net/qq_26499321/article/details/71429813https://juejin.im/post/5ad4094e6fb9a028d7011069https://juejin.im/post/598ba1d06fb9a03c4d6464abhttps://blog.csdn.net/jtracydy/article/details/52366461","categories":[{"name":"Network Protocol","slug":"Network-Protocol","permalink":"http://www.goyth.com/categories/Network-Protocol/"}],"tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"http://www.goyth.com/tags/TCP-IP/"}]},{"title":"浏览器的缓存机制梳理","slug":"browseCache","date":"2018-07-01T00:52:09.000Z","updated":"2018-12-02T08:38:29.108Z","comments":true,"path":"2018/07/01/browseCache/","link":"","permalink":"http://www.goyth.com/2018/07/01/browseCache/","excerpt":"概述浏览器的缓存机制也就是我们说的HTTP缓存机制，其机制是根据HTTP报文的缓存标识进行的，所以在分析浏览器缓存机制之前，我们先使用图文简单介绍一下HTTP报文，HTTP报文分为两种：","text":"概述浏览器的缓存机制也就是我们说的HTTP缓存机制，其机制是根据HTTP报文的缓存标识进行的，所以在分析浏览器缓存机制之前，我们先使用图文简单介绍一下HTTP报文，HTTP报文分为两种： HTTP请求(Request)报文，报文格式为：请求行 – HTTP头(通用信息头，请求头，实体头) – 请求报文主体(只有POST才有报文主体)，如下图 HTTP响应(Response)报文，报文格式为：状态行 – HTTP头(通用信息头，响应头，实体头) – 响应报文主体，如下图 注：通用信息头指的是请求和响应报文都支持的头域，分别为Cache-Control、Connection、Date、Pragma、Transfer-Encoding、Upgrade、Via；实体头则是实体信息的实体头域，分别为Allow、Content-Base、Content-Encoding、Content-Language、Content-Length、Content-Location、Content-MD5、Content-Range、Content-Type、Etag、Expires、Last-Modified、extension-header。这里只是为了方便理解，将通用信息头，响应头/请求头，实体头都归为了HTTP头。 以上的概念在这里我们不做多讲解，只简单介绍，有兴趣的童鞋可以自行研究。 缓存过程分析浏览器与服务器通信的方式为应答模式，即是：浏览器发起HTTP请求 – 服务器响应该请求。那么浏览器第一次向服务器发起该请求后拿到请求结果，会根据响应报文中HTTP头的缓存标识，决定是否缓存结果，是则将请求结果和缓存标识存入浏览器缓存中，简单的过程如下图： 由上图我们可以知道： 浏览器每次发起请求，都会先在浏览器缓存中查找该请求的结果以及缓存标识 浏览器每次拿到返回的请求结果都会将该结果和缓存标识存入浏览器缓存中 以上两点结论就是浏览器缓存机制的关键，他确保了每个请求的缓存存入与读取，只要我们再理解浏览器缓存的使用规则，那么所有的问题就迎刃而解了，本文也将围绕着这点进行详细分析。为了方便大家理解，这里我们根据是否需要向服务器重新发起HTTP请求将缓存过程分为两个部分，分别是强制缓存和协商缓存。 强制缓存强制缓存就是向浏览器缓存查找该请求结果，并根据该结果的缓存规则来决定是否使用该缓存结果的过程，强制缓存的情况主要有三种(暂不分析协商缓存过程)，如下： 不存在该缓存结果和缓存标识，强制缓存失效，则直接向服务器发起请求（跟第一次发起请求一致），如下图： 存在该缓存结果和缓存标识，但该结果已失效，强制缓存失效，则使用协商缓存(暂不分析)，如下图 存在该缓存结果和缓存标识，且该结果尚未失效，强制缓存生效，直接返回该结果，如下图 那么强制缓存的缓存规则是什么？ 当浏览器向服务器发起请求时，服务器会将缓存规则放入HTTP响应报文的HTTP头中和请求结果一起返回给浏览器，控制强制缓存的字段分别是Expires和Cache-Control，其中Cache-Control优先级比Expires高。 ExpiresExpires是HTTP/1.0控制网页缓存的字段，其值为服务器返回该请求结果缓存的到期时间，即再次发起该请求时，如果客户端的时间小于Expires的值时，直接使用缓存结果。 Expires是HTTP/1.0的字段，但是现在浏览器默认使用的是HTTP/1.1，那么在HTTP/1.1中网页缓存还是否由Expires控制？ 到了HTTP/1.1，Expire已经被Cache-Control替代，原因在于Expires控制缓存的原理是使用客户端的时间与服务端返回的时间做对比，那么如果客户端与服务端的时间因为某些原因（例如时区不同；客户端和服务端有一方的时间不准确）发生误差，那么强制缓存则会直接失效，这样的话强制缓存的存在则毫无意义，那么Cache-Control又是如何控制的呢？ Cache-Control在HTTP/1.1中，Cache-Control是最重要的规则，主要用于控制网页缓存，主要取值为： public：所有内容都将被缓存（客户端和代理服务器都可缓存） private：所有内容只有客户端可以缓存，Cache-Control的默认取值 no-cache：客户端缓存内容，但是是否使用缓存则需要经过协商缓存来验证决定 no-store：所有内容都不会被缓存，即不使用强制缓存，也不使用协商缓存 max-age=xxx (xxx is numeric)：缓存内容将在xxx秒后失效 接下来，我们直接看一个例子，如下： 由上面的例子我们可以知道： HTTP响应报文中expires的时间值，是一个绝对值 HTTP响应报文中Cache-Control为max-age=600，是相对值 由于Cache-Control的优先级比expires，那么直接根据Cache-Control的值进行缓存，意思就是说在600秒内再次发起该请求，则会直接使用缓存结果，强制缓存生效。 注：在无法确定客户端的时间是否与服务端的时间同步的情况下，Cache-Control相比于expires是更好的选择，所以同时存在时，只有Cache-Control生效。 了解强制缓存的过程后，我们拓展性的思考一下： 浏览器的缓存存放在哪里，如何在浏览器中判断强制缓存是否生效？ 这里我们以博客的请求为例，状态码为灰色的请求则代表使用了强制缓存，请求对应的Size值则代表该缓存存放的位置，分别为from memory cache 和 from disk cache。 那么from memory cache 和 from disk cache又分别代表的是什么呢？什么时候会使用from disk cache，什么时候会使用from memory cache呢？ from memory cache代表使用内存中的缓存，from disk cache则代表使用的是硬盘中的缓存，浏览器读取缓存的顺序为memory –&gt; disk。 虽然我已经直接把结论说出来了，但是相信有不少人对此不能理解，那么接下来我们一起详细分析一下缓存读取问题，这里仍让以我的博客为例进行分析： 访问https://heyingye.github.io/ –&gt; 200 –&gt; 关闭博客的标签页 –&gt; 重新打开https://heyingye.github.io/ –&gt; 200(from disk cache) –&gt; 刷新 –&gt; 200(from memory cache) 过程如下： 访问https://heyingye.github.io/ 关闭博客的标签页 重新打开https://heyingye.github.io/ 刷新 看到这里可能有人小伙伴问了，最后一个步骤刷新的时候，不是同时存在着from disk cache和from memory cache吗？ 对于这个问题，我们需要了解内存缓存(from memory cache)和硬盘缓存(from disk cache)，如下: 内存缓存(from memory cache)：内存缓存具有两个特点，分别是快速读取和时效性： 快速读取：内存缓存会将编译解析后的文件，直接存入该进程的内存中，占据该进程一定的内存资源，以方便下次运行使用时的快速读取。 时效性：一旦该进程关闭，则该进程的内存则会清空。 硬盘缓存(from disk cache)：硬盘缓存则是直接将缓存写入硬盘文件中，读取缓存需要对该缓存存放的硬盘文件进行I/O操作，然后重新解析该缓存内容，读取复杂，速度比内存缓存慢。 在浏览器中，浏览器会在js和图片等文件解析执行后直接存入内存缓存中，那么当刷新页面时只需直接从内存缓存中读取(from memory cache)；而css文件则会存入硬盘文件中，所以每次渲染页面都需要从硬盘读取缓存(from disk cache)。 协商缓存协商缓存就是强制缓存失效后，浏览器携带缓存标识向服务器发起请求，由服务器根据缓存标识决定是否使用缓存的过程。主要有以下两种情况： 协商缓存生效，返回304，如下 协商缓存失效，返回200和请求结果结果，如下 同样，协商缓存的标识也是在响应报文的HTTP头中和请求结果一起返回给浏览器的，控制协商缓存的字段分别有：Last-Modified / If-Modified-Since和Etag / If-None-Match，其中Etag / If-None-Match的优先级比Last-Modified / If-Modified-Since高。 Last-Modified / If-Modified-Since Last-Modified是服务器响应请求时，返回该资源文件在服务器最后被修改的时间，如下。 If-Modified-Since 则是客户端再次发起该请求时，携带上次请求返回的Last-Modified值，通过此字段值告诉服务器该资源上次请求返回的最后被修改时间。服务器收到该请求，发现请求头含有If-Modified-Since字段，则会根据If-Modified-Since的字段值与该资源在服务器的最后被修改时间做对比，若服务器的资源最后被修改时间大于If-Modified-Since的字段值，则重新返回资源，状态码为200；否则则返回304，代表资源无更新，可继续使用缓存文件，如下。 Etag / If-None-Match Etag 是服务器响应请求时，返回当前资源文件的一个唯一标识(由服务器生成)，如下。 If-None-Match 是客户端再次发起该请求时，携带上次请求返回的唯一标识Etag值，通过此字段值告诉服务器该资源上次请求返回的唯一标识值。服务器收到该请求后，发现该请求头中含有If-None-Match，则会根据If-None-Match的字段值与该资源在服务器的Etag值做对比，一致则返回304，代表资源无更新，继续使用缓存文件；不一致则重新返回资源文件，状态码为200，如下。 注：Etag / If-None-Match优先级高于Last-Modified / If-Modified-Since，同时存在则只有Etag / If-None-Match生效。 总结强制缓存优先于协商缓存进行，若强制缓存(Expires和Cache-Control)生效则直接使用缓存，若不生效则进行协商缓存(Last-Modified / If-Modified-Since和Etag / If-None-Match)，协商缓存由服务器决定是否使用缓存，若协商缓存失效，那么代表该请求的缓存失效，重新获取请求结果，再存入浏览器缓存中；生效则返回304，继续使用缓存，主要过程如下： 转载自：https://heyingye.github.io/2018/04/16/%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3%E6%B5%8F%E8%A7%88%E5%99%A8%E7%9A%84%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"browserCache","slug":"browserCache","permalink":"http://www.goyth.com/tags/browserCache/"}]},{"title":"常见跨域方式梳理","slug":"crossDomain","date":"2018-06-29T13:59:32.000Z","updated":"2018-12-02T08:38:42.968Z","comments":true,"path":"2018/06/29/crossDomain/","link":"","permalink":"http://www.goyth.com/2018/06/29/crossDomain/","excerpt":"跨域是由于浏览器同源策略导致的，所以跨域只存在于浏览器端，非浏览器端不存在跨域问题，浏览器对跨域的请求、应答都能正常发送接收，只是浏览器在接收跨域应答时，将应答拦截了，所以我们需要一些额外的处理或设置让浏览器将跨域的应答返回给我们。","text":"跨域是由于浏览器同源策略导致的，所以跨域只存在于浏览器端，非浏览器端不存在跨域问题，浏览器对跨域的请求、应答都能正常发送接收，只是浏览器在接收跨域应答时，将应答拦截了，所以我们需要一些额外的处理或设置让浏览器将跨域的应答返回给我们。 常见的跨域处理方式有： jsonp CORS iframe + postMessage iframe + window.name iframe + location.hash iframe + domain nginx代理 Nodejs中间件 WebSocket jsonp 跨域jsonp 跨域是利用script标签天生具备跨域的特性，script的src属性发起的请求不受浏览器同源策略的限制，所以我们可以动态生成一个script标签对象，将要请求数据的url赋值给script标签的src属性，然后将此script标签append到body中。但是服务端怎么返回数据呢，返回的数据又如何处理呢？此时我们还需要预先写好一个解析数据的函数analyzeData，并将这个函数名通过请求的url一并传给后端，后端收到后，直接请求的数据放在解析函数analyzeData的参数中analyzeData({a:1,b:2,c:3})并返回，当次script标签加载完毕后就会直接执行analyzeData({a:1,b:2,c:3})方法。 12345678// 预先写好一个解析数据的函数function analyzeData(data) &#123; console.log(data)&#125;var sct = document.createElement('script')sct.src = 'http://goyth.com/json?callback=analyzeData'document.body.appendChild(sct) jsop 的优点是兼容性好，能兼容低版本的浏览器，缺点是只支持get请求，不支持其他方式的请求，并且对回调函数的错误处理不太友好。 CORS(跨域资源共享)CORS 全称为跨域资源共享（Cross-origin resource sharing），它是 W3C 用来允许XMLHttpRequest请求跨域的一个标准，也是现在主流的跨域方案。CORS需要浏览器和服务器同时支持。目前，所有浏览器都支持该功能，IE浏览器不能低于IE10。IE8+：IE8/9需要使用XDomainRequest对象来支持CORS。 整个CORS通信过程，都是浏览器自动完成，不需要用户参与。对于开发者来说，CORS通信与同源的AJAX通信没有差别，代码完全一样。浏览器一旦发现AJAX请求跨源，就会自动添加一些附加的头信息，有时还会多出一次附加的请求，但用户不会有感觉。 因此，实现CORS通信的关键是服务器。只要服务器实现了CORS接口，就可以跨源通信。 跨域请求只需要在服务端应答报文头增加一个Access-Control-Allow-Origin字段，该字段是的值要么是请求时Origin字段的值，要么是一个 ，Access-Control-Allow-Origin=Origin字段的值 表示只接受该域的请求，`Access-Control-Allow-Origin=表示接受任意域名的请求。此时的请求是不带Cookie的，如果需要带上Cookie，则需要在发起请求时将XMLHttpRequest实例的withCredentials属性设置为true，在服务端将Access-Control-Allow-Credentials字段设置为true`。 以下内容直接参考阮一峰老师的微博CORS 分为简单请求和非简单请求，简繁请求符合以下要求：（1) 请求方法是以下三种方法之一： HEAD GET POST （2）HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 凡是不同时满足上面两个条件，就属于非简单请求。 简单请求基本流程对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。 下面是一个例子，浏览器发现这次跨源AJAX请求是简单请求，就自动在头信息之中，添加一个Origin字段。 123456GET /cors HTTP/1.1Origin: http://api.bob.comHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... 上面的头信息中，Origin字段用来说明，本次请求来自哪个源（协议 + 域名 + 端口）。服务器根据这个值，决定是否同意这次请求。 如果Origin指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应。浏览器发现，这个回应的头信息没有包含Access-Control-Allow-Origin字段（详见下文），就知道出错了，从而抛出一个错误，被XMLHttpRequest的onerror回调函数捕获。注意，这种错误无法通过状态码识别，因为HTTP回应的状态码有可能是200。 如果Origin指定的域名在许可范围内，服务器返回的响应，会多出几个头信息字段。 1234Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Credentials: trueAccess-Control-Expose-Headers: FooBarContent-Type: text/html; charset=utf-8 上面的头信息之中，有三个与CORS请求相关的字段，都以Access-Control-开头。 （1）Access-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 （2）Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 （3）Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(&#39;FooBar&#39;)可以返回FooBar字段的值。 withCredentials 属性上面说到，CORS请求默认不发送Cookie和HTTP认证信息。如果要把Cookie发到服务器，一方面要服务器同意，指定Access-Control-Allow-Credentials字段。 1Access-Control-Allow-Credentials: true 另一方面，开发者必须在AJAX请求中打开withCredentials属性。 12var xhr = new XMLHttpRequest();xhr.withCredentials = true; 否则，即使服务器同意发送Cookie，浏览器也不会发送。或者，服务器要求设置Cookie，浏览器也不会处理。 但是，如果省略withCredentials设置，有的浏览器还是会一起发送Cookie。这时，可以显式关闭withCredentials。 1xhr.withCredentials = false; 需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 非简单请求预检请求非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 下面是一段浏览器的JavaScript脚本。 12345var url = &apos;http://api.alice.com/cors&apos;;var xhr = new XMLHttpRequest();xhr.open(&apos;PUT&apos;, url, true);xhr.setRequestHeader(&apos;X-Custom-Header&apos;, &apos;value&apos;);xhr.send(); 上面代码中，HTTP请求的方法是PUT，并且发送一个自定义头信息X-Custom-Header。 浏览器发现，这是一个非简单请求，就自动发出一个”预检”请求，要求服务器确认可以这样请求。下面是这个”预检”请求的HTTP头信息。 12345678OPTIONS /cors HTTP/1.1Origin: http://api.bob.comAccess-Control-Request-Method: PUTAccess-Control-Request-Headers: X-Custom-HeaderHost: api.alice.comAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... “预检”请求用的请求方法是OPTIONS，表示这个请求是用来询问的。头信息里面，关键字段是Origin，表示请求来自哪个源。 除了Origin字段，”预检”请求的头信息包括两个特殊字段。 （1）Access-Control-Request-Method 该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法，上例是PUT。 （2）Access-Control-Request-Headers 该字段是一个逗号分隔的字符串，指定浏览器CORS请求会额外发送的头信息字段，上例是X-Custom-Header。 预检请求的回应服务器收到”预检”请求以后，检查了Origin、Access-Control-Request-Method和Access-Control-Request-Headers字段以后，确认允许跨源请求，就可以做出回应。 123456789101112HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:15:39 GMTServer: Apache/2.0.61 (Unix)Access-Control-Allow-Origin: http://api.bob.comAccess-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderContent-Type: text/html; charset=utf-8Content-Encoding: gzipContent-Length: 0Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain 上面的HTTP回应中，关键的是Access-Control-Allow-Origin字段，表示http://api.bob.com可以请求数据。该字段也可以设为星号，表示同意任意跨源请求。 1Access-Control-Allow-Origin: * 如果浏览器否定了”预检”请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。这时，浏览器就会认定，服务器不同意预检请求，因此触发一个错误，被XMLHttpRequest对象的onerror回调函数捕获。控制台会打印出如下的报错信息。 12XMLHttpRequest cannot load http://api.alice.com.Origin http://api.bob.com is not allowed by Access-Control-Allow-Origin. 服务器回应的其他CORS相关字段如下。 1234Access-Control-Allow-Methods: GET, POST, PUTAccess-Control-Allow-Headers: X-Custom-HeaderAccess-Control-Allow-Credentials: trueAccess-Control-Max-Age: 1728000 （1）Access-Control-Allow-Methods 该字段必需，它的值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。注意，返回的是所有支持的方法，而不单是浏览器请求的那个方法。这是为了避免多次”预检”请求。 （2）Access-Control-Allow-Headers 如果浏览器请求包括Access-Control-Request-Headers字段，则Access-Control-Allow-Headers字段是必需的。它也是一个逗号分隔的字符串，表明服务器支持的所有头信息字段，不限于浏览器在”预检”中请求的字段。 （3）Access-Control-Allow-Credentials 该字段与简单请求时的含义相同。 （4）Access-Control-Max-Age 该字段可选，用来指定本次预检请求的有效期，单位为秒。上面结果中，有效期是20天（1728000秒），即允许缓存该条回应1728000秒（即20天），在此期间，不用发出另一条预检请求。 浏览器的正常请求和回应一旦服务器通过了”预检”请求，以后每次浏览器正常的CORS请求，就都跟简单请求一样，会有一个Origin头信息字段。服务器的回应，也都会有一个Access-Control-Allow-Origin头信息字段。 下面是”预检”请求之后，浏览器的正常CORS请求。 1234567PUT /cors HTTP/1.1Origin: http://api.bob.comHost: api.alice.comX-Custom-Header: valueAccept-Language: en-USConnection: keep-aliveUser-Agent: Mozilla/5.0... 上面头信息的Origin字段是浏览器自动添加的。 下面是服务器正常的回应。 12Access-Control-Allow-Origin: http://api.bob.comContent-Type: text/html; charset=utf-8 上面头信息中，Access-Control-Allow-Origin字段是每次回应都必定包含的。 与JSONP的比较CORS与JSONP的使用目的相同，但是比JSONP更强大。 JSONP只支持GET请求，CORS支持所有类型的HTTP请求。JSONP的优势在于支持老式浏览器，以及可以向不支持CORS的网站请求数据。 iframe + postMessagepostMessage是HTML5 XMLHttpRequest Level 2中的API，且是为数不多可以跨域操作的window属性之一，它可用于解决以下方面的问题：a.） 页面和其打开的新窗口的数据传递b.） 多窗口之间消息传递c.） 页面与嵌套的iframe消息传递d.） 上面三个场景的跨域数据传递 以 a.com 域下的 a.html 页面向 b.com 域下 b.html 页面通讯为例 a.com/a.html 123456789101112131415var iframe = document.createElement('iframe')iframe.src = 'http://b.com/b.html'iframe.style.display = 'none'document.body.appendElement(iframe)iframe.onload = function() &#123; let msg = &#123;domain : 'a.html'&#125; iframe.contentWindow.postMessage(msg, 'http://b.com')&#125;window.addEventListener('message', function(msg) &#123; let origin = msg.origin // 消息来源地址 'http://b.com' let data = msg.data // 传送过来的数据 this message is from b.html let source = msg.source // 源window对象 console.log(data) //this message is from b.html&#125;, false) b.com/b.html12345678window.addEventListener('message', function(msg) &#123; let origin = msg.origin // 消息来源地址 'http://a.com' let data = msg.data // 传送过来的数据 &#123;domain : 'a.html'&#125; let source = msg.source // 源window对象 console.log(data) //&#123;domain : 'a.html'&#125;&#125;, false)let data = 'this message is from b.html'window.parent.postMessage(data, 'http://a.html') postMessage的使用方法： otherWindow.postMessage(message, targetOrigin); otherWindow其他窗口的一个引用，比如iframe的contentWindow属性、执行window.open返回的窗口对象、或者是命名过或数值索引的window.frames。 message不受什么限制的将数据对象安全的传送给目标窗口而无需自己序列化。 targetOrigin通过窗口的origin属性来指定哪些窗口能接收到消息事件，其值可以是字符串”“（表示无限制）或者一个URI。在发送消息的时候，如果目标窗口的协议、主机地址或端口这三者的任意一项不匹配targetOrigin提供的值，那么消息就不会被发送；只有三者完全匹配，消息才会被发送。这个机制用来控制消息可以发送到哪些窗口；例如，当用postMessage传送密码时，这个参数就显得尤为重要，必须保证它的值与这条包含密码的信息的预期接受者的origin属性完全一致，来防止密码被恶意的第三方截获。如果你明确的知道消息应该发送到哪个窗口，那么请始终提供一个有确切值的targetOrigin，而不是。不提供确切的目标将导致数据泄露到任何对数据感兴趣的恶意站点。 message 的属性有: data从其他 window 中传递过来的对象。 origin调用 postMessage 时消息发送方窗口的 origin . 这个字符串由 协议、“://“、域名、“ : 端口号”拼接而成。例如 “https://example.org (隐含端口 443)”、“http://example.net (隐含端口 80)”、“http://example.com:8080”。请注意，这个origin不能保证是该窗口的当前或未来origin，因为postMessage被调用后可能被导航到不同的位置。 source对发送消息的窗口对象的引用; 您可以使用此来在具有不同origin的两个窗口之间建立双向通信。 iframe + window.namewindow.name 有一个特性就是，在一个窗口（window）下的所有的页面都是共享一个 window.name 对象，只要是同域的情况下，每个页面都可以对window.name 进行读写，不同域是读取不到的。因此我们可以用一个代理iframe将这个iframe的域设置为要请求数据的域，此时是同域请求，是可以请求到数据的，然后将请求的数据赋值给 window.name 对象，再将iframe的域跳转到当前域，然后读取window.name 的值，就实现了跨域通讯。我们以http://a.com域下的a.html页面向http://b.com域发起一个http://b.com/json请求为例 我们首先创建一个http://b.com域下的代理页面proxy.html，通过proxy.html 去发起http://b.com/json请求，注意此时是同域的所以可以请求成功 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt;let xhr = new XMLHttpRequest()xhr.onreadystatechange = function() &#123; if(xhr.readystate === '4' &amp;&amp; xhr.status === '200') &#123; window.name = xhr.responseText // 将获取到的数据赋值给window.name location.href = 'http://a.com/index.html' // 将iframe 的域设置回http://a.com &#125;&#125;xhr.open('http://b.com/json')xht.send()&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 通过iframe将代理页面proxy.html与a.html放到一个窗口下，这样就可以读取到 proxy.html 页面设置的 window.name 的值。 http://a.com/a.html1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt;let iframe = document.createElement('iframe')let time = 0iframe.onload = function() &#123; if(++time = 2) &#123; var data = iframe.contentWindow.name // 取出window.name console.log(data) &#125;&#125;iframe.src = 'http://b.com/proxy.html'document.body.appendChild(iframe)&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; iframe + location.hash与 iframe + window.name 一样，此方法也是通过一个与请求同域的代理页面去发起请求，然后将请求到的数据放在a.com 域 的hash 部分，赋值给 parent.location.href，这样就可以触发 a.com 域下的 onhashchange 事件，然后通过 location.hash 就可以读取到 hash 部分的数据了 代理页面 http://b.com/proxy.html12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt;let xhr = new XMLHttpRequest()xhr.onreadystatechange = function() &#123; if(xhr.readystate === '4' &amp;&amp; xhr.status === '200') &#123; let hash = JSON.stringify(xhr.responseText) // 将获取到的数据赋值给window.name parent.location.href = 'http://a.com/index.html#'+ hash // 此时会触发父页面的onhashchange事件 // 注意这个地方不能使用parent.location.hash，子页面需要与父页面同域才能修改父页面的location.hash，此时是不同域的 &#125;&#125;xhr.open('http://b.com/json')xht.send()&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; http://a.com/a.html12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt;let iframe = document.createElement('iframe')iframe.src = 'http://b.com/proxy.html'document.body.appendChild(iframe)window.onhashchange = function() &#123; let data = location.hash.slice(1) console.log(data)&#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; iframe + domain这种跨域方式只适用与主域相同的情况下的跨域通信，假如我们现在有两个页面a.html和b.html分别在a.goyth.com和b.goyth.com域下，此时他们的主域都是goyth.com，我们现在只用把两个页面下的 document.domain 都设置成一样，就可以跨域通信了，可以相互读取对方window对象下的数据。但要注意的是，document.domain的设置是有限制的，我们只能把document.domain设置成自身或更高一级的父域，且主域必须相同。 a.goyth.com/a.html123456789&lt;iframe id = \"iframe\" src=\"http://b.goyth.com/b.html\" onload = \"test()\"&gt;&lt;/iframe&gt;&lt;script type=\"text/javascript\"&gt; function test()&#123; var iframe = document.getElementById('￼ifame'); var win = document.contentWindow;//可以获取到iframe里的window对象，但该window对象的属性和方法几乎是不可用的 var doc = win.document;//这里获取不到iframe里的document对象 var name = win.name;//这里同样获取不到window对象的name属性 &#125;&lt;/script&gt; 此时将a.html和b.html的document.domain都设置为goyth.com a.goyth.com/a.html12345678910&lt;iframe id = \"iframe\" src=\"http://b.goyth.com/b.html\" onload = \"test()\"&gt;&lt;/iframe&gt;&lt;script type=\"text/javascript\"&gt; document.domain = 'goyth.com' function test()&#123; var iframe = document.getElementById('￼ifame'); var win = document.contentWindow;//可以获取到iframe里的window对象，但该window对象的属性和方法几乎是不可用的 var doc = win.document;//这里获取不到iframe里的document对象 var name = win.name;//这里同样获取不到window对象的name属性 &#125;&lt;/script&gt; b.goyth.com/b.html1234&lt;script type=\"text/javascript\"&gt; document.domain = 'goyth.com'&lt;/script&gt; nginx代理跨域nginx配置解决iconfont跨域浏览器跨域访问js、css、img等常规静态资源被同源策略许可，但iconfont字体文件(eot|otf|ttf|woff|svg)例外，此时可在nginx的静态资源服务器中加入以下配置。123location / &#123; add_header Access-Control-Allow-Origin *;&#125; nginx反向代理接口跨域跨域原理： 同源策略是浏览器的安全策略，不是HTTP协议的一部分。服务器端调用HTTP接口只是使用HTTP协议，不会执行JS脚本，不需要同源策略，也就不存在跨越问题。 实现思路：通过nginx配置一个代理服务器（域名与domain1相同，端口不同）做跳板机，反向代理访问domain2接口，并且可以顺便修改cookie中domain信息，方便当前域cookie写入，实现跨域登录。 nginx具体配置：123456789101112131415#proxy服务器server &#123; listen 81; server_name www.domain1.com; location / &#123; proxy_pass http://www.domain2.com:8080; #反向代理 proxy_cookie_domain www.domain2.com www.domain1.com; #修改cookie里域名 index index.html index.htm; # 当用webpack-dev-server等中间件代理接口访问nignx时，此时无浏览器参与，故没有同源限制，下面的跨域配置可不启用 add_header Access-Control-Allow-Origin http://www.domain1.com; #当前端只跨域不带cookie时，可为* add_header Access-Control-Allow-Credentials true; &#125;&#125; 1.) 前端代码示例：12345678var xhr = new XMLHttpRequest();// 前端开关：浏览器是否读写cookiexhr.withCredentials = true;// 访问nginx中的代理服务器xhr.open('get', 'http://www.domain1.com:81/?user=admin', true);xhr.send(); 2.) Nodejs后台示例：123456789101112131415161718var http = require('http');var server = http.createServer();var qs = require('querystring');server.on('request', function(req, res) &#123; var params = qs.parse(req.url.substring(2)); // 向前台写cookie res.writeHead(200, &#123; 'Set-Cookie': 'l=a123456;Path=/;Domain=www.domain2.com;HttpOnly' // HttpOnly:脚本无法读取 &#125;); res.write(JSON.stringify(params)); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...'); Nodejs中间件代理跨域node中间件实现跨域代理，原理大致与nginx相同，都是通过启一个代理服务器，实现数据的转发。 非vue框架的跨域（2次跨域）利用node + express + http-proxy-middleware搭建一个proxy服务器。 1.）前端代码示例：12345678var xhr = new XMLHttpRequest();// 前端开关：浏览器是否读写cookiexhr.withCredentials = true;// 访问http-proxy-middleware代理服务器xhr.open('get', 'http://www.domain1.com:3000/login?user=admin', true);xhr.send(); 2.）中间件服务器：123456789101112131415161718192021var express = require('express');var proxy = require('http-proxy-middleware');var app = express();app.use('/', proxy(&#123; // 代理跨域目标接口 target: 'http://www.domain2.com:8080', changeOrigin: true, // 修改响应头信息，实现跨域并允许带cookie onProxyRes: function(proxyRes, req, res) &#123; res.header('Access-Control-Allow-Origin', 'http://www.domain1.com'); res.header('Access-Control-Allow-Credentials', 'true'); &#125;, // 修改响应信息中的cookie域名 cookieDomainRewrite: 'www.domain1.com' // 可以为false，表示不修改&#125;));app.listen(3000);console.log('Proxy server is listen at port 3000...'); 3.）Nodejs后台同（六：nginx） vue框架的跨域（1次跨域）利用node + webpack + webpack-dev-server代理接口跨域。在开发环境下，由于vue渲染服务和接口代理服务都是webpack-dev-server同一个，所以页面与代理接口之间不再跨域，无须设置headers跨域信息了。 webpack.config.js部分配置：123456789101112131415module.exports = &#123; entry: &#123;&#125;, module: &#123;&#125;, ... devServer: &#123; historyApiFallback: true, proxy: [&#123; context: '/login', target: 'http://www.domain2.com:8080', // 代理跨域目标接口 changeOrigin: true, cookieDomainRewrite: 'www.domain1.com' // 可以为false，表示不修改 &#125;], noInfo: true &#125;&#125; WebSocket协议跨域WebSocket protocol是HTML5一种新的协议。它实现了浏览器与服务器全双工通信，同时允许跨域通讯，是server push技术的一种很好的实现。原生WebSocket API使用起来不太方便，我们使用Socket.io，它很好地封装了webSocket接口，提供了更简单、灵活的接口，也对不支持webSocket的浏览器提供了向下兼容。 1.）前端代码：12345678910111213141516171819202122&lt;div&gt;user input：&lt;input type=\"text\"&gt;&lt;/div&gt;&lt;script src=\"./socket.io.js\"&gt;&lt;/script&gt;&lt;script&gt;var socket = io('http://www.domain2.com:8080');// 连接成功处理socket.on('connect', function() &#123; // 监听服务端消息 socket.on('message', function(msg) &#123; console.log('data from server: ---&gt; ' + msg); &#125;); // 监听服务端关闭 socket.on('disconnect', function() &#123; console.log('Server socket has closed.'); &#125;);&#125;);document.getElementsByTagName('input')[0].onblur = function() &#123; socket.send(this.value);&#125;;&lt;/script&gt; 2.）Nodejs socket后台：123456789101112131415161718192021222324252627var http = require('http');var socket = require('socket.io');// 启http服务var server = http.createServer(function(req, res) &#123; res.writeHead(200, &#123; 'Content-type': 'text/html' &#125;); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...');// 监听socket连接socket.listen(server).on('connection', function(client) &#123; // 接收信息 client.on('message', function(msg) &#123; client.send('hello：' + msg); console.log('data from client: ---&gt; ' + msg); &#125;); // 断开处理 client.on('disconnect', function() &#123; console.log('Client socket has closed.'); &#125;);&#125;); 参考链接：http://www.ruanyifeng.com/blog/2016/04/same-origin-policy.htmlhttps://developer.mozilla.org/zh-CN/docs/Web/HTTP/Access_control_CORShttps://www.cnblogs.com/roam/p/7520433.htmlhttp://web.jobbole.com/88519/https://juejin.im/post/5a2f92c65188253e2470f16dhttps://juejin.im/post/5a6320d56fb9a01cb64ee191https://juejin.im/post/58e8c932ac502e4957bde78b","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"cross-domain","slug":"cross-domain","permalink":"http://www.goyth.com/tags/cross-domain/"}]},{"title":"JavaScript之apply、call和bind的模拟实现","slug":"applyAndCall","date":"2018-05-27T09:25:50.000Z","updated":"2018-12-02T08:38:24.458Z","comments":true,"path":"2018/05/27/applyAndCall/","link":"","permalink":"http://www.goyth.com/2018/05/27/applyAndCall/","excerpt":"apply()apply 方法传入两个参数：一个是作为函数上下文的对象，另外一个是作为函数参数所组成的数组。当第一个参数为 null 时，函数上下文为 window。 123456789var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;func.apply(obj, [18, 'male']); // luke 18 male","text":"apply()apply 方法传入两个参数：一个是作为函数上下文的对象，另外一个是作为函数参数所组成的数组。当第一个参数为 null 时，函数上下文为 window。 123456789var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;func.apply(obj, [18, 'male']); // luke 18 male apply模拟实现12345678910111213141516171819202122Function.prototype.apply2 = function(context, arrArgs)&#123; context = context || window; context.fn = this; let args = []; for(let i=0, len=arrArgs.length; i&lt;len; i++)&#123; args.push('arrArgs['+i+']'); &#125; let result = eval('context.fn('+args+')'); delete context.fn; return result;&#125;// 测试一下var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;func.apply2(obj, [18, 'male']); // luke 18 male call()call 方法第一个参数也是作为函数上下文的对象，但是后面传入的是一个参数列表，而不是单个数组。当第一个参数为 null 时，函数上下文也是 window。 123456789var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;func.call(obj, 18, 'male'); // luke 18 male call模拟实现12345678910111213141516171819202122Function.prototype.call2 = function(context)&#123; context = context || window; context.fn = this; let args = []; for(let i=1, len=arguments.length; i&lt;len; i++)&#123; args.push('arguments['+i+']') &#125; let result = eval('context.fn('+args+')'); delete context.fn; return result;&#125;// 测试一下var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;func.call2(obj, 18, 'male'); // luke 18 male bind()bind() 方法会创建一个新函数。当这个新函数被调用时，bind() 的第一个参数将作为它运行时的 this，之后的一序列参数将会在传递的实参前传入作为它的参数。 12345678910var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;let bindfn = func.bind(obj, 18);bindfn('male') // luke 18 male bind模拟实现12345678910111213141516171819202122Function.prototype.bind2 = function()&#123; let context = [].shift.call(arguments) || window; let args = [].slice.call(arguments); let self = this; function Bd()&#123; return self.apply(this instanceof Bd ? this : context, args.concat([].slice.call(arguments))); &#125; Bd.prototype = Object.create(self.prototype); return Bd;&#125;// 测试一下var obj = &#123; name : 'luke'&#125;function func(age, gender)&#123; console.log(this.name + ' ' + age + ' ' + gender);&#125;let bindfn = func.bind2(obj, 18);bindfn('male') // luke 18 male","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/tags/JavaScript/"}]},{"title":"浏览器渲染之回流（Reflow）与重绘（Repaint）","slug":"reflowAndRepaint","date":"2018-05-25T10:39:42.000Z","updated":"2018-12-02T08:40:00.117Z","comments":true,"path":"2018/05/25/reflowAndRepaint/","link":"","permalink":"http://www.goyth.com/2018/05/25/reflowAndRepaint/","excerpt":"浏览器渲染流程浏览器渲染流程如下图所示： 大概可以划分成以下几个步骤： 通过HTML解析器解析HTML文本并构建DOM tree 通过CSS解析器解析CSS样式表并构建CSSOM tree 根据DOM tree 和 CSSOM tree 构建 \bRender tree Render tree 刚构建完后是没有元素节点坐标、尺寸大小等信息的，此时需要通过Reflow(Layout)进行\b布局处理，计算出元素在屏幕上显示的位置，尺寸大小等信息。 遍历渲染树，对每一个元素节点进行绘制（Painting） 回流（Reflow）与重绘（Repaint）就分别发生在第四步和第五步","text":"浏览器渲染流程浏览器渲染流程如下图所示： 大概可以划分成以下几个步骤： 通过HTML解析器解析HTML文本并构建DOM tree 通过CSS解析器解析CSS样式表并构建CSSOM tree 根据DOM tree 和 CSSOM tree 构建 \bRender tree Render tree 刚构建完后是没有元素节点坐标、尺寸大小等信息的，此时需要通过Reflow(Layout)进行\b布局处理，计算出元素在屏幕上显示的位置，尺寸大小等信息。 遍历渲染树，对每一个元素节点进行绘制（Painting） 回流（Reflow）与重绘（Repaint）就分别发生在第四步和第五步 回流（Reflow）和重绘（Repaint）的定义回流（Reflow）对于DOM结构中的各个元素都有自己的盒子（模型），这些都需要浏览器根据各种样式（浏览器的、开发人员定义的等）来计算，并根据计算结果将元素放到它该出现的位置，这个过程称之为reflow。 重绘（Repaint）当各种盒子的位置、大小以及其他属性，例如颜色、字体大小等都确定下来后，浏览器于是便把这些元素都按照各自的特性绘制了一遍，于是页面的内容出现了，这个过程称之为 repaint。 回流（Reflow）和重绘（Repaint）会对性能产生一定的影响，尤其是当引发全局的回流和重绘时。 导致回流（Reflow）和重绘（Repaint）的操作 调整窗口大小 改变字体 增加或者移除样式表 内容变化，比如用户在input框中输入文字 激活 CSS 伪类，比如 :hover (IE 中为兄弟结点伪类的激活) 操作 class 属性 脚本操作 DOM 计算 offsetWidth 和 offsetHeight 属性 设置 style 属性的值 如何尽量避免回流（Reflow）和重绘（Repaint） 不要一条一条地修改 DOM 的样式。与其这样，还不如预先定义好 css 的 class，然后修改 DOM 的 className，即将多次改变样式属性的操作合并成一次操作： 12345678// 不好的写法var left = 10,top = 10;el.style.left = left + \"px\";el.style.top = top + \"px\";el.style.background = '#eee'; // 比较好的写法el.className += \" theclassname\"; 让要操作的元素进行”离线处理”，处理完后一起更新 使用documentFragment对象进行缓存操作,引发一次回流和重绘； 使用display:none技术，只引发两次回流和重绘。原理：由于display属性为none的元素不在渲染树中，对隐藏的元素操 作不会引发其他元素的重排。如果要对一个元素进行复杂的操作时，可以先隐藏它，操作完成后再显示。这样只在隐藏和显示时触发2次重排。 先克隆Dom节点(cloneNode) 修改完后，再用克隆的Dom节点将原来的节点替换掉，只引发一次回流和重绘； 将需要多次重排的元素，position属性设为absolute或fixed，这样此元素就脱离了文档流，它的变化不会影响到其他元素为动画的 HTML 元素，例如动画，那么修改他们的 CSS 是会大大减小 reflow 。因为,它们不影响其他元素的布局，所它他们只会导致重新绘制，而不是一个完整回流。这样消耗会更低 不要用tables布局的一个原因就是tables中某个元素一旦触发reflow就会导致table里所有的其它元素reflow。在适合用table的场合，可以设置table-layout为auto或fixed，这样可以让table一行一行的渲染，这种做法也是为了限制reflow的影响范围。 尽可能的修改层级比较低的 DOM节点。当然，改变层级比较底的 DOM节点有可能会造成大面积的 reflow，但是也可能影响范围很小。因为改变 DOM 树中的一级会导致所有层级的改变，上至根部，下至被改变节点的子节点。这导致大量时间耗费在执行 reflow 上面 不要把 DOM 节点的属性值放在一个循环里当成循环里的变量。不然这会导致大量地读写这个结点的属性。 避免使用CSS的JavaScript表达式，如果css里有expression，每次都会重新计算一遍。","categories":[{"name":"Browser","slug":"Browser","permalink":"http://www.goyth.com/categories/Browser/"}],"tags":[{"name":"Reflow","slug":"Reflow","permalink":"http://www.goyth.com/tags/Reflow/"},{"name":"Repaint","slug":"Repaint","permalink":"http://www.goyth.com/tags/Repaint/"}]},{"title":"N-Sum 问题","slug":"nsum","date":"2018-05-25T09:26:18.000Z","updated":"2018-12-02T08:39:41.948Z","comments":true,"path":"2018/05/25/nsum/","link":"","permalink":"http://www.goyth.com/2018/05/25/nsum/","excerpt":"问题描述给定一个包含多个整数且排好序的数组 nums 和一个目标值 target，判断 nums 中是否存在 N(N&gt;1) 个元素，使得 N 个元素之和与 target 相等？找出所有满足条件且不重复的N元组。 解题思路通过递归降幂将 N-Sum问题 降幂到 2-Sum 问题，然后采用两边加逼的办法求解","text":"问题描述给定一个包含多个整数且排好序的数组 nums 和一个目标值 target，判断 nums 中是否存在 N(N&gt;1) 个元素，使得 N 个元素之和与 target 相等？找出所有满足条件且不重复的N元组。 解题思路通过递归降幂将 N-Sum问题 降幂到 2-Sum 问题，然后采用两边加逼的办法求解 JavaScript 版本12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @param &#123;number[]&#125; nums * @param &#123;number&#125; target * @param &#123;number&#125; n * @param &#123;number[]&#125; result * @param &#123;number[]&#125; results 结果集 */function findNsum(nums, target, n, result, results) &#123; if(n&lt;2 || nums.length &lt; n || target &lt; nums[0] * n || target &gt; nums[nums.length-1] * n) return ; if(n === 2)&#123; let l = 0, r = nums.length - 1; while(l &lt; r)&#123; let s = nums[l] + nums[r]; if(s == target)&#123; results.push(result.concat(nums[l], nums[r])); l++; r--; while(l &lt; r &amp;&amp; nums[l] == nums[l-1])&#123; l++; &#125; while(l&lt;r &amp;&amp; nums[r] == nums[r+1])&#123; r--; &#125; &#125;else if(s &lt; target)&#123; l++; while(l &lt; r &amp;&amp; nums[l] == nums[l-1])&#123; l++; &#125; &#125;else&#123; r--; while(l&lt;r &amp;&amp; nums[r] == nums[r+1])&#123; r--; &#125; &#125; &#125; &#125;else&#123; let len = nums.length - n + 1 for(let i = 0 ; i &lt; len; i++)&#123; if(i == 0 || ( i&gt;0 &amp;&amp; nums[i] != nums[i - 1]))&#123; findNsum(nums.slice(i+1), target - nums[i], n - 1, result.concat(nums[i]), results); &#125; &#125; &#125;&#125; Python 版本12345678910111213141516171819202122232425262728def findNsum(nums, target, N, result, results): if len(nums) &lt; N or N &lt; 2 or target &lt; nums[0]*N or target &gt; nums[-1]*N: # early termination return if N == 2: # two pointers solve sorted 2-sum problem l,r = 0,len(nums)-1 while l &lt; r: s = nums[l] + nums[r] if s == target: results.append(result + [nums[l], nums[r]]) l += 1 r -= 1 while l &lt; r and nums[l] == nums[l-1]: l += 1 while l &lt; r and nums[r] == nums[r+1]: r -= 1 elif s &lt; target: l += 1 while l &lt; r and nums[l] == nums[l-1]: l += 1 else: r -= 1 while l &lt; r and nums[r] == nums[r+1]: r -= 1 else: # recursively reduce N for i in range(len(nums)-N+1): if i == 0 or (i &gt; 0 and nums[i-1] != nums[i]): findNsum(nums[i+1:], target-nums[i], N-1, result+[nums[i]], results)","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"浏览器页面渲染流程梳理","slug":"browserRendering","date":"2018-05-23T09:14:52.000Z","updated":"2018-12-02T08:38:33.848Z","comments":true,"path":"2018/05/23/browserRendering/","link":"","permalink":"http://www.goyth.com/2018/05/23/browserRendering/","excerpt":"浏览器渲染基本流程浏览器渲染流程如下图所示： 图片来源：https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/ 大概可以划分成以下几个步骤： 通过HTML解析器解析HTML文本并构建DOM tree 通过CSS解析器解析CSS样式表并构建CSSOM tree 根据DOM tree 和 CSSOM tree 构建 \bRender tree Render tree 刚构建完后是没有元素节点坐标、尺寸大小等信息的，此时需要通过Layout(Reflow)进行\b布局处理，计算出元素在屏幕上显示的位置，尺寸大小等信息。 遍历渲染树，对每一个元素节点进行绘制（Painting）","text":"浏览器渲染基本流程浏览器渲染流程如下图所示： 图片来源：https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/ 大概可以划分成以下几个步骤： 通过HTML解析器解析HTML文本并构建DOM tree 通过CSS解析器解析CSS样式表并构建CSSOM tree 根据DOM tree 和 CSSOM tree 构建 \bRender tree Render tree 刚构建完后是没有元素节点坐标、尺寸大小等信息的，此时需要通过Layout(Reflow)进行\b布局处理，计算出元素在屏幕上显示的位置，尺寸大小等信息。 遍历渲染树，对每一个元素节点进行绘制（Painting） 解析（Parsing）解析的过程分为两个\b\b步骤：\b词法分析和语法分析。词法分析负责将输入内容分解成一个个有效标记；而语法分析负责根据语言的语法规则分析文档的结构，从而构建解析树。通过词法分析可以将无关的字符（比如空格和换行符）分离出来。 图：从源文档到解析树 解析是一个迭代的过程。通常，解析器会向词法分析器请求一个新标记，并尝试将其与某条语法规则进行匹配。如果发现了匹配规则，解析器会将一个对应于该标记的节点添加到解析树中，然后继续请求下一个标记。 如果没有规则可以匹配，解析器就会将标记存储到内部，并继续请求标记，直至找到可与所有内部存储的标记匹配的规则。如果找不到任何匹配规则，解析器就会引发一个异常。这意味着文档无效，包含语法错误。 转译(Translation)\b很多时候，解析树还不是最终产品。解析通常是在转译过程中使用的，而转译是指将输入文档转换成另一种格式。编译就是这样一个例子。编译器可将源代码编译成机器代码，具体过程是首先将源代码解析成解析树，然后将解析树翻译成机器代码文档。 图：编译流程 HTML解析解析器的输出“解析树”是由 DOM 元素和属性节点构成的树结构。DOM 是文档对象模型 (Document Object Model) 的缩写。它是 HTML 文档的对象表示，同时也是外部内容（例如 JavaScript）与 HTML 元素之间的接口。解析树的根节点是“Document”对象。 DOM 与标记之间几乎是一一对应的关系。比如下面这段标记：12345678&lt;html&gt; &lt;body&gt; &lt;p&gt; Hello World &lt;/p&gt; &lt;div&gt; &lt;img src=\"example.png\"/&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 可翻译成如下的 DOM 树： 图：示例标记的 DOM 树 解析算法HTML5 规范详细地描述了解析算法。此算法由两个阶段组成：标记化和树构建。 标记化是词法分析过程，将输入内容解析成多个标记。HTML 标记包括起始标记、结束标记、属性名称和属性值。 标记生成器识别标记，传递给树构造器，然后接受下一个字符以识别下一个标记；如此反复直到输入的结束。 图：HTML 解析流程（摘自 HTML5 规范） CSS解析和 HTML 不同，CSS 是上下文无关的语法。事实上，CSS 规范定义了 CSS 的词法和语法。 WebKit 使用 Flex 和 Bison 解析器生成器，通过 CSS 语法文件自动创建解析器。Bison 会创建自下而上的移位归约解析器。Firefox 使用的是人工编写的自上而下的解析器。这两种解析器都会将 CSS 文件解析成 StyleSheet 对象，且每个对象都包含 CSS 规则。CSS 规则对象则包含选择器和声明对象，以及其他与 CSS 语法对应的对象。 图：解析 CSS 处理脚本和样式表的顺序脚本网络的模型是同步的。网页解析器遇到 &lt;script&gt; 标记时文档的解析将停止，直到脚本执行完毕。如果脚本是外部的，那么解析过程会停止，直到从网络同步抓取资源完成后再继续。你可以在&lt;script&gt; 标签上添加“defer”属性（&lt;script defer&gt;），这样它就不会停止文档解析，而是等到解析结束才执行。HTML5 增加了一个async属性，可将脚本标记为异步&lt;script async&gt;），以便由其他线程解析和执行。 预解析WebKit 和 Firefox 都进行了这项优化。在执行脚本时，其他线程会解析文档的其余部分，找出并加载需要通过网络加载的其他资源。通过这种方式，资源可以在并行连接上加载，从而提高总体速度。请注意，预解析器不会修改 DOM 树，而是将这项工作交由主解析器处理；预解析器只会解析外部资源（例如外部脚本、样式表和图片）的引用。 样式表另一方面，样式表有着不同的模型。理论上来说，应用样式表不会更改 DOM 树，因此似乎没有必要等待样式表并停止文档解析。但这涉及到一个问题，就是脚本在文档解析阶段会请求样式信息。如果当时还没有加载和解析样式，脚本就会获得错误的回复，这样显然会产生很多问题。这看上去是一个非典型案例，但事实上非常普遍。Firefox 在样式表加载和解析的过程中，会禁止所有脚本。而对于 WebKit 而言，仅当脚本尝试访问的样式属性可能受尚未加载的样式表影响时，它才会禁止该脚本。 Render tree构建 图：Render tree构建 Render tree是由 DOM 和 CSSOM 组合构建而成的。也是页面可视化元素按照其显示顺序而组成的树，是文档的可视化表示。它的作用是让浏览器按照正确的顺序绘制内容。 Firefox 将Render tree中的元素称为“框架”。WebKit 使用的术语是呈现器或呈现对象。呈现器知道如何布局并将自身及其子元素绘制出来。 呈现树和 DOM 树的关系呈现器是和 DOM 元素相对应的，但并非一一对应。非可视化的 DOM 元素不会插入呈现树中，例如“head”元素。如果元素的 display 属性值为“none”，那么也不会显示在呈现树中（但是 visibility 属性值为“hidden”的元素仍会显示）。有一些 DOM 元素对应多个可视化对象。它们往往是具有复杂结构的元素，无法用单一的矩形来描述。例如，“select”元素有 3 个呈现器：一个用于显示区域，一个用于下拉列表框，还有一个用于按钮。如果由于宽度不够，文本无法在一行中显示而分为多行，那么新的行也会作为新的呈现器而添加。另一个关于多呈现器的例子是格式无效的 HTML。根据 CSS 规范，inline 元素只能包含 block 元素或 inline 元素中的一种。如果出现了混合内容，则应创建匿名的 block 呈现器，以包裹 inline 元素。 有一些呈现对象对应于 DOM 节点，但在树中所在的位置与 DOM 节点不同。浮动定位和绝对定位的元素就是这样，它们处于正常的流程之外，放置在树中的其他地方，并映射到真正的框架，而放在原位的是占位框架。 图：呈现树及其对应的 DOM 树 布局（Layout/Reflow）当Render Tree刚构建完时，并不包含元素节点的位置和大小信息。计算这些值的过程称为布局或重排。 HTML 采用基于流的布局模型，这意味着大多数情况下只要一次遍历就能计算出几何信息。处于流中靠后位置元素通常不会影响靠前位置元素的几何特征，因此布局可以按从左至右、从上至下的顺序遍历文档。但是也有例外情况，比如 HTML 表格的计算就需要不止一次的遍历。 坐标系是相对于根框架而建立的，使用的是上坐标和左坐标。 布局是一个递归的过程。它从根呈现器（对应于 HTML 文档的 元素）开始，然后递归遍历部分或所有的框架层次结构，为每一个需要计算的呈现器计算几何信息。 根呈现器的位置左边是 0,0，其尺寸为视口（也就是浏览器窗口的可见区域）。所有的呈现器都有一个“layout”或者“reflow”方法，每一个呈现器都会调用其需要进行布局的子代的 layout 方法。 Dirty 位系统为避免对所有细小更改都进行整体布局，浏览器采用了一种“dirty 位”系统。如果某个呈现器发生了更改，或者将自身及其子代标注为“dirty”，则需要进行布局。 有两种标记：“dirty”和“children are dirty”。“children are dirty”表示尽管呈现器自身没有变化，但它至少有一个子代需要布局。 全局布局和增量布局全局布局是指触发了整个呈现树范围的布局，触发原因可能包括： 影响所有呈现器的全局样式更改，例如字体大小更改。 屏幕大小调整。 布局可以采用增量方式，也就是只对 dirty 呈现器进行布局（这样可能存在需要进行额外布局的弊端）。当呈现器为 dirty 时，会异步触发增量布局。例如，当来自网络的额外内容添加到 DOM 树之后，新的呈现器附加到了呈现树中。 图：增量布局 - 只有 dirty 呈现器及其子代进行布局 绘制在绘制阶段，系统会遍历呈现树，并调用呈现器的“paint”方法，将呈现器的内容显示在屏幕上。绘制工作是使用用户界面基础组件完成的。 全局绘制和增量绘制和布局一样，绘制也分为全局（绘制整个呈现树）和增量两种。在增量绘制中，部分呈现器发生了更改，但是不会影响整个树。更改后的呈现器将其在屏幕上对应的矩形区域设为无效，这导致 OS 将其视为一块“dirty 区域”，并生成“paint”事件。OS 会很巧妙地将多个区域合并成一个。在 Chrome 浏览器中，情况要更复杂一些，因为 Chrome 浏览器的呈现器不在主进程上。Chrome 浏览器会在某种程度上模拟 OS 的行为。展示层会侦听这些事件，并将消息委托给呈现根节点。然后遍历呈现树，直到找到相关的呈现器，该呈现器会重新绘制自己（通常也包括其子代）。 绘制顺序CSS2 规范定义了绘制流程的顺序。绘制的顺序其实就是元素进入堆栈样式上下文的顺序。这些堆栈会从后往前绘制，因此这样的顺序会影响绘制。块呈现器的堆栈顺序如下： 背景颜色 背景图片 边框 子代 轮廓 WebKit 矩形存储在重新绘制之前，WebKit 会将原来的矩形另存为一张位图(Bitmap)，然后只绘制新旧矩形之间的差异部分。 动态变化在发生变化时，浏览器会尽可能做出最小的响应。因此，元素的颜色改变后，只会对该元素进行重绘。元素的位置改变后，只会对该元素及其子元素（可能还有同级元素）进行布局和重绘。添加 DOM 节点后，会对该节点进行布局和重绘。一些重大变化（例如增大“html”元素的字体）会导致缓存无效，使得整个呈现树都会进行重新布局和绘制。 参考链接 https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/ https://www.youtube.com/watch?v=SmE4OwHztCc https://www.youtube.com/watch?v=0IsQqJ7pwhw","categories":[{"name":"Browser","slug":"Browser","permalink":"http://www.goyth.com/categories/Browser/"}],"tags":[{"name":"Browser rendering","slug":"Browser-rendering","permalink":"http://www.goyth.com/tags/Browser-rendering/"}]},{"title":"JavaScript之函数防抖与节流","slug":"debounceAndThrottle","date":"2018-05-10T08:31:07.000Z","updated":"2018-12-02T08:38:47.906Z","comments":true,"path":"2018/05/10/debounceAndThrottle/","link":"","permalink":"http://www.goyth.com/2018/05/10/debounceAndThrottle/","excerpt":"函数防抖（debounce)函数防抖是指在函数调用动作触发n秒后才开始执行，n秒内若再次触发，则重新开始计时，再次等待n秒后才开始执行。如果n秒内不断触发，那就不断重新开始计时，一直等到有一个n秒内没有触发，才开始执行此函数。 根据描述，我们可以用setTimeout来实现一个简单版的防抖函数","text":"函数防抖（debounce)函数防抖是指在函数调用动作触发n秒后才开始执行，n秒内若再次触发，则重新开始计时，再次等待n秒后才开始执行。如果n秒内不断触发，那就不断重新开始计时，一直等到有一个n秒内没有触发，才开始执行此函数。 根据描述，我们可以用setTimeout来实现一个简单版的防抖函数 第一版1234567891011／*** @ fn 回调函数 * @ delay 延迟时间 *／function debounce(fn, delay)&#123; let timer = null; return function()&#123; clearTimeout(timer); timer = setTimeout(fn, delay); &#125;&#125; 由于setTimeout的回调函数内的this是指向window，如果不传参数则argument对象为空，所以我们得修复this的指向，并将argument对象也传给回调函数 第二版123456789101112131415／*** @ fn 回调函数 * @ delay 延迟时间 *／function debounce(fn, delay)&#123; let timer = null; return function()&#123; let context = this, arg = arguments; clearTimeout(timer); timer = setTimeout(function()&#123; fn.apply(context, arg); &#125;, delay); &#125;&#125; 现在我们新增一个立即执行的需求，就是第一次触发后就立即执行，然后再等待n秒后再执行，n秒内如果有触发则重新计时。我们新增一个参数immediate，true表示立即执行，false表示非立即执行 第三版123456789101112131415161718192021222324252627／*** @ fn 回调函数 * @ delay 延迟时间 * @ immediate 是否立即执行 *／function debounce(fn, delay, immediate)&#123; let timer = null; return function()&#123; let context = this, arg = arguments; if(timer)&#123; clearTimeout(timer); &#125; if(immediate)&#123; if(!timer)&#123; fn.apply(context, arg); &#125; timer = setTimeout(function()&#123; timer = null; &#125;, delay); &#125;else&#123; timer = setTimeout(function()&#123; fn.apply(context, arg); &#125;, delay); &#125; &#125;&#125; underscore 实现版本：123456789101112131415161718192021222324252627_.debounce = function(func, wait, immediate) &#123; var timeout, args, context, timestamp, result; var later = function() &#123; var last = _.now() - timestamp; if (last &lt; wait &amp;&amp; last &gt;= 0) &#123; timeout = setTimeout(later, wait - last); &#125; else &#123; timeout = null; if (!immediate) &#123; result = func.apply(context, args); if (!timeout) context = args = null; &#125; &#125; &#125;; return function() &#123; context = this; args = arguments; timestamp = _.now(); var callNow = immediate &amp;&amp; !timeout; if (!timeout) timeout = setTimeout(later, wait); if (callNow) &#123; result = func.apply(context, args); context = args = null; &#125; return result; &#125;;&#125;; 函数节流（throttle）函数节流是指每隔n秒钟就执行一次事件，不管你在n秒内触发了多少次事件，都是每隔n秒才执行一次。 可以用定时器和时间戳两种方式实现 时间戳版本123456789101112131415／*** @ fn 回调函数 * @ wait 间隔时间 *／function throttle(fn, wait)&#123; let pre = 0; return function()&#123; let now = +new Data(); let remain = now - pre; if(remain &gt;= wait || remain &lt;= 0 )&#123; fn.apply(this, arguments); pre = now; &#125; &#125;&#125; 时间戳版本，第一次会立即触发并执行回调函数，但是最后一次触发如果是在最后一个n秒内发生的，则最后一次触发并不会执行回调函数 定时器版本1234567891011121314151617／*** @ fn 回调函数 * @ wait 间隔时间 *／function throttle(fn, wait)&#123; let timer = null; return function()&#123; let context = this, arg = arguments; if(!timer)&#123; timer = setTimeout(function()&#123; fn.apply(context, arg); timer = null; &#125;, wait); &#125; &#125;&#125; 定时器版本第一次触发后会在n秒后再执行回调函数，最后一次触发如果是在最后一个n秒内发生，则最后一次触发也会执行回调函数 我们可以结合两个版本的优点实现一个首次会立即执行，最后一次也会执行的版本 时间戳定时器混合版本123456789101112131415161718192021222324252627282930／*** @ fn 回调函数 * @ wait 间隔时间 *／function throttle(fn, wait)&#123; let pre = 0， timer = null; return function()&#123; let context = this, arg = arguments, now = +new Data(), remaining = wait - (now - pre); if((remaining &lt; 0 || remaining &gt;= wait))&#123; if(!timer)&#123; fn.apply(this, arguments); pre = now; &#125; timer = setTimeout(function()&#123; pre = now; fn.apply(context, arg); &#125;, wait); &#125;else&#123; clearTimeout(timer); timer = setTimeout(function()&#123; pre = now; fn.apply(context, arg); &#125;, remaining); &#125; &#125;&#125; underscore实现版本12345678910111213141516171819202122232425262728293031323334353637／*** @ func 回调函数 * @ wait 间隔时间 * @ options options.leading = true 表示首次立即执行 options.leading = false 表示首次不立即执行 ；* @ options.trailing = true 表示最后一次执行 options.trailing = false 表示最后一次不执行 *／_.throttle = function(func, wait, options) &#123; var context, args, result; var timeout = null; var previous = 0; if (!options) options = &#123;&#125;; var later = function() &#123; previous = options.leading === false ? 0 : _.now(); timeout = null; result = func.apply(context, args); if (!timeout) context = args = null; &#125;; return function() &#123; var now = _.now(); if (!previous &amp;&amp; options.leading === false) previous = now; var remaining = wait - (now - previous); context = this; args = arguments; if (remaining &lt;= 0 || remaining &gt; wait) &#123; if (timeout) &#123; clearTimeout(timeout); timeout = null; &#125; previous = now; result = func.apply(context, args); if (!timeout) context = args = null; &#125; else if (!timeout &amp;&amp; options.trailing !== false) &#123; timeout = setTimeout(later, remaining); &#125; return result; &#125;;&#125;; underscore 的版本有一个很好的地方就是当事件频繁触发时不用一直设置定时器和清除定时器。但是这个版本有两个问题，第一个就是当设置options.leading = false 和 options.trailing = false 首次调用时 remaining = wait if 和 else if 分支都不会进去，这是一个bug；第二个问题就是当设置options.leading = true 和 options.trailing = true 首次调用时 previous = 0 now 等于一个很大的正数，remaining = wait - (now - 0) &lt; 0 数一个很大的负数，timeout = null; !timeout = true 进入 else if 分支的时候，执行timeout = setTimeout(later, remaining);的时候，给定时器设延迟执行，这应该","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"Debounce","slug":"Debounce","permalink":"http://www.goyth.com/tags/Debounce/"},{"name":"Throttle","slug":"Throttle","permalink":"http://www.goyth.com/tags/Throttle/"}]},{"title":"基于 Docker 构建前端持续集成开发环境","slug":"dockerDeploy","date":"2018-05-08T09:24:13.000Z","updated":"2018-12-02T08:39:00.112Z","comments":true,"path":"2018/05/08/dockerDeploy/","link":"","permalink":"http://www.goyth.com/2018/05/08/dockerDeploy/","excerpt":"本文将以一个标准的 Vue 项目为例，完全抛弃传统的前端项目开发部署方式，基于 Docker 容器技术打造一个精简的前端持续集成的开发环境。 前置知识： CI（持续集成）：阮一峰老师的关于 CI 的介绍 Docker： Docker 快速入门 目标： 代码无需在本地构建 只需将代码推上 Github ，自动构建 -&gt; 部署 版本易管理，可轻松回退版本","text":"本文将以一个标准的 Vue 项目为例，完全抛弃传统的前端项目开发部署方式，基于 Docker 容器技术打造一个精简的前端持续集成的开发环境。 前置知识： CI（持续集成）：阮一峰老师的关于 CI 的介绍 Docker： Docker 快速入门 目标： 代码无需在本地构建 只需将代码推上 Github ，自动构建 -&gt; 部署 版本易管理，可轻松回退版本 现在开始进入主题第一步： 初始化 Vue 项目（使用vue官方脚手架 vue-cli) 初始化 vue 项目：vue init webpack vue-docker-demo 在项目根目录下编 Dockerfile Dockerfile 内容如下（如果是构建其他项目，比如 angular4，只需安装 angular-cli，将构建参数改成 ng build 即可，大同小异） 1234567891011121314151617181920212223242526272829# 使用 node 6.10.3 的精简版作为基础镜像FROM node:6.10.3-slim# 安装nginxRUN apt-get update \\ &amp;&amp; apt-get install -y nginx# 指定工作目录WORKDIR /app# 将当前目录下的所有文件拷贝到工作目录下COPY . /app/# 声明运行时容器提供服务端口EXPOSE 80# 1. 安装依赖# 2. 运行 npm run buil# 3. 将 dist 目录的所有文件拷贝到 nginx 的目录下# 4. 删除工作目录的文件，尤其是 node_modules 以减小镜像体积# 由于镜像构建的每一步都会产生新层# 为了减小镜像体积，尽可能将一些同类操作，集成到一个步骤中，如下RUN npm install \\ &amp;&amp; npm run build \\ &amp;&amp; cp -r dist/* /var/www/html \\ &amp;&amp; rm -rf /app# 以前台方式启动 nginx CMD [ &quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;] 初始化 git， 连接并将代码推送到 Github 仓库 第二步：使用 DaoCloud 搭建 Devops 流程（也可以使用其他公有云服务，差别不大，本文将以简单易操作并且对个人开发者免费的 DaoCloud 为例）1. 注册一个 DaoCloud 账号2. 用户中心 -&gt; 代码托管，授权可访问你的 Github 仓库 注册一个 DaoCloud 账号 用户中心 -&gt; 代码托管，授权可访问你的 Github 仓库 在 Devops 项目中新建一个项目，并选择 Github 中对应刚才新创建的项目，点击“开始创建” 先手动构建一个镜像版本，便于下面用这个镜像版本创建一个应用 连接自有主机（没有自有主机的，也可以使用云端测试环境） tips：可以去购买 vultr 等主机，按照指示流程完成主机接入，大概很简单的三四步操作，注意在完成主机连接后，需要手动在主机上启动 docker（service docker start） 太酷了，我们已经将我们的主机接入了 DaoCloud，接下来就来完成最有意思的一步。 创建一个应用 进入【镜像仓库】选择刚才手动构建出来的镜像，并部署最新版本到自由主机或者云端测试环境 稍等片刻，便可以点击“立即部署” 等待完成镜像拉取，待容器列表中的容器起来后，通过地址查看我们部署的 vue 应用 我们已经可以访问到我们刚才部署的 vue 应用了，也表示我们已经将我们的镜像部署到我们的自有主机上去了，此时进入主机查看容器运行情况，可以看到有一个正在运行中的容器，正是我们刚刚部署的，一切都是完美的。 完成到这里，我们可以说已经完成了 99% 的工作，但是还非常重要的最后 1%，那就是真正的自定义持续集成流程，让一切都自动化起来，现在让我们回到刚才 Devops 项目的【流程定义】中去 定义自动构建，自动发布任务回到 Devops 项目里对自动化流程进行定义 首先我们来定义一下自动构建任务，我们设定规则是只有在有新 tag 时才执行构建任务，构建时查找根目录下的 Dockerfile，并以此构建镜像 其次，我们再来定义自动发布任务，当构建任务完成时自动触发自动发布任务，并发布到自有主机的应用上去 至此，我们已经完成了，所有流程控制工作，去测试一下整个流程是否能走通？ 第三步： 测试整个流程回到我们本地，修改一下文本内容，提交，并推送到远端，并且打下我们的第一个版本tag 1.1.1，并将 tag 推送到远端 可以看到，与此同时，我们打 tag 的操作触发了我们定义的 CI 流程 稍等片刻，可以看到我们的应用更新了，对应的版本就是我们刚刚推上去的 1.1.1 我们还可以对应用的版本进行切换，回退等操作 至此，我们在只编写了一个 Dockerfile 配置文件，没有编写脚本的情况下，成功地搭建了一套前端的持续集成开发环境，之后我们只需要专心编写我们的业务代码就好了，打一个 Tag 便可以轻松地完成自动部署上线。 参考链接：https://juejin.im/post/5a142d7b6fb9a0451170c2c7","categories":[{"name":"Docker","slug":"Docker","permalink":"http://www.goyth.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://www.goyth.com/tags/Docker/"}]},{"title":"JavaScript 原型链与继承","slug":"prototypeAndExtend","date":"2018-04-23T04:23:43.000Z","updated":"2018-12-02T08:39:53.395Z","comments":true,"path":"2018/04/23/prototypeAndExtend/","link":"","permalink":"http://www.goyth.com/2018/04/23/prototypeAndExtend/","excerpt":"原型对象无论什么时候，只要创建一个新函数，就会根据一组特定的规则为该函数创建一个 prototype 属性，这个属性指向函数的原型对象。默认情况下，所有原型对象都会自动获得一个 constructor（构造函数）属性，这个属性指向 prototype 属性所在的函数。","text":"原型对象无论什么时候，只要创建一个新函数，就会根据一组特定的规则为该函数创建一个 prototype 属性，这个属性指向函数的原型对象。默认情况下，所有原型对象都会自动获得一个 constructor（构造函数）属性，这个属性指向 prototype 属性所在的函数。 12function Person()&#123;&#125; 当我们用构造函数创建一个实例时，也会为这个实例创建一个 __proto__ 属性，这个__proto__ 属性是一个指针指向构造函数的原型对象 1234let person = new Person();person.__proto__ === Person.prototype // truelet person1 = new Person();person1.__proto__ === Person.prototype // true 由于同一个构造函数创建的所有实例对象的__proto__ 属性都指向这个构造函数的原型对象，因此所有的实例对象都会共享构造函数的原型对象上所有的属性和方法，一旦原型对象上的属性或方法发生改变，所有的实例对象都会受到影响。 1234567891011function Person()&#123;&#125;Person.prototype.name = \"Luke\";Person.prototype.age = 18;let person1 = new Person();let person2 = new Person();alert(person1.name) // \"Luke\"alert(person2.name) // \"Luke\"Person.prototype.name = \"Jack\";alert(person1.name) // \"Jack\"alert(person2.name) // \"Jack\" 重写原型对象我们经常用一个包含所有属性和方法的对象字面量来重写整个原型对象，如下面的例子所示 12345678910function Person()&#123;&#125;Person.prototype = &#123; name : \"Luke\", age : 18, job : \"Software Engineer\", sayName : function()&#123; alert(this.name) &#125;&#125; 在上面的代码中，我们将 Person.prototype 设置为一个新对象，而这个对象中没有constructor属性，这导致 constructor 属性不再指向 Person，而是指向 Object。 123let friend = new Person();alert(friend.constructor === Person); //false alert(friend.constructor === Object); //true 如果 constructor 的值很重要，我们可以像下面这样特意将它设置回设置回适当的值 1234567891011function Person()&#123;&#125;Person.prototype = &#123; constructor : Person, name : \"Luke\", age : 18, job : \"Software Engineer\", sayName : function()&#123; alert(this.name) &#125;&#125; 原型链及原型链继承每个构造函数都有一个原型对象，原型对象都包含一个指向构造函数的指针(constructor)，而实例都包含一个指向原型对象的内部指针(__proto__)。那么，假如我们让原型对象等于另一个类型的实例，结果会怎么样呢？显然，此时的原型对象将包含一个指向另一个原型的指针，相应地，另一个原型中也包含着一个指向另一个构造函数的指针。假如另一个原型又是另一个构造函数的实例，那么上述关系依然成立，如此层层递进，就构成了实例与原型的链条。这就是所谓的原型链的基本概念。 1234567891011121314151617181920212223function Super()&#123; this.property = true;&#125;Super.prototype.getSuperValue = function()&#123; return this.property;&#125;function Sub()&#123; this.subproperty = false;&#125;Sub.prototype = new Super(); //继承了 Super Sub.prototype.getSubValue = function ()&#123; return this.subproperty;&#125;let instance = new Sub();console.log(instance.getSuperValue()); //trueconsole.log(instance.__proto__ === Sub.prototype); //trueconsole.log(Sub.prototype.__proto__ === Super.prototype); //true 上面的代码中Sub.prototype = new Super();通过创建Super的实例，并将该实例赋值给Sub.prototype来实现继承。此时存在于Super的实例和原型对象中的所有属性和方法，也都存在于Sub.prototype中。instanse的__proto__属性指向Sub的原型对象Sub.prototype，Sub原型对象的__proto__属性又指向Super的原型对象Super.prototype。 原型链搜索机制当访问一个实例的属性时，首先会在该实例中搜索该属性。如果没有找到该属性，则会继续搜索实例的原型。在通过原型链继承的情况下，搜索过程就得以沿着原型链继续向上查找，直到找到该属性为止，或者搜索到最高级的原型链Object.prototype中，任然没有找到则返回undefined。就拿上面的例子来说，调用instance.getSuperValue()会经历三个搜索步骤：1）搜索实例；2）搜索Sub.prototype;3）搜索Super.prototype，最后一步才会找到该方法。在找不到属性或方法的情况下，搜索过程总是要一环一环地前行到原型链的末端才会停下。 原型链问题原型链继承最大的问题是来自包含引用类型值的原型。引用类型值的原型属性会被所有实例共享。而这正是为什么要在构造函数中，而不是原型对象中定义属性的原因。在通过原型来实现继承时，原型实际上会另一个类型的实例。于是，原先的实例属性也就顺理成章地变成了现在的原型属性了。 123456789101112131415function Super()&#123; this.colors = [\"red\", \"blue\", \"green\"];&#125;function Sub()&#123;&#125;Sub.prototype = new Super(); // 继承了Superlet instance1 = new Sub();instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"let instance2 = new Sub();alert(instance2.colors); //\"red, blue, green, black\" 上面的代码中，Super 构造函数定义了一个colors 属性，该属性是一个数组。Super 的每个实例都会有各自包含自己数组的colors 属性。当Sub 通过原型链继承了Super之后，Sub.prototype 就变成了Super 的一个实例，因此它也拥有了一个它自己的colors 属性。结果是所有的Sub 实例都会共享这一个colors 属性。原型链的第二个问题是没有办法在不影响所有对象实例的情况下，给超类的构造函数传递参数。 构造函数继承（经典继承）即在子类构造函数的中调用父类构造函数，此时当构建一个子类实例时，此实例也会拥有父类实例的属性和方法。 1234567891011121314function Super()&#123; this.colors = [\"red\", \"blue\", \"green\"];&#125;function Sub()&#123; Super.call(this, name); //继承了Super&#125;let instance1 = new Sub();instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"let instance2 = new Sub();alert(instance2.colors); //\"red, blue, green\" 上面的代码，当构建Sub的实例时，也会调用Super 的构造函数，这样就会在新Sub对象上执行Super()函数中定义的所有对象初始化代码。结果，Sub 的每个实例就都会具有自己的colors 属性的副本了。 构造函数继承问题如果仅仅是借用构造函数，那么也将无法避免构造函数模式存在的问题————方法都在构造函数中定义，因此函数服用就无从谈起。而且，在超类原型中定义的方法，对子类而已也是不可见的。 组合继承是指将原型链和构造函数的相结合，发挥二者之长的一种继承模式。其思路是使用原型链实现对原型属性和方法的继承，而通过借用构造函数来实现对实例属性的继承。这样，即通过在原型上定义方法实现了函数复用，又能够保证每个实例都有它自己的属性。 123456789101112131415161718192021222324252627282930function Super(name)&#123; this.name = name; this.colors = [\"red\", \"blue\", \"green\"];&#125;Super.prototype.sayName = function ()&#123; alert(this.name);&#125;;function Sub(name, age)&#123; Super.call(this, name); //继承了Super 属性 (第二次调用Sup构造函数) this.age = age;&#125;Sub.prototype = new Super(); // 继承了Super 原型链上的方法 (第一次调用Sup构造函数)Sub.prototype.constructor = Sub;Sub.prototype.sayAge = function ()&#123; alert(this.age);&#125;;var instance1 = new Sub(\"Luke\", 18);instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"instance1.sayName(); //\"Luke\"instance1.sayAge() //18var instance2 = new Sub(\"Jack\", 20);alert(instance2.colors); //\"red, blue, green\"instance2.sayName(); //\"Jack\"instance2.sayAge() //20 在上面的例子中，Sup构造函数定义了两个属性：name和colors。Sup的原型定义了一个方法sayName()。Sub构造函数在调用Sup构造函数时传入了name参数，紧接着又定义了它自己的属性age。然后，将Sup的实例赋值给Sub的原型，然后又在该新原型上定义了sayAge()方法。这样就可以让两个不同的Sub 实例即分别拥有自己的属性————包括colors 属性，又可以使用相同的方法了。组合继承避免了原型链和构造函数的缺陷，融合了它们的优点，是JavaScript中最常用的继承模式。但是美中不足的是，上面的代码中调用了两次父类构造函数。Sub.prototype = new Super(); 第一次调用父类构造函数时，将Sup父类构造函数的实例赋值给了Sub子类的原型对象Sub.prototype。此时也会将父类构造函数实例上的属性赋值给子类的原型对象Sub.prototype。而第二次是在子类的构造函数中调用父类的构造函数 Super.call(this)，此时会将父类构造函数实例上的属性赋值给子类的构造函数的实例。根据原型链搜索原则，实例上的属性会屏蔽原型链上的属性。因此我们没有必要将父类构造函数实例的属性赋值给子类的原型对象，这是浪费资源而又没有意义的行为。 优化后的组合继承12345678910111213141516171819202122232425262728293031323334function Super(name)&#123; this.name = name; this.colors = [\"red\", \"blue\", \"green\"];&#125;Super.prototype.sayName = function ()&#123; alert(this.name);&#125;;function Sub(name, age)&#123; Super.call(this, name); //继承了Super 属性 this.age = age;&#125;function F()&#123;&#125;F.prototype = Super.prototype; Sub.prototype = new F(); // 继承了Super 原型链上的方法Sub.prototype.constructor = Sub;Sub.prototype.sayAge = function ()&#123; alert(this.age);&#125;;var instance1 = new Sub(\"Luke\", 18);instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"instance1.sayName(); //\"Luke\"instance1.sayAge() //18var instance2 = new Sub(\"Jack\", 20);alert(instance2.colors); //\"red, blue, green\"instance2.sayName(); //\"Jack\"instance2.sayAge() //20 上面的例子通过将父类的原型对象直接赋值给一个中间构造函数的原型对象，然后将这个中间构造函数的实例赋值给子类的原型对象Sub.prototype，从而完成原型链继承。它的高效性体现在只调用了一个父类构造函数Super，并且原型链保持不变。还有一种简便的写法是采用ES5的Object.create()方法来替代中间构造函数，其实原理都是一样的 1234567891011121314151617181920212223242526272829303132333435363738function Super(name)&#123; this.name = name; this.colors = [\"red\", \"blue\", \"green\"];&#125;Super.prototype.sayName = function ()&#123; alert(this.name);&#125;;function Sub(name, age)&#123; Super.call(this, name); //继承了Super 属性 this.age = age;&#125;/*function F()&#123;&#125;F.prototype = Super.prototype; Sub.prototype = new F(); // 继承了Super 原型链上的方法Sub.prototype.constructor = Sub;*///这行代码的原理与上面注释的代码是一样的Sub.prototype = Object.create(Super.prototype, &#123;constructor: &#123;value: Sub&#125;&#125;)Sub.prototype.sayAge = function ()&#123; alert(this.age);&#125;;var instance1 = new Sub(\"Luke\", 18);instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"instance1.sayName(); //\"Luke\"instance1.sayAge() //18var instance2 = new Sub(\"Jack\", 20);alert(instance2.colors); //\"red, blue, green\"instance2.sayName(); //\"Jack\"instance2.sayAge() //20 更简单的继承方式还有一种更简单的继承方法，就是直接将子类的原型对象(prototype)上的__proto__指向父类的的原型对象(prototype)，这种方式没有改变子类的原型对象，所\b以子类原型对象\b上的constructor属性还是\b指向子类的构造函数，而且当子类的实例在子类的原型对象上没有搜索到\b对应的属性或方法时，它会通过子类原型对象上的__proto__属性，继续在父类的\b原型对象上搜索对应的属性或方法 12345678910111213141516171819202122232425262728function Super(name)&#123; this.name = name; this.colors = [\"red\", \"blue\", \"green\"];&#125;Super.prototype.sayName = function ()&#123; alert(this.name);&#125;;function Sub(name, age)&#123; Super.call(this, name); //继承了Super 属性 this.age = age;&#125;Sub.prototype.__proto__ = Super.prototypeSub.prototype.sayAge = function ()&#123; alert(this.age);&#125;;var instance1 = new Sub(\"Luke\", 18);instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"instance1.sayName(); //\"Luke\"instance1.sayAge() //18var instance2 = new Sub(\"Jack\", 20);alert(instance2.colors); //\"red, blue, green\"instance2.sayName(); //\"Jack\"instance2.sayAge() //20 Object.setPrototypeOf()Object.setPrototypeOf()是ECMAScript 6最新草案中的方法，相对于 Object.prototype.proto ，它被认为是修改对象原型更合适的方法 123456789101112131415161718192021222324252627282930function Super(name)&#123; this.name = name; this.colors = [\"red\", \"blue\", \"green\"];&#125;Super.prototype.sayName = function ()&#123; alert(this.name);&#125;;function Sub(name, age)&#123; Super.call(this, name); //继承了Super 属性 this.age = age;&#125;//Sub.prototype.__proto__ = Super.prototypeObject.setPrototypeOf(Sub.prototype, Super.prototype)Sub.prototype.sayAge = function ()&#123; alert(this.age);&#125;;var instance1 = new Sub(\"Luke\", 18);instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"instance1.sayName(); //\"Luke\"instance1.sayAge() //18var instance2 = new Sub(\"Jack\", 20);alert(instance2.colors); //\"red, blue, green\"instance2.sayName(); //\"Jack\"instance2.sayAge() //20 类的静态方法继承上面所有的继承方法都没有实现类的静态方法继承，而在ES6的\bclass继承中，子类是\b可以继承父类的静态方法的。我们可通过Object.setPrototypeOf()\b来实现\b类的静态方法继承，非常简单1Object.setPrototypeOf(Sub, Super) 123456789101112131415161718192021222324252627282930313233343536function Super(name)&#123; this.name = name; this.colors = [\"red\", \"blue\", \"green\"];&#125;Super.prototype.sayName = function ()&#123; alert(this.name);&#125;;Super.staticFn = function()&#123; alert('Super.staticFn')&#125;function Sub(name, age)&#123; Super.call(this, name); //继承了Super 属性 this.age = age;&#125;//Sub.prototype.__proto__ = Super.prototypeObject.setPrototypeOf(Sub.prototype, Super.prototype)Object.setPrototypeOf(Sub, Super) // 继承父类的静态\b属性或方法\bSub.staticFn() // \"Super.staticFn\"Sub.prototype.sayAge = function ()&#123; alert(this.age);&#125;;var instance1 = new Sub(\"Luke\", 18);instance1.colors.push(\"black\");alert(instance1.colors); //\"red, blue, green, black\"instance1.sayName(); //\"Luke\"instance1.sayAge() //18var instance2 = new Sub(\"Jack\", 20);alert(instance2.colors); //\"red, blue, green\"instance2.sayName(); //\"Jack\"instance2.sayAge() //20 这大概就是最终的理想继承方式吧。","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"Prototype","slug":"Prototype","permalink":"http://www.goyth.com/tags/Prototype/"},{"name":"Extend","slug":"Extend","permalink":"http://www.goyth.com/tags/Extend/"}]},{"title":"JS 的正则表达式","slug":"JSRegExp","date":"2018-04-01T08:22:03.000Z","updated":"2018-12-02T08:39:15.759Z","comments":true,"path":"2018/04/01/JSRegExp/","link":"","permalink":"http://www.goyth.com/2018/04/01/JSRegExp/","excerpt":"正则表达式一种几乎可以在所有的程序设计语言里和所有的计算机平台上使用的文字处理工具。它可以用来查找特定的信息（搜索），也可以用来查找并编辑特定的信息（替换）。核心是 匹配，匹配位置或者匹配字符","text":"正则表达式一种几乎可以在所有的程序设计语言里和所有的计算机平台上使用的文字处理工具。它可以用来查找特定的信息（搜索），也可以用来查找并编辑特定的信息（替换）。核心是 匹配，匹配位置或者匹配字符 先简单的介绍一下语法基本元字符 .： 匹配除了换行符之外的任何单个字符 \\ ： 在非特殊字符之前的反斜杠表示下一个字符是特殊的，不能从字面上解释。例如，没有前\\的&#39;b&#39;通常匹配小写&#39;b&#39;，无论它们出现在哪里。如果加了&#39;\\&#39;,这个字符变成了一个特殊意义的字符，反斜杠也可以将其后的特殊字符，转义为字面量。例如，模式 /a*/ 代表会匹配 0 a。相反，模式 /a\\*/ 将 ‘ * ‘ 的特殊性移除，从而可以匹配像 &quot;a*&quot; 这样的字符串。 | ： 逻辑或操作符 [ ] ：定义一个字符集合，匹配字符集合中的一个字符，在字符集合里面像 . ，\\这些字符都表示其本身 [^ ] ：对上面一个集合取非 - ：定义一个区间，例如[A-Z]，其首尾字符在 ASCII 字符集里面 数量元字符 {m,n} ：匹配前面一个字符至少 m 次至多 n 次重复，还有{m}表示匹配 m 次，{m,}表示至少 m 次 + ： 匹配前面一个表达式一次或者多次，相当于 {1,}，记忆方式追加(+)，起码得有一次 * ： 匹配前面一个表达式零次或者多次，相当于 {0,}，记忆方式乘法(*)，可以一次都没有 ? ： 单独使用匹配前面一个表达式零次或者一次，相当于 {0,1}，记忆方式，有吗？，有(1)或者没有(1)，如果跟在任何量词*, +, ?, {} 后面的时候将会使量词变为非贪婪模式（尽量匹配少的字符），默认是使用贪婪模式。比如对 “123abc” 应用 /\\d+/ 将会返回 “123”，如果使用 /\\d+?/,那么就只会匹配到 “1”。 位置元字符 ^ ： 单独使用匹配表达式的开始 \\$ ： 匹配表达式的结束 \\b ：匹配单词边界 \\B ：匹配非单词边界 (?=p) ：匹配 p 前面的位置 (?!p) ：匹配不是 p 前面的位置 标志字符 g : 全局搜索 记忆方式global i ：不区分大小写 记忆方式 ignore m ：多行搜索 在 js 中的使用支持正则的 String 对象的方法 searchsearch 接受一个正则作为参数，如果参入的参数不是正则会隐式的使用 new RegExp(obj)将其转换成一个正则，返回匹配到子串的起始位置，匹配不到返回-1 matchmatch 接受参数和上面的方法一致。返回值是依赖传入的正则是否包含 g ，如果没有 g 标识，那么 match 方法对 string 做一次匹配，如果没有找到任何匹配的文本时，match 会返回 null ，否则，会返回一个数组，数组第 0 个元素包含匹配到的文本，其余元素放的是正则捕获的文本，数组还包含两个对象，index 表示匹配文本在字符串中的位置，input 表示被解析的原始字符串。如果有 g 标识，则返回一个数组，包含每一次的匹配结果 123456789101112131415161718var str = 'For more information, see Chapter 3.4.5.1'; var re = /see (chapter \\d+(\\.\\d)*)/i; var found = str.match(re); console.log(found); // (3) [\"see Chapter 3.4.5.1\", \"Chapter 3.4.5.1\", \".1\", index: 22, input: \"For more information, see Chapter 3.4.5.1\"] // 0:\"see Chapter 3.4.5.1\" // 1:\"Chapter 3.4.5.1\" // 2:\".1\" // index:22 // input:\"For more information, see Chapter 3.4.5.1\" // length:3 // __proto__:Array(0) // 'see Chapter 3.4.5.1' 是整个匹配。 // 'Chapter 3.4.5.1' 被'(chapter \\d+(\\.\\d)*)'捕获。 // '.1' 是被'(\\.\\d)'捕获的最后一个值。 // 'index' 属性(22) 是整个匹配从零开始的索引。 // 'input' 属性是被解析的原始字符串。 123456var str = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';var regexp = /[A-E]/gi;var matches_array = str.match(regexp);console.log(matches_array);// ['A', 'B', 'C', 'D', 'E', 'a', 'b', 'c', 'd', 'e'] replacereplace 接受两个参数，第一个是要被替换的文本，可以是正则也可以是字符串，如果是字符串的时候不会被转换成正则，而是作为检索的直接量文本。第二个是替换成的文本，可以是字符串或者函数，字符串可以使用一些特殊的变量来替代前面捕获到的子串 变量名 代表的值 $$ 插入一个 “$”。 $&amp; 插入匹配的子串。 $` 插入当前匹配的子串左边的内容。 $’ 插入当前匹配的子串右边的内容。 $n 假如第一个参数是 RegExp对象，并且 n 是个小于100的非负整数，那么插入第 n 个括号匹配的字符串。 12345var re = /(\\w+)\\s(\\w+)/;var str = \"John Smith\";var newstr = str.replace(re, \"$2, $1\");// Smith, Johnconsole.log(newstr); 如果是函数的话，函数入参如下，返回替换成的文本 变量名 代表的值 match 匹配的子串。（对应于上述的$&amp;。） p1,p2,… 假如replace()方法的第一个参数是一个RegExp 对象，则代表第n个括号匹配的字符串。（对应于上述的$1，$2等。） offset 匹配到的子字符串在原字符串中的偏移量。（比如，如果原字符串是“abcd”，匹配到的子字符串是“bc”，那么这个参数将是1） string 被匹配的原字符串。 123456function replacer(match, p1, p2, p3, offset, string) &#123; // p1 is nondigits, p2 digits, and p3 non-alphanumerics return [p1, p2, p3].join(' - ');&#125;var newString = 'abc12345#$*%'.replace(/([^\\d]*)(\\d*)([^\\w]*)/, replacer);// newString abc - 12345 - #$*% split接受两个参数，返回一个数组。第一个是用来分割字符串的字符或者正则，如果是空字符串则会将元字符串中的每个字符以数组形式返回，第二个参数可选作为限制分割多少个字符，也是返回的数组的长度限制。有一个地方需要注意，用捕获括号的时候会将匹配结果也包含在返回的数组中 123456789var myString = \"Hello 1 word. Sentence number 2.\";var splits = myString.split(/\\d/);console.log(splits);// [ \"Hello \", \" word. Sentence number \", \".\" ]splits = myString.split(/(\\d)/);console.log(splits);// [ \"Hello \", \"1\", \" word. Sentence number \", \"2\", \".\" ] 正则对象的方法 test接受一个字符串参数，如果正则表达式与指定的字符串匹配返回 true 否则返回 false exec同样接受一个字符串为参数，返回一个数组，其中存放匹配的结果。如果未找到匹配，则返回值为 null。匹配时，返回值跟 match 方法没有 g 标识时是一样的。数组第 0 个表示与正则相匹配的文本，后面 n 个是对应的 n 个捕获的文本，最后两个是对象 index 和 input同时它会在正则实例的 lastIndex 属性指定的字符处开始检索字符串 string。当 exec() 找到了与表达式相匹配的文本时，在匹配后，它将把正则实例的 lastIndex 属性设置为匹配文本的最后一个字符的下一个位置。有没有 g 标识对单词执行 exec 方法是没有影响的，只是有 g 标识的时候可以反复调用 exec() 方法来遍历字符串中的所有匹配文本。当 exec() 再也找不到匹配的文本时，它将返回 null，并把 lastIndex 属性重置为 0。 123456789101112131415161718var string = \"2017.06.27\";var regex2 = /\\b(\\d+)\\b/g;console.log( regex2.exec(string) );console.log( regex2.lastIndex);console.log( regex2.exec(string) );console.log( regex2.lastIndex);console.log( regex2.exec(string) );console.log( regex2.lastIndex);console.log( regex2.exec(string) );console.log( regex2.lastIndex);// =&gt; [\"2017\", \"2017\", index: 0, input: \"2017.06.27\"]// =&gt; 4// =&gt; [\"06\", \"06\", index: 5, input: \"2017.06.27\"]// =&gt; 7// =&gt; [\"27\", \"27\", index: 8, input: \"2017.06.27\"]// =&gt; 10// =&gt; null// =&gt; 0 其中正则实例lastIndex属性，表示下一次匹配开始的位置。 比如第一次匹配了“2017”，开始下标是0，共4个字符，因此这次匹配结束的位置是3，下一次开始匹配的位置是4。 从上述代码看出，在使用exec时，经常需要配合使用while循环： 123456789var string = \"2017.06.27\";var regex2 = /\\b(\\d+)\\b/g;var result;while ( result = regex2.exec(string) ) &#123; console.log( result, regex2.lastIndex );&#125;// =&gt; [\"2017\", \"2017\", index: 0, input: \"2017.06.27\"] 4// =&gt; [\"06\", \"06\", index: 5, input: \"2017.06.27\"] 7// =&gt; [\"27\", \"27\", index: 8, input: \"2017.06.27\"] 10 正则的匹配字符匹配精确匹配就不说了，比如/hello/，也只能匹配字符串中的&quot;hello&quot;这个子串。正则表达式之所以强大，是因为其能实现模糊匹配。 匹配多种数量用{m,n}来匹配多种数量，其他几种形式(+*?)都可以等价成这种。比如 123var regex = /ab&#123;2,5&#125;c/g;var string = \"abc abbc abbbc abbbbc abbbbbc abbbbbbc\";console.log( string.match(regex) ); // [\"abbc\", \"abbbc\", \"abbbbc\", \"abbbbbc\"] 贪婪和非贪婪默认贪婪 123var regex = /\\d&#123;2,5&#125;/g;var string = \"123 1234 12345 123456\";console.log( string.match(regex) ); // [\"123\", \"1234\", \"12345\", \"12345\"] 两次后面加一个 ？ 就可以表示非贪婪，非贪婪时 123var regex = /\\d&#123;2,5&#125;?/g;var string = \"123 1234 12345 123456\";console.log( string.match(regex) ); // [\"12\", \"12\", \"34\", \"12\", \"34\", \"12\", \"34\", \"56\"] 匹配多种情况用字符组[]来匹配多种情况，其他几种形式(\\d\\D\\s\\S\\w\\W)都可以等价成这种。比如123var regex = /a[123]b/g;var string = \"a0b a1b a2b a3b a4b\";console.log( string.match(regex) ); // [\"a1b\", \"a2b\", \"a3b\"] 如果字符组里面字符特别多的话可以用-来表示范围，比如[123456abcdefGHIJKLM]，可以写成[1-6a-fG-M]，用[^0-9]表示非除了数字以外的字符多种情况还可以是多种分支，用管道符来连接|，比如 123var regex = /good|goodbye/g;var string = \"goodbye\";console.log( string.match(regex) ); // [\"good\"] 这个例子可以看出分支结构也是惰性的，匹配到了就不再往后尝试了。 例子掌握这两种方式就可以解决比较简单的正则问题了。 最多保留2位小数的数字/^([1-9]\\d*|0)(\\.\\d{1,2})?$/ 电话号码/(\\+86)?1\\d{10}/ 身份证/^(\\d{15}|\\d{17}([xX]|\\d))$/ 位置匹配什么是位置位置是相邻字符之间的，比如，有一个字符串 hello ，这个字符串一共有6个位置 *h*e*l*l*o* ， *代表位置 上面说到了 6 种位置元字符 ^，$ 匹配字符的开头和结尾，比如/^hello$/ 匹配一个字符串，要符合这样的条件，字符串开头的位置，紧接着是 h 然后是 e,l,l,o 最后是字符串结尾的位置位置还可以被替换成字符串，比如&#39;hello&#39;.replace(/^|$/g, &#39;#&#39;) 结果是 #hello# /b，/B 匹配单词边界和非单词边界，单词边界具体指 \\w([a-zA-Z0-9_]) 和 \\W 之间的位置，包括 \\w 和 ^ 以及 $ 之间的位置，比如&#39;hello word [js]_reg.exp-01&#39;.replace(/\\b/g, &#39;#&#39;) 结果是#hello# #word# [#js#]#_reg#.#exp#-#01# (?=p)，(?!p) 匹配 p 前面的位置和不是 p 前面位置，比如&#39;hello&#39;.replace(/(?=l)/g, &#39;#&#39;) 结果是 he#l#lo&#39;hello&#39;.replace(/(?!l)/g, &#39;#&#39;) 结果是 #h#ell#o# 位置的特性字符与字符之间的位置可以是多个。在理解上可以将位置理解成空字符串 &#39;&#39;，比如hello 可以是一般的 &#39;&#39; + &#39;h&#39; + &#39;e&#39; + &#39;l&#39; + &#39;l&#39; + &#39;o&#39; + &#39;&#39;，也可以是 &#39;&#39; + &#39;&#39; + &#39;&#39; + &#39;&#39; + &#39;h&#39; + &#39;e&#39; + &#39;l&#39; + &#39;l&#39; + &#39;o&#39; + &#39;&#39;，所以/^h\\Be\\Bl\\Bl\\Bo$/.test(&#39;hello&#39;) 结果是 true，/^^^h\\B\\B\\Be\\Bl\\Bl\\Bo$$$/.test(&#39;hello&#39;) 结果也是 true 例子-. 千分位，将 123123123 转换成 123,123,123数字是从后往前数，也就是以一个或者多个3位数字结尾的位置换成 &#39;,&#39; 就好了，写成正则就是123123213.replace(/(?=(\\d{3})+$)/g, &#39;,&#39;) 但是这样的话会在最前面也加一个 &#39;,&#39; 这明显是不对的。所以还得继续改一下正则要求匹配到的位置不是开头，可以用 /(?!^)(?=(\\d{3})+$)/g 来表示。换种思路来想，能不能是以数字开头然后加上上面的条件呢，得出这个正则 /\\d(?=(\\d{3})+$)/g，但是这个正则匹配的结果是 12,12,123，发现这个正则匹配的不是位置而是字符，将数字换成了 &#39;,&#39; 可以得出结论，如果要求一个正则是匹配位置的话，那么所有的条件必须都是位置。 分组分组主要是括号的使用 分组和分支结构在分支结构中，括号是用来表示一个整体的，(p1|p2)，比如要匹配下面的字符串 12I love JavaScriptI love Regular Expression 可以用正则/^I love (JavaScript|Regular Expression)$/ 而不是 /^I love JavaScript|Regular Expression$/表示一个整体还比如 /(abc)+/ 一个或者多个 abc 字符串上面这些使用 () 包起来的地方就叫做分组 12'I love JavaScript'.match(/^I love (JavaScript|Regular Expression)$/)// [\"I love JavaScript\", \"JavaScript\", index: 0, input: \"I love JavaScript\"] 输出的数组第二个元素，”JavaScript” 就是分组匹配到的内容 引用分组提取数据比如我们要用正则来匹配一个日期格式，yyyy-mm-dd，可以写出简单的正则/\\d{4}-\\d{2}-\\d{2}/，这个正则还可以改成分组形式的/(\\d{4})-(\\d{2})-(\\d{2})/这样我们可以分别提取出一个日期的年月日，用 String 的 match 方法或者用正则的 exec 方法都可以1234var regex = /(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)/;var string = \"2017-08-09\";console.log( string.match(regex) ); // =&gt; [\"2017-08-09\", \"2017\", \"08\", \"09\", index: 0, input: \"2017-08-09\"] 也可以用正则对象构造函数的全局属性 $1 - $9 来获取 12345678910var regex = /(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)/;var string = \"2017-08-09\";regex.test(string); // 正则操作即可，例如//regex.exec(string);//string.match(regex);console.log(RegExp.$1); // \"2017\"console.log(RegExp.$2); // \"08\"console.log(RegExp.$3); // \"09\" 替换如果想要把 yyyy-mm-dd 替换成格式 mm/dd/yyyy 应该怎么做。String 的 replace 方法在第二个参数里面可以用 $1 - $9 来指代相应的分组 12345678910111213141516var regex = /(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)/;var string = \"2017-08-09\";var result = string.replace(regex, \"$2/$3/$1\");console.log(result); // \"08/09/2017\"等价var result = string.replace(regex, function() &#123; return RegExp.$2 + \"/\" + RegExp.$3 + \"/\" + RegExp.$1;&#125;);console.log(result); // \"08/09/2017\"等价var regex = /(\\d&#123;4&#125;)-(\\d&#123;2&#125;)-(\\d&#123;2&#125;)/;var string = \"2017-08-09\";var result = string.replace(regex, function(match, year, month, day) &#123; return month + \"/\" + day + \"/\" + year;&#125;);console.log(result); // \"08/09/2017\" 反向引用之前匹配日期的正则在使用的时候发现还有另外两种写法，一共三种123452017-08-092017/08/092017.08.09 要匹配这三种应该怎么写正则，第一反应肯定是把上面那个正则改一下/(\\d{4})[-/.](\\d{2})[-/.](\\d{2})/，把 - 改成 [-/.] 这三种都可以看上去没问题，我们多想想就会发现，这个正则把 2017-08.09 这种字符串也匹配到了，这个肯定是不符合预期的。这个时候我们就需要用到反向引用了，反向引用可以在匹配阶段捕获到分组的内容 /(\\d{4})([-/.])(\\d{2})\\2(\\d{2})/ 那么出现括号嵌套怎么办，比如1234567var regex = /^((\\d)(\\d(\\d)))\\1\\2\\3\\4$/;var string = \"1231231233\";console.log( regex.test(string) ); // trueconsole.log( RegExp.$1 ); // 123console.log( RegExp.$2 ); // 1console.log( RegExp.$3 ); // 23console.log( RegExp.$4 ); // 3 嵌套的括号以左括号为准 引用了不存在的分组呢如果在正则里面引用了前面不存在的分组，这个时候正则会匹配字符本身，比如\\1就匹配\\1 非捕获分组我们有时候只是想用括号原本的功能而不想捕获他们。这个时候可以用(?:p)表示一个非捕获分组 例子 驼峰改短横 123function dash(str) &#123;return str.replace(/([A-Z])/g, '-$1').toLowerCase();&#125; 获取链接的 search 值链接：https://www.baidu.com?name=jawil&amp;age=23 12345678function getParamName(attr) &#123;let match = RegExp(`[?&amp;]$&#123;attr&#125;=([^&amp;]*)`) //分组运算符是为了把结果存到exec函数返回的结果里 .exec(window.location.search)//[\"?name=jawil\", \"jawil\", index: 0, input: \"?name=jawil&amp;age=23\"]return match &amp;&amp; decodeURIComponent(match[1].replace(/\\+/g, ' ')) // url中+号表示空格,要替换掉&#125;console.log(getParamName('name')) // \"jawil\" 去掉字符串前后的空格 123function trim(str) &#123; return str.replace(/(^\\s*)|(\\s*$)/g, \"\")&#125; 判断一个数是否是质数 123function isPrime(num) &#123;return !/^1?$|^(11+?)\\1+$/.test(Array(num+1).join('1'))&#125; 这里首先是把一个数字变成1组成的字符串，比如11就是 ‘1111111111’ 11个1 然后正则分两部分，第一部分是匹配空字符串或者1,第二部分是先匹配两个或者多个1，非贪婪模式，那么先会匹配两个1，然后将匹配的两个1分组，后面就是匹配一个或者多个’2个1’，就相当于整除2，如果匹配成功就证明不是质数，如果不成功就会匹配3个1，然后匹配多个3个1，相当于整除3，这样一直下去会一直整除到自己本身。如果还是不行就证明这个数字是质数。 回溯正则是怎么匹配的有这么一个字符串 &#39;abbbc&#39; 和这么一个正则 /ab{1,3}bbc/ /ab{1,3}bbc/.test(&#39;abbbc&#39;) 我们一眼可以看出来是 true，但是 JavaScript 是怎么匹配的呢 回溯例如我们上面的例子，回溯的思想是，从问题的某一种状态（初始状态）出发，搜索从这种状态出发所能达到的所有“状态”，当一条路走到“尽头”的时候（不能再前进），再后退一步或若干步，从另一种可能“状态”出发，继续搜索，直到所有的“路径”（状态）都试探过。这种不断“前进”、不断“回溯”寻找解的方法，就称作“回溯法”贪婪和非贪婪的匹配都会产生回溯，不同的是贪婪的是先尽量多的匹配，如果不行就吐出一个然后继续匹配，再不行就再吐出一个，非贪婪的是先尽量少的匹配。如果不行就再多匹配一个，再不行就再来一个分支结构也会产生回溯，比如/^(test|te)sts$/.test(&#39;tests&#39;)前面括号里面的匹配过程是先匹配到 test 然后继续往后匹配匹配到字符 s 的时候还是成功的，匹配到 st 的时候发现不能匹配， 所以会回到前面的分支结构的其他分支继续匹配，如果不行的话再换其他分支。 读正则读懂其他人写的正则也是一个很重要的方面。 结构和操作符结构：字符字面量、字符组、量词、锚字符、分组、选择分支、反向引用。 操作符： 转义符 \\ 括号和方括号 (...)、(?:...)、(?=...)、(?!...)、[...] 量词限定符 {m}、{m,n}、{m,}、?、*、+ 位置和序列 ^ 、$、 \\元字符、 一般字符 管道符（竖杠） | 操作符的优先级是从上到下，由高到低的，所以在分析正则的时候可以根据优先级来拆分正则，比如/ab?(c|de*)+|fg/ 因为括号是一个整体，所以/ab?()+|fg/,括号里面具体是什么可以放到后面再分析 根据量词和管道符的优先级，所以a, b?, ()+和管道符后面的f,g 同理分析括号里面的c|de* =&gt; c和d, e* 综上，这个正则描述的是 以这种模式来分析，再复杂的正则都可以看懂。有一个可视化的正则分析网站 转载自网易考拉前端团队","categories":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://www.goyth.com/categories/JavaScript/"}],"tags":[{"name":"RegExp","slug":"RegExp","permalink":"http://www.goyth.com/tags/RegExp/"}]},{"title":"排序算法之堆排序","slug":"heapSort","date":"2018-02-09T14:06:52.000Z","updated":"2018-12-02T08:39:04.899Z","comments":true,"path":"2018/02/09/heapSort/","link":"","permalink":"http://www.goyth.com/2018/02/09/heapSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 堆排序 不得不说说二叉树要了解堆首先得了解一下二叉树，在计算机科学中，二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）。二叉树常被用于实现二叉查找树和二叉堆。 二叉树的每个结点至多只有二棵子树（不存在度大于 2 的结点），二叉树的子树有左右之分，次序不能颠倒。二叉树的第 i 层至多有 2i - 1 个结点；深度为 k 的二叉树至多有 2k - 1 个结点；对任何一棵二叉树 T，如果其终端结点数为 n0，度为 2 的结点数为 n2，则n0 = n2 + 1。","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 堆排序 不得不说说二叉树要了解堆首先得了解一下二叉树，在计算机科学中，二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）。二叉树常被用于实现二叉查找树和二叉堆。 二叉树的每个结点至多只有二棵子树（不存在度大于 2 的结点），二叉树的子树有左右之分，次序不能颠倒。二叉树的第 i 层至多有 2i - 1 个结点；深度为 k 的二叉树至多有 2k - 1 个结点；对任何一棵二叉树 T，如果其终端结点数为 n0，度为 2 的结点数为 n2，则n0 = n2 + 1。 树和二叉树的三个主要差别： 树的结点个数至少为 1，而二叉树的结点个数可以为 0 树中结点的最大度数没有限制，而二叉树结点的最大度数为 2 树的结点无左、右之分，而二叉树的结点有左、右之分 二叉树又分为完全二叉树（complete binary tree）和满二叉树（full binary tree） 满二叉树：一棵深度为 k，且有 2k - 1 个节点称之为满二叉树 完全二叉树：深度为 k，有 n 个节点的二叉树，当且仅当其每一个节点都与深度为 k 的满二叉树中序号为 1 至 n 的节点对应时，称之为完全二叉树 什么是堆？堆（二叉堆）可以视为一棵完全的二叉树，完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示（普通的一般的二叉树通常用链表作为基本容器表示），每一个结点对应数组中的一个元素。 如下图，是一个堆和数组的相互关系 对于给定的某个结点的下标 i，可以很容易的计算出这个结点的父结点、孩子结点的下标： Parent(i) = floor(i/2)，i 的父节点下标 Left(i) = 2i，i 的左子节点下标 Right(i) = 2i + 1，i 的右子节点下标 二叉堆一般分为两种：最大堆和最小堆。 最大堆： 最大堆中的最大元素值出现在根结点（堆顶） 堆中每个父节点的元素值都大于等于其孩子结点（如果存在） 最小堆： 最小堆中的最小元素值出现在根结点（堆顶） 堆中每个父节点的元素值都小于等于其孩子结点（如果存在） 堆排序原理堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作： 最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点 创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆 堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 继续进行下面的讨论前，需要注意的一个问题是：数组都是 Zero-Based，这就意味着我们的堆数据结构模型要发生改变 相应的，几个计算公式也要作出相应调整： Parent(i) = floor((i-1)/2)，i 的父节点下标 Left(i) = 2i + 1，i 的左子节点下标 Right(i) = 2(i + 1)，i 的右子节点下标 最大堆调整（MAX‐HEAPIFY）的作用是保持最大堆的性质，是创建最大堆的核心子程序，作用过程如图所示： 由于一次调整后，堆仍然违反堆性质，所以需要递归的测试，使得整个堆都满足堆性质，用 JavaScript 可以表示如下： 123456789101112131415161718192021222324252627282930/** * 从 index 开始检查并保持最大堆性质 * * @array * * @index 检查的起始下标 * * @heapSize 堆大小 * **/function maxHeapify(array, index, heapSize) &#123; var iMax = index, iLeft = 2 * index + 1, iRight = 2 * (index + 1); if (iLeft &lt; heapSize &amp;&amp; array[index] &lt; array[iLeft]) &#123; iMax = iLeft; &#125; if (iRight &lt; heapSize &amp;&amp; array[iMax] &lt; array[iRight]) &#123; iMax = iRight; &#125; if (iMax != index) &#123; swap(array, iMax, index); maxHeapify(array, iMax, heapSize); // 递归调整 &#125;&#125;function swap(array, i, j) &#123; var temp = array[i]; array[i] = array[j]; array[j] = temp;&#125; 通常来说，递归主要用在分治法中，而这里并不需要分治。而且递归调用需要压栈/清栈，和迭代相比，性能上有略微的劣势。当然，按照20/80法则，这是可以忽略的。但是如果你觉得用递归会让自己心里过不去的话，也可以用迭代，比如下面这样： 1234567891011121314151617181920212223242526272829303132333435/** * 从 index 开始检查并保持最大堆性质 * * @array * * @index 检查的起始下标 * * @heapSize 堆大小 * **/function maxHeapify(array, index, heapSize) &#123; var iMax, iLeft, iRight; while (true) &#123; iMax = index; iLeft = 2 * index + 1; iRight = 2 * (index + 1); if (iLeft &lt; heapSize &amp;&amp; array[index] &lt; array[iLeft]) &#123; iMax = iLeft; &#125; if (iRight &lt; heapSize &amp;&amp; array[iMax] &lt; array[iRight]) &#123; iMax = iRight; &#125; if (iMax != index) &#123; swap(array, iMax, index); index = iMax; &#125; else &#123; break; &#125; &#125;&#125;function swap(array, i, j) &#123; var temp = array[i]; array[i] = array[j]; array[j] = temp;&#125; 创建最大堆（Build-Max-Heap）的作用是将一个数组改造成一个最大堆，接受数组和堆大小两个参数，Build-Max-Heap 将自下而上的调用 Max-Heapify 来改造数组，建立最大堆。因为 Max-Heapify 能够保证下标 i 的结点之后结点都满足最大堆的性质，所以自下而上的调用 Max-Heapify 能够在改造过程中保持这一性质。如果最大堆的数量元素是 n，那么 Build-Max-Heap 从 Parent(n) 开始，往上依次调用 Max-Heapify。流程如下： 用 JavaScript 描述如下： 12345678function buildMaxHeap(array, heapSize) &#123; var i, iParent = Math.floor((heapSize - 1) / 2); for (i = iParent; i &gt;= 0; i--) &#123; maxHeapify(array, i, heapSize); &#125;&#125; 堆排序（Heap-Sort）是堆排序的接口算法，Heap-Sort先调用Build-Max-Heap将数组改造为最大堆，然后将堆顶和堆底元素交换，之后将底部上升，最后重新调用Max-Heapify保持最大堆性质。由于堆顶元素必然是堆中最大的元素，所以一次操作之后，堆中存在的最大元素被分离出堆，重复n-1次之后，数组排列完毕。整个流程如下： 用 JavaScript 描述如下： 1234567function heapSort(array, heapSize) &#123; buildMaxHeap(array, heapSize); for (int i = heapSize - 1; i &gt; 0; i--) &#123; swap(array, 0, i); maxHeapify(array, 0, i); &#125; &#125; JavaScript 语言实现最后，把上面的整理为完整的 javascript 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647function heapSort(arr)&#123; // 交换 function swap(arr, i, j)&#123; var temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; // 大顶堆调整 function maxHeapify(arr, index, maxSize)&#123; var leftChildIndex, rightChildIndex, maxValueIndex; maxValueIndex = index; leftChildIndex = 2 * index + 1; rightChildIndex = 2 * (index + 1); if(leftChildIndex &lt; maxSize &amp;&amp; arr[leftChildIndex] &gt; arr[index])&#123; maxValueIndex = leftChildIndex; &#125; if(rightChildIndex &lt; maxSize &amp;&amp; arr[maxValueIndex] &lt; arr[rightChildIndex])&#123; maxValueIndex = rightChildIndex; &#125; if(maxValueIndex != index)&#123; swap(arr, index, maxValueIndex); maxHeapify(arr, maxValueIndex, maxSize); // index = maxValueIndex; &#125; &#125; // 大顶堆构建 function buildMaxHeap(arr)&#123; var len = arr.length; var parentIndex = Math.floor((len - 1)/2); for(; parentIndex &gt;= 0; parentIndex--)&#123; maxHeapify(arr, parentIndex, len) &#125; &#125; // 堆排序 function sort(arr)&#123; buildMaxHeap(arr); for(var i = arr.length-1; i&gt;0; i--)&#123; swap(arr, 0, i); // 将堆顶元素与末尾元素交换 maxHeapify(arr, 0, i); &#125; return arr; &#125; return sort(arr);&#125; 参考链接：https://zh.wikipedia.org/wiki/%E5%A0%86%E6%8E%92%E5%BA%8Fhttps://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8F%89%E6%A0%91http://bubkoo.com/2014/01/14/sort-algorithm/heap-sort/","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"排序算法之快速排序","slug":"quickSort","date":"2018-02-09T10:47:16.000Z","updated":"2018-12-02T08:39:56.604Z","comments":true,"path":"2018/02/09/quickSort/","link":"","permalink":"http://www.goyth.com/2018/02/09/quickSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 快速排序 快速排序是图灵奖得主 C. R. A. Hoare 于 1960 年提出的一种划分交换排序。它采用了一种分治的策略，通常称其为分治法(Divide-and-ConquerMethod)。 分治法的基本思想是：将原问题分解为若干个规模更小但结构与原问题相似的子问题。递归地解这些子问题，然后将这些子问题的解组合为原问题的解。 利用分治法可将快速排序的分为三步： 在数据集之中，选择一个元素作为”基准”（pivot）。 所有小于”基准”的元素，都移到”基准”的左边；所有大于”基准”的元素，都移到”基准”的右边。这个操作称为分区 (partition) 操作，分区操作结束后，基准元素所处的位置就是最终排序后它的位置。 对”基准”左边和右边的两个子集，不断重复第一步和第二步，直到所有子集只剩下一个元素为止。","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 快速排序 快速排序是图灵奖得主 C. R. A. Hoare 于 1960 年提出的一种划分交换排序。它采用了一种分治的策略，通常称其为分治法(Divide-and-ConquerMethod)。 分治法的基本思想是：将原问题分解为若干个规模更小但结构与原问题相似的子问题。递归地解这些子问题，然后将这些子问题的解组合为原问题的解。 利用分治法可将快速排序的分为三步： 在数据集之中，选择一个元素作为”基准”（pivot）。 所有小于”基准”的元素，都移到”基准”的左边；所有大于”基准”的元素，都移到”基准”的右边。这个操作称为分区 (partition) 操作，分区操作结束后，基准元素所处的位置就是最终排序后它的位置。 对”基准”左边和右边的两个子集，不断重复第一步和第二步，直到所有子集只剩下一个元素为止。 JavaScript 递归版1234567891011121314151617181920212223242526272829function quickSort(arr)&#123; var high = arr.length - 1; qSort(arr, 0, high);&#125;function qSort(arr, low, high)&#123; if(low &gt;= high)&#123; return arr; &#125; var mid = partition(arr, low, high); qSort(arr, low, mid-1); qSort(arr, mid+1, high);&#125;function partition(arr, low, high)&#123; var pivot = arr[low]; while(low &lt; high)&#123; while(low &lt; high &amp;&amp; arr[high] &gt;= pivot)&#123; high--; &#125; arr[low] = arr[high]; while(low &lt; high &amp;&amp; arr[low] &lt;= pivot)&#123; low++; &#125; arr[high] = arr[low]; &#125; arr[low] = pivot; return low;&#125; JavaScript 迭代版12345678910111213141516171819202122232425262728293031323334353637383940function quickSort(arr)&#123; var high = arr.length - 1; qSort(arr, 0, high);&#125;function qSort(arr, low, high)&#123; var stack = []; var top = -1; stack[++top] = low; stack[++top] = high; while(top &gt;= 0)&#123; high = stack[top--]; low = stack[top--]; var mid = partition(arr, low, high); if(low &lt; mid - 1)&#123; stack[++top] = low; stack[++top] = mid - 1; &#125; if(mid + 1 &lt; high)&#123; stack[++top] = mid + 1; stack[++top] = high; &#125; &#125;&#125;function partition(arr, low, high)&#123; var pivot = arr[low]; while(low &lt; high)&#123; while(low &lt; high &amp;&amp; arr[high] &gt;= pivot)&#123; high--; &#125; arr[low] = arr[high]; while(low &lt; high &amp;&amp; arr[low] &lt;= pivot)&#123; low++; &#125; arr[high] = arr[low]; &#125; arr[low] = pivot; return low;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"排序算法之归并排序","slug":"mergeSort","date":"2018-02-09T08:05:22.000Z","updated":"2018-12-02T08:39:21.396Z","comments":true,"path":"2018/02/09/mergeSort/","link":"","permalink":"http://www.goyth.com/2018/02/09/mergeSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 归并排序归并排序（MERGE-SORT）是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。 归并排序可以使用递归和迭代两种方式进行实现","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 归并排序归并排序（MERGE-SORT）是建立在归并操作上的一种有效的排序算法,该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。 归并排序可以使用递归和迭代两种方式进行实现 递归法（Top-down） 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针到达序列尾 将另一序列剩下的所有元素直接复制到合并序列尾 迭代法（Bottom-up）原理如下（假设序列共有n个元素）： 将序列每相邻两个数字进行归并操作，形成 ceil(n/2)个序列，排序后每个序列包含两/一个元素 若此时序列数不是1个则将上述序列再次归并，形成 ceil(n/4)个序列，每个序列包含四/三个元素 重复步骤2，直到所有元素排序完毕，即序列数为1 JavaScrpt 递归版123456789101112131415161718192021222324function mergeSort(arr)&#123; var len = arr.length; if(len &lt;= 1)&#123; return arr; &#125; var mid = Math.floor(len/2) var left = arr.slice(0, mid); var right = arr.slice(mid); return merge(mergeSort(left), mergeSort(right))&#125;function merge(left, right)&#123; var result = []; while(left.length &gt; 0 &amp;&amp; right.length &gt; 0)&#123; if(left[0] &lt; right[0])&#123; result.push(left.shift()) &#125;else&#123; result.push(right.shift()) &#125; &#125; return result.concat(left).concat(right);&#125; JavaScrpt 迭代版1234567891011121314151617181920212223242526272829function mergeSort(arr)&#123; var len = arr.length; var result = []; for(var block=1; block &lt; len; block = 2 * block)&#123; for(var start = 0; start &lt; len; start = start + 2 * block)&#123; var low = start; var mid = (start + block) &gt; len ? len : (start + block) var high = (start + 2 * block) &gt; len ? len : (start + 2 * block) var start1 = low, end1 = mid; var start2 = mid, end2 = high; while(start1 &lt; end1 &amp;&amp; start2 &lt; end2)&#123; if(arr[start1] &lt; arr[start2])&#123; result[low++] = arr[start1++] &#125;else&#123; result[low++] = arr[start2++] &#125; &#125; while(start1 &lt; end1)&#123; result[low++] = arr[start1++] &#125; while(start2 &lt; end2)&#123; result[low++] = arr[start2++] &#125; &#125; arr = result; result = []; // 这里一定要将 result 设置为一个新的空数组，否则下一次循环时，修改result的同时也会修改arr &#125; return result;&#125;","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"排序算法之希尔排序","slug":"shellSort","date":"2018-02-08T08:19:32.000Z","updated":"2018-12-02T08:40:08.694Z","comments":true,"path":"2018/02/08/shellSort/","link":"","permalink":"http://www.goyth.com/2018/02/08/shellSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 希尔排序 希尔排序(Shell’s Sort)也称递减增量排序算法，是插入排序的一种更高效的改进版本。但希尔排序是非稳定排序算法。希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率； 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位； 希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时，再对全体记录进行依次直接插入排序。","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 希尔排序 希尔排序(Shell’s Sort)也称递减增量排序算法，是插入排序的一种更高效的改进版本。但希尔排序是非稳定排序算法。希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率； 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位； 希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录基本有序时，再对全体记录进行依次直接插入排序。 插入排序算法回顾12345678910111213function insertSort(arr)&#123; var len = arr.length; var temp; for(var i=1; i&lt;len-1; i++)&#123; if(arr[i-1] &gt; arr[i])&#123; temp = arr[i]; for(var j = i-1; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j--)&#123; arr[j+1] = arr[j]; &#125; arr[j+1] = temp; &#125; &#125;&#125; 希尔排序算法实现12345678910111213141516171819202122function shellSort(arr)&#123; var len = arr.length; var temp; for(var gap = Math.floor(len/2); gap &gt; 0; gap = Math.floor(gap/2))&#123; for(var i=gap; i&lt;len; i++)&#123; if(arr[i-gap] &gt; arr[i])&#123; temp = arr[i]; for(var j = i-gap; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j -= gap)&#123; arr[j+gap] = arr[j]; &#125; arr[j+gap] = temp; &#125; &#125; &#125; return arr;&#125;// 测试var arr = [3, 2, 4, 9, 1, 5, 7, 6, 8];var arrSorted = shellSort(arr);console.log(arrSorted);// 控制台将输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"排序算法之直接插入排序","slug":"straightInsertionSort","date":"2018-02-08T07:02:30.000Z","updated":"2018-12-02T08:40:13.389Z","comments":true,"path":"2018/02/08/straightInsertionSort/","link":"","permalink":"http://www.goyth.com/2018/02/08/straightInsertionSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序、基数排序等。这里主要介绍直接插入排序 排序算法总览： 直接插入排序 直接插入排序(Straight Insertion Sort)的基本思想是：把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序、基数排序等。这里主要介绍直接插入排序 排序算法总览： 直接插入排序 直接插入排序(Straight Insertion Sort)的基本思想是：把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 算法实现1234567891011121314151617181920function straightInsertSort(arr)&#123; var len = arr.length; var temp; for(var i=1; i&lt;len; i++)&#123; if(arr[i] &lt; arr[i-1])&#123; temp = arr[i]; for(var j = i-1; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j--)&#123; arr[j+1] = arr[j]; &#125; arr[j+1] = temp; &#125; &#125; return arr;&#125;// 测试var arr = [3, 2, 4, 9, 1, 5, 7, 6, 8];var arrSorted = straightInsertSort(arr);console.log(arrSorted);// 控制台将输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"排序算法之选择排序","slug":"selectionSort","date":"2018-02-08T05:03:59.000Z","updated":"2018-12-02T08:40:04.869Z","comments":true,"path":"2018/02/08/selectionSort/","link":"","permalink":"http://www.goyth.com/2018/02/08/selectionSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 选择排序 选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。 选择排序是不稳定的排序方法（比如序列[5， 5， 3]第一次就将第一个[5]与[3]交换，导致第一个5挪动到第二个5后面）。","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 选择排序 选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理是每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。 选择排序是不稳定的排序方法（比如序列[5， 5， 3]第一次就将第一个[5]与[3]交换，导致第一个5挪动到第二个5后面）。 算法实现12345678910111213141516171819202122function selectionSort(arr)&#123; var len = arr.length, minIndex = 0; for(var i = 0; i &lt; len-1; i++)&#123; minIndex = i; for(var j = i + 1; j &lt; len; j++)&#123; if(arr[j] &lt; arr[minIndex])&#123; minIndex = j; &#125; &#125; if(minIndex != i)&#123; [arr[minIndex], arr[i]] = [arr[i], arr[minIndex]] &#125; &#125; return arr;&#125;// 测试var arr = [3, 2, 4, 9, 1, 5, 7, 6, 8];var arrSorted = selectionSort(arr);console.log(arrSorted);// 控制台将输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]},{"title":"排序算法之冒泡排序","slug":"bubbleSort","date":"2018-02-08T02:40:24.000Z","updated":"2018-12-02T08:38:38.663Z","comments":true,"path":"2018/02/08/bubbleSort/","link":"","permalink":"http://www.goyth.com/2018/02/08/bubbleSort/","excerpt":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 冒泡排序 冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端，故名“冒泡排序”。","text":"常见的内部排序算法有：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序等。这里主要介绍快速排序 排序算法总览： 冒泡排序 冒泡排序（Bubble Sort），是一种计算机科学领域的较简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越大的元素会经由交换慢慢“浮”到数列的顶端，故名“冒泡排序”。 算法原理编辑冒泡排序算法的运作如下：（从前往后）比较相邻的元素。如果第一个比第二个大，就交换他们两个。对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。针对所有的元素重复以上的步骤，除了最后一个。持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 算法实现JavaScript12345678910111213141516function bubbleSort(arr)&#123; for(let i = arr.length-1; i&gt;0; i--)&#123; for(let j=0; j&lt;i; j++)&#123; if(arr[j] &gt; arr[j+1])&#123; [arr[j], arr[j+1]] = [arr[j+1], arr[j]] // 利用es6解构语法进行\bswap &#125; &#125; &#125; return arr;&#125;// 测试var arr = [3, 2, 4, 9, 1, 5, 7, 6, 8];var arrSorted = bubbleSort(arr);console.log(arrSorted);// 控制台将输出：[1, 2, 3, 4, 5, 6, 7, 8, 9] 冒泡算法优化12345678910111213141516171819function bubbleSort(arr)&#123; let flag = true; for(let i=arr.length-1; flag &amp;&amp; i&gt;0; i--)&#123; flag = false; //只要flag在下一次外循环条件检测的时候值为false，就说明已经排好序，不用继续循环 for(let j=0; j&lt;i; j++)&#123; if(arr[j] &gt; arr[j+1])&#123; flag = true; //如果有交换，就将标记变量赋true [arr[j], arr[j+1]] = [arr[j+1], arr[j]] // 利用es6解构语法进行\bswap &#125; &#125; &#125; return arr;&#125;// 测试var arr = [3, 2, 4, 9, 1, 5, 7, 6, 8];var arrSorted = bubbleSort(arr);console.log(arrSorted);// 控制台将输出：[1, 2, 3, 4, 5, 6, 7, 8, 9]","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"http://www.goyth.com/categories/Algorithm/"}],"tags":[{"name":"Sort","slug":"Sort","permalink":"http://www.goyth.com/tags/Sort/"}]}]}